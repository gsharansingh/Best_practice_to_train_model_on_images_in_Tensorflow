{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "organic-evanescence",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comic-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# this code is to allocate GPU memory for trainig execution\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-priest",
   "metadata": {},
   "source": [
    "**Defining common Parameters**: These common parameters are defined for all three methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "embedded-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 150\n",
    "IMG_HEIGHT = 150\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "\n",
    "data_dir = './datasets/small_training'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-intro",
   "metadata": {},
   "source": [
    "**Images used for the comparision**:  is `Fruits 360` from `https://www.kaggle.com/moltean/fruits` Amomg the 131 categories, I have used only 14. These classes are:\n",
    "\n",
    "`['Avocado', 'Banana', 'Blueberry', 'Cauliflower', 'Corn', 'Guava', 'Kiwi', 'Mango', 'Orange', 'Pear', 'Pineapple', 'Pomegranate', 'Strawberry', 'Watermelon']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "indie-recipient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Avocado', 'Banana', 'Blueberry', 'Cauliflower', 'Corn', 'Guava', 'Kiwi', 'Mango', 'Orange', 'Pear', 'Pineapple', 'Pomegranate', 'Strawberry', 'Watermelon']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 45 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import random\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "print('Classes:' ,sorted([dir1 for dir1 in os.listdir(data_dir)]))\n",
    "\n",
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 3\n",
    "ncols = 15\n",
    "\n",
    "# Index for iterating over images\n",
    "pic_index = 0\n",
    "\n",
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 1, nrows * 1)\n",
    "\n",
    "for i in range(45):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "    img = mpimg.imread(random.choice([x for x in glob.glob(data_dir+'/**/*.jpg')]))\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-donna",
   "metadata": {},
   "source": [
    "**Defining the optimizer, loss and accuracy**: Optimizer is same in all 3 methods. But Loss and Accuracy are common for first two methods, that are model with ImageDataGenerator and tf.Data\n",
    "\n",
    "<span style=\"color:red\">**NOTE** :</span>\n",
    "The reason why we did not use the same `set_loss` and `set_accuracy` for Autograph, because we have to create Loss and Accuracy object separately for both training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "confident-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_optimizer():\n",
    "    optimizer = tf.keras.optimizers.RMSprop(lr=0.0001) \n",
    "    return optimizer\n",
    "def set_loss():\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()  \n",
    "    return loss\n",
    "def set_accuracy():\n",
    "    accuracy = tf.keras.metrics.CategoricalAccuracy() \n",
    "    return accuracy\n",
    "optimizer = set_optimizer()\n",
    "loss = set_loss()\n",
    "accuracy = set_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-tanzania",
   "metadata": {},
   "source": [
    "**Model Creation**: Model is same in all three methods. It is an `InceptionV3` model which is customizied using *functional API* to perform transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "regional-blade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          262400      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 14)           3598        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 47,777,454\n",
      "Trainable params: 38,802,190\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Using transfer learning for model creation\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "local_weights_file = './tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "pre_trained_model = InceptionV3(input_shape = (IMG_WIDTH, IMG_HEIGHT, 3),\n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False \n",
    "# pre_trained_model.summary()\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.4)(x)    \n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(len(os.listdir(data_dir)), activation='softmax')(x)           \n",
    "\n",
    "model = tf.keras.Model(pre_trained_model.input, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-cookbook",
   "metadata": {},
   "source": [
    "# Model with ImageDataGenerator\n",
    "To make the comparision fair, I have not used **Data Augmentation** which creating training object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informational-calcium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5521 images belonging to 14 classes.\n",
      "Found 1376 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  validation_split=0.2)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=6,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='training',\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "validation_generator=train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=6,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='validation',\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "TRAINING_STEPS = len(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-aurora",
   "metadata": {},
   "source": [
    "**Compiling and fitting the model**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "twelve-internet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting time:  1617081525.7351725\n",
      "Epoch 1/30\n",
      "173/173 [==============================] - 19s 76ms/step - loss: 0.5281 - categorical_accuracy: 0.8514 - val_loss: 0.0190 - val_categorical_accuracy: 0.9942\n",
      "Epoch 2/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 0.0031 - categorical_accuracy: 0.9994 - val_loss: 0.0079 - val_categorical_accuracy: 0.9964\n",
      "Epoch 3/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 2.7757e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0092 - val_categorical_accuracy: 0.9964\n",
      "Epoch 4/30\n",
      "173/173 [==============================] - 11s 63ms/step - loss: 6.3957e-04 - categorical_accuracy: 0.9998 - val_loss: 0.0076 - val_categorical_accuracy: 0.9964\n",
      "Epoch 5/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 1.1156e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0029 - val_categorical_accuracy: 0.9971\n",
      "Epoch 6/30\n",
      "173/173 [==============================] - 11s 61ms/step - loss: 8.5571e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0073 - val_categorical_accuracy: 0.9964\n",
      "Epoch 7/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 1.7601e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0097 - val_categorical_accuracy: 0.9964\n",
      "Epoch 8/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 2.8347e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0128 - val_categorical_accuracy: 0.9964\n",
      "Epoch 9/30\n",
      "173/173 [==============================] - 11s 61ms/step - loss: 1.7993e-06 - categorical_accuracy: 1.0000 - val_loss: 0.0041 - val_categorical_accuracy: 0.9971\n",
      "Epoch 10/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 9.3672e-06 - categorical_accuracy: 1.0000 - val_loss: 0.0066 - val_categorical_accuracy: 0.9964\n",
      "Epoch 11/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 1.0120e-06 - categorical_accuracy: 1.0000 - val_loss: 0.0020 - val_categorical_accuracy: 0.9993\n",
      "Epoch 12/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 2.6080e-07 - categorical_accuracy: 1.0000 - val_loss: 0.0063 - val_categorical_accuracy: 0.9971\n",
      "Epoch 13/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 3.6585e-07 - categorical_accuracy: 1.0000 - val_loss: 0.0162 - val_categorical_accuracy: 0.9964\n",
      "Epoch 14/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 3.3797e-07 - categorical_accuracy: 1.0000 - val_loss: 0.0154 - val_categorical_accuracy: 0.9964\n",
      "Epoch 15/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 2.0880e-07 - categorical_accuracy: 1.0000 - val_loss: 0.0045 - val_categorical_accuracy: 0.9971\n",
      "Epoch 16/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 1.9336e-07 - categorical_accuracy: 1.0000 - val_loss: 0.0073 - val_categorical_accuracy: 0.9964\n",
      "Epoch 17/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 5.0846e-07 - categorical_accuracy: 1.0000 - val_loss: 0.0089 - val_categorical_accuracy: 0.9964\n",
      "Epoch 18/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 3.2522e-07 - categorical_accuracy: 1.0000 - val_loss: 0.0095 - val_categorical_accuracy: 0.9964\n",
      "Epoch 19/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 6.8809e-08 - categorical_accuracy: 1.0000 - val_loss: 0.0111 - val_categorical_accuracy: 0.9964\n",
      "Epoch 20/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 5.1918e-08 - categorical_accuracy: 1.0000 - val_loss: 0.0080 - val_categorical_accuracy: 0.9964\n",
      "Epoch 21/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 3.9373e-08 - categorical_accuracy: 1.0000 - val_loss: 0.0076 - val_categorical_accuracy: 0.9971\n",
      "Epoch 22/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 9.1556e-08 - categorical_accuracy: 1.0000 - val_loss: 0.0029 - val_categorical_accuracy: 0.9978\n",
      "Epoch 23/30\n",
      "173/173 [==============================] - 11s 63ms/step - loss: 5.4504e-07 - categorical_accuracy: 1.0000 - val_loss: 0.0054 - val_categorical_accuracy: 0.9971\n",
      "Epoch 24/30\n",
      "173/173 [==============================] - 11s 64ms/step - loss: 1.6349e-08 - categorical_accuracy: 1.0000 - val_loss: 0.0092 - val_categorical_accuracy: 0.9964\n",
      "Epoch 25/30\n",
      "173/173 [==============================] - 11s 65ms/step - loss: 1.5213e-08 - categorical_accuracy: 1.0000 - val_loss: 0.0086 - val_categorical_accuracy: 0.9964\n",
      "Epoch 26/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 1.3079e-07 - categorical_accuracy: 1.0000 - val_loss: 0.0071 - val_categorical_accuracy: 0.9971\n",
      "Epoch 27/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 2.1436e-06 - categorical_accuracy: 1.0000 - val_loss: 0.0190 - val_categorical_accuracy: 0.9964\n",
      "Epoch 28/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 1.2334e-04 - categorical_accuracy: 0.9999 - val_loss: 0.0200 - val_categorical_accuracy: 0.9964\n",
      "Epoch 29/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 2.2870e-08 - categorical_accuracy: 1.0000 - val_loss: 0.0230 - val_categorical_accuracy: 0.9964\n",
      "Epoch 30/30\n",
      "173/173 [==============================] - 11s 62ms/step - loss: 9.0965e-08 - categorical_accuracy: 1.0000 - val_loss: 0.0143 - val_categorical_accuracy: 0.9964\n",
      "finishing time:  1617081857.0645316\n",
      "\n",
      "total time taken:  331.32935905456543\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = optimizer, \n",
    "              loss = loss, \n",
    "              metrics = [accuracy])\n",
    "\n",
    "t0 = time.time()\n",
    "print('starting time: ', t0)\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=TRAINING_STEPS,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1)\n",
    "\n",
    "tn = time.time()\n",
    "print('finishing time: ', tn)\n",
    "t_m1 = tn - t0\n",
    "print('\\ntotal time taken: ', t_m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-freeware",
   "metadata": {},
   "source": [
    "**Deleting the model**: To avoid running into memory errors, I have deleted the model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "favorite-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-sheet",
   "metadata": {},
   "source": [
    "# Model with tf.Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mental-disaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5518 images belonging to 14 classes\n",
      "Found 1379 images belonging to 14 classes\n"
     ]
    }
   ],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(data_dir+'/*/*'), shuffle=False)\n",
    "list_ds = list_ds.shuffle(len(list_ds), reshuffle_each_iteration=False)\n",
    "\n",
    "# spitting the data into training and validation datasets\n",
    "val_size = int(len(list_ds) * 0.2)\n",
    "train_ds = list_ds.skip(val_size)\n",
    "val_ds = list_ds.take(val_size)\n",
    "\n",
    "class_names = np.array(sorted([dir1 for dir1 in os.listdir(data_dir)]))\n",
    "\n",
    "print(f'Found {tf.data.experimental.cardinality(train_ds).numpy()} images belonging to {len(os.listdir(data_dir))} classes')\n",
    "print(f'Found {tf.data.experimental.cardinality(val_ds).numpy()} images belonging to {len(os.listdir(data_dir))} classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "running-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To process the label\n",
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components separated by sep\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "  \n",
    "    # The second to last is the class-directory\n",
    "    one_hot = parts[-2] == class_names\n",
    "    # Integer encode the label\n",
    "    return one_hot\n",
    "\n",
    "# To process the image\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # resize the image to the desired size\n",
    "    return tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
    "\n",
    "# To create the single training of validation example with image and its corresponding label\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unauthorized-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=256)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pointed-petroleum",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting time:  1617081857.4766304\n",
      "Epoch 1/30\n",
      "172/172 [==============================] - 15s 75ms/step - loss: 121.8257 - categorical_accuracy: 0.7419 - val_loss: 0.8376 - val_categorical_accuracy: 0.9608\n",
      "Epoch 2/30\n",
      "172/172 [==============================] - 11s 62ms/step - loss: 5.9450 - categorical_accuracy: 0.8500 - val_loss: 0.8086 - val_categorical_accuracy: 0.9587\n",
      "Epoch 3/30\n",
      "172/172 [==============================] - 11s 62ms/step - loss: 3.4387 - categorical_accuracy: 0.8954 - val_loss: 0.9850 - val_categorical_accuracy: 0.9775\n",
      "Epoch 4/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 2.2590 - categorical_accuracy: 0.9277 - val_loss: 0.3899 - val_categorical_accuracy: 0.9775\n",
      "Epoch 5/30\n",
      "172/172 [==============================] - 11s 62ms/step - loss: 1.9118 - categorical_accuracy: 0.9315 - val_loss: 0.0956 - val_categorical_accuracy: 0.9935\n",
      "Epoch 6/30\n",
      "172/172 [==============================] - 11s 62ms/step - loss: 1.3187 - categorical_accuracy: 0.9469 - val_loss: 0.3428 - val_categorical_accuracy: 0.9703\n",
      "Epoch 7/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 1.0724 - categorical_accuracy: 0.9550 - val_loss: 0.0111 - val_categorical_accuracy: 0.9985\n",
      "Epoch 8/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 1.1483 - categorical_accuracy: 0.9550 - val_loss: 0.2384 - val_categorical_accuracy: 0.9935\n",
      "Epoch 9/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.8171 - categorical_accuracy: 0.9628 - val_loss: 0.0604 - val_categorical_accuracy: 0.9942\n",
      "Epoch 10/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.6400 - categorical_accuracy: 0.9702 - val_loss: 0.0582 - val_categorical_accuracy: 0.9956\n",
      "Epoch 11/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.7921 - categorical_accuracy: 0.9615 - val_loss: 0.0235 - val_categorical_accuracy: 0.9985\n",
      "Epoch 12/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.9951 - categorical_accuracy: 0.9659 - val_loss: 0.1018 - val_categorical_accuracy: 0.9949\n",
      "Epoch 13/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.5856 - categorical_accuracy: 0.9695 - val_loss: 0.0832 - val_categorical_accuracy: 0.9964\n",
      "Epoch 14/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.6808 - categorical_accuracy: 0.9688 - val_loss: 0.0211 - val_categorical_accuracy: 0.9993\n",
      "Epoch 15/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.3803 - categorical_accuracy: 0.9791 - val_loss: 0.0446 - val_categorical_accuracy: 0.9993\n",
      "Epoch 16/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.4238 - categorical_accuracy: 0.9776 - val_loss: 0.0194 - val_categorical_accuracy: 0.9993\n",
      "Epoch 17/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.4794 - categorical_accuracy: 0.9791 - val_loss: 0.0294 - val_categorical_accuracy: 0.9993\n",
      "Epoch 18/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.3580 - categorical_accuracy: 0.9815 - val_loss: 0.0685 - val_categorical_accuracy: 0.9985\n",
      "Epoch 19/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.3911 - categorical_accuracy: 0.9770 - val_loss: 0.0121 - val_categorical_accuracy: 0.9971\n",
      "Epoch 20/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.6132 - categorical_accuracy: 0.9712 - val_loss: 0.0175 - val_categorical_accuracy: 0.9993\n",
      "Epoch 21/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.2748 - categorical_accuracy: 0.9837 - val_loss: 0.0101 - val_categorical_accuracy: 0.9993\n",
      "Epoch 22/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.2701 - categorical_accuracy: 0.9842 - val_loss: 0.0272 - val_categorical_accuracy: 0.9993\n",
      "Epoch 23/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.4921 - categorical_accuracy: 0.9747 - val_loss: 0.0523 - val_categorical_accuracy: 0.9993\n",
      "Epoch 24/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.2001 - categorical_accuracy: 0.9861 - val_loss: 0.0401 - val_categorical_accuracy: 0.9993\n",
      "Epoch 25/30\n",
      "172/172 [==============================] - 11s 63ms/step - loss: 0.4138 - categorical_accuracy: 0.9795 - val_loss: 0.0638 - val_categorical_accuracy: 0.9985\n",
      "Epoch 26/30\n",
      "172/172 [==============================] - 11s 62ms/step - loss: 0.3527 - categorical_accuracy: 0.9796 - val_loss: 0.0492 - val_categorical_accuracy: 0.9993\n",
      "Epoch 27/30\n",
      "172/172 [==============================] - 11s 62ms/step - loss: 0.3313 - categorical_accuracy: 0.9828 - val_loss: 0.0880 - val_categorical_accuracy: 0.9942\n",
      "Epoch 28/30\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.3420 - categorical_accuracy: 0.9851 - val_loss: 0.0692 - val_categorical_accuracy: 0.9978\n",
      "Epoch 29/30\n",
      "172/172 [==============================] - 11s 62ms/step - loss: 0.3613 - categorical_accuracy: 0.9823 - val_loss: 0.0503 - val_categorical_accuracy: 0.9993\n",
      "Epoch 30/30\n",
      "172/172 [==============================] - 11s 62ms/step - loss: 0.3255 - categorical_accuracy: 0.9831 - val_loss: 0.0274 - val_categorical_accuracy: 0.9993\n",
      "finishing time:  1617082179.4681156\n",
      "\n",
      "total time taken:  321.99148511886597\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(pre_trained_model.input, x)\n",
    "model.compile(optimizer = optimizer, \n",
    "              loss = loss, \n",
    "              metrics = [accuracy]) \n",
    "\n",
    "t0 = time.time()\n",
    "print('starting time: ', t0)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds.repeat(),\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=172,\n",
    "    validation_data=val_ds,\n",
    "    verbose=1)\n",
    "\n",
    "tn = time.time()\n",
    "print('finishing time: ', tn)\n",
    "t_m2 = tn - t0\n",
    "print('\\ntotal time taken: ', t_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "oriental-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-graduation",
   "metadata": {},
   "source": [
    "# with Autograph model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adaptive-father",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5518 images belonging to 14 classes\n",
      "Found 1379 images belonging to 14 classes\n"
     ]
    }
   ],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(data_dir+'/*/*'), shuffle=False)\n",
    "list_ds = list_ds.shuffle(len(list_ds), reshuffle_each_iteration=False)\n",
    "\n",
    "# spitting the data into training and validation datasets\n",
    "val_size = int(len(list_ds) * 0.2)\n",
    "train_ds = list_ds.skip(val_size)\n",
    "val_ds = list_ds.take(val_size)\n",
    "\n",
    "class_names = np.array(sorted([dir1 for dir1 in os.listdir(data_dir)]))\n",
    "\n",
    "print(f'Found {tf.data.experimental.cardinality(train_ds).numpy()} images belonging to {len(os.listdir(data_dir))} classes')\n",
    "print(f'Found {tf.data.experimental.cardinality(val_ds).numpy()} images belonging to {len(os.listdir(data_dir))} classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "advanced-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_optimizer():\n",
    "    optimizer = tf.keras.optimizers.RMSprop(lr=0.0001) \n",
    "    return optimizer\n",
    "def set_loss():\n",
    "    train_loss = tf.keras.losses.CategoricalCrossentropy() \n",
    "    val_loss = tf.keras.losses.CategoricalCrossentropy() \n",
    "    return train_loss, val_loss\n",
    "def set_accuracy():\n",
    "    train_accuracy = tf.keras.metrics.CategoricalAccuracy() \n",
    "    val_accuracy = tf.keras.metrics.CategoricalAccuracy() \n",
    "    return train_accuracy, val_accuracy\n",
    "optimizer = set_optimizer()\n",
    "train_loss, val_loss = set_loss()\n",
    "train_accuracy, val_accuracy = set_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "novel-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def map_fn(img):\n",
    "    img = tf.image.resize(img, (IMG_HEIGHT, IMG_WIDTH)) \n",
    "    img /= 255.0\n",
    "    return img\n",
    "\n",
    "#To process the label\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    one_hot = parts[-2] == class_names #one-hot encoding the labels\n",
    "    return one_hot\n",
    "\n",
    "# To process the image\n",
    "def decode_img(img):\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return map_fn(img)\n",
    "\n",
    "# To create the single training of validation example with image and its corresponding label\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=256)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dietary-enterprise",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting time:  1617082607.3165264\n",
      "Step 1 : train loss 2.57006311 ; train accuracy 0.03125\n",
      "Step 2 : train loss 1.97808266 ; train accuracy 0.25\n",
      "Step 3 : train loss 1.65106678 ; train accuracy 0.333333343\n",
      "Step 4 : train loss 1.26847529 ; train accuracy 0.40625\n",
      "Step 5 : train loss 0.709853172 ; train accuracy 0.5125\n",
      "Step 6 : train loss 0.655120254 ; train accuracy 0.557291687\n",
      "Step 7 : train loss 0.863617063 ; train accuracy 0.580357134\n",
      "Step 8 : train loss 0.42618981 ; train accuracy 0.625\n",
      "Step 9 : train loss 0.370180905 ; train accuracy 0.649305582\n",
      "Step 10 : train loss 0.33661136 ; train accuracy 0.678125\n",
      "Step 11 : train loss 0.166169614 ; train accuracy 0.707386374\n",
      "Step 12 : train loss 0.437790334 ; train accuracy 0.7265625\n",
      "Step 13 : train loss 0.398728669 ; train accuracy 0.737980783\n",
      "Step 14 : train loss 0.113891445 ; train accuracy 0.756696403\n",
      "Step 15 : train loss 0.0546099097 ; train accuracy 0.772916675\n",
      "Step 16 : train loss 0.0893028 ; train accuracy 0.787109375\n",
      "Step 17 : train loss 0.0448833406 ; train accuracy 0.79963237\n",
      "Step 18 : train loss 0.0561709404 ; train accuracy 0.810763896\n",
      "Step 19 : train loss 0.0385369584 ; train accuracy 0.820723712\n",
      "Step 20 : train loss 0.0808804333 ; train accuracy 0.829687476\n",
      "Step 21 : train loss 0.0921182707 ; train accuracy 0.836309552\n",
      "Step 22 : train loss 0.0364599377 ; train accuracy 0.84375\n",
      "Step 23 : train loss 0.0338685364 ; train accuracy 0.850543499\n",
      "Step 24 : train loss 0.0329744928 ; train accuracy 0.856770813\n",
      "Step 25 : train loss 0.0215238556 ; train accuracy 0.8625\n",
      "Step 26 : train loss 0.0270367935 ; train accuracy 0.867788434\n",
      "Step 27 : train loss 0.023843484 ; train accuracy 0.872685194\n",
      "Step 28 : train loss 0.0282618869 ; train accuracy 0.877232134\n",
      "Step 29 : train loss 0.026771795 ; train accuracy 0.881465495\n",
      "Step 30 : train loss 0.0215596445 ; train accuracy 0.885416687\n",
      "Step 31 : train loss 0.00641091075 ; train accuracy 0.88911289\n",
      "Step 32 : train loss 0.034293294 ; train accuracy 0.892578125\n",
      "Step 33 : train loss 0.0133957 ; train accuracy 0.895833313\n",
      "Step 34 : train loss 0.0103377961 ; train accuracy 0.898897052\n",
      "Step 35 : train loss 0.00996058621 ; train accuracy 0.901785731\n",
      "Step 36 : train loss 0.0106522497 ; train accuracy 0.904513896\n",
      "Step 37 : train loss 0.0153203011 ; train accuracy 0.907094598\n",
      "Step 38 : train loss 0.00910599343 ; train accuracy 0.909539461\n",
      "Step 39 : train loss 0.0132530928 ; train accuracy 0.911859\n",
      "Step 40 : train loss 0.00887818169 ; train accuracy 0.9140625\n",
      "Step 41 : train loss 0.00524352817 ; train accuracy 0.916158557\n",
      "Step 42 : train loss 0.00831075 ; train accuracy 0.918154776\n",
      "Step 43 : train loss 0.00532876654 ; train accuracy 0.920058131\n",
      "Step 44 : train loss 0.00464921584 ; train accuracy 0.921875\n",
      "Step 45 : train loss 0.00450249668 ; train accuracy 0.923611104\n",
      "Step 46 : train loss 0.00410687784 ; train accuracy 0.925271749\n",
      "Step 47 : train loss 0.00569286384 ; train accuracy 0.926861703\n",
      "Step 48 : train loss 0.00654342631 ; train accuracy 0.928385437\n",
      "Step 49 : train loss 0.0064534368 ; train accuracy 0.929846942\n",
      "Step 50 : train loss 0.00444026245 ; train accuracy 0.93125\n",
      "Step 51 : train loss 0.00264305063 ; train accuracy 0.932598054\n",
      "Step 52 : train loss 0.00451835245 ; train accuracy 0.933894217\n",
      "Step 53 : train loss 0.00346727856 ; train accuracy 0.935141504\n",
      "Step 54 : train loss 0.00187532627 ; train accuracy 0.936342597\n",
      "Step 55 : train loss 0.00350961974 ; train accuracy 0.9375\n",
      "Step 56 : train loss 0.00292324764 ; train accuracy 0.938616097\n",
      "Step 57 : train loss 0.00266076298 ; train accuracy 0.939693\n",
      "Step 58 : train loss 0.00259847287 ; train accuracy 0.940732777\n",
      "Step 59 : train loss 0.00233640708 ; train accuracy 0.941737294\n",
      "Step 60 : train loss 0.00139626255 ; train accuracy 0.942708313\n",
      "Step 61 : train loss 0.00132747856 ; train accuracy 0.943647563\n",
      "Step 62 : train loss 0.00148580945 ; train accuracy 0.944556475\n",
      "Step 63 : train loss 0.00175985054 ; train accuracy 0.945436537\n",
      "Step 64 : train loss 0.0012592423 ; train accuracy 0.946289062\n",
      "Step 65 : train loss 0.00149061973 ; train accuracy 0.947115362\n",
      "Step 66 : train loss 0.00242626364 ; train accuracy 0.947916687\n",
      "Step 67 : train loss 0.0022989253 ; train accuracy 0.94869405\n",
      "Step 68 : train loss 0.000973402814 ; train accuracy 0.949448526\n",
      "Step 69 : train loss 0.00120132871 ; train accuracy 0.950181186\n",
      "Step 70 : train loss 0.00125379895 ; train accuracy 0.950892866\n",
      "Step 71 : train loss 0.00205806526 ; train accuracy 0.951584518\n",
      "Step 72 : train loss 0.0011131214 ; train accuracy 0.952256918\n",
      "Step 73 : train loss 0.000967427739 ; train accuracy 0.95291096\n",
      "Step 74 : train loss 0.0010370505 ; train accuracy 0.953547299\n",
      "Step 75 : train loss 0.00099103048 ; train accuracy 0.954166651\n",
      "Step 76 : train loss 0.000951176044 ; train accuracy 0.954769731\n",
      "Step 77 : train loss 0.000946517743 ; train accuracy 0.955357134\n",
      "Step 78 : train loss 0.000820217305 ; train accuracy 0.955929458\n",
      "Step 79 : train loss 0.00149625784 ; train accuracy 0.956487358\n",
      "Step 80 : train loss 0.000581749948 ; train accuracy 0.95703125\n",
      "Step 81 : train loss 0.000609351 ; train accuracy 0.957561731\n",
      "Step 82 : train loss 0.000608656 ; train accuracy 0.958079278\n",
      "Step 83 : train loss 0.00066416245 ; train accuracy 0.958584309\n",
      "Step 84 : train loss 0.000377057353 ; train accuracy 0.959077358\n",
      "Step 85 : train loss 0.0004778039 ; train accuracy 0.959558845\n",
      "Step 86 : train loss 0.000414288515 ; train accuracy 0.960029066\n",
      "Step 87 : train loss 0.000392568618 ; train accuracy 0.960488498\n",
      "Step 88 : train loss 0.000375505566 ; train accuracy 0.9609375\n",
      "Step 89 : train loss 0.000332022784 ; train accuracy 0.961376429\n",
      "Step 90 : train loss 0.000284576439 ; train accuracy 0.961805582\n",
      "Step 91 : train loss 0.000428533676 ; train accuracy 0.962225258\n",
      "Step 92 : train loss 0.000280111097 ; train accuracy 0.962635875\n",
      "Step 93 : train loss 0.000217707042 ; train accuracy 0.96303761\n",
      "Step 94 : train loss 0.000362293969 ; train accuracy 0.963430822\n",
      "Step 95 : train loss 0.00025287774 ; train accuracy 0.963815808\n",
      "Step 96 : train loss 0.00038310769 ; train accuracy 0.964192688\n",
      "Step 97 : train loss 0.000256150262 ; train accuracy 0.96456188\n",
      "Step 98 : train loss 0.000372644921 ; train accuracy 0.964923441\n",
      "Step 99 : train loss 0.000122505269 ; train accuracy 0.965277791\n",
      "Step 100 : train loss 0.000161120086 ; train accuracy 0.965625\n",
      "Step 101 : train loss 0.000183620927 ; train accuracy 0.965965331\n",
      "Step 102 : train loss 0.000241267466 ; train accuracy 0.966299\n",
      "Step 103 : train loss 0.000316919904 ; train accuracy 0.966626227\n",
      "Step 104 : train loss 0.000198876136 ; train accuracy 0.966947138\n",
      "Step 105 : train loss 0.000175955909 ; train accuracy 0.96726191\n",
      "Step 106 : train loss 0.00137630431 ; train accuracy 0.967570782\n",
      "Step 107 : train loss 0.210007012 ; train accuracy 0.966997683\n",
      "Step 108 : train loss 0.226369888 ; train accuracy 0.967013896\n",
      "Step 109 : train loss 0.0391077735 ; train accuracy 0.96702981\n",
      "Step 110 : train loss 0.000172063868 ; train accuracy 0.967329562\n",
      "Step 111 : train loss 0.000315122568 ; train accuracy 0.967623889\n",
      "Step 112 : train loss 0.00238666893 ; train accuracy 0.967913\n",
      "Step 113 : train loss 0.000728136511 ; train accuracy 0.968196929\n",
      "Step 114 : train loss 0.000474959088 ; train accuracy 0.968475878\n",
      "Step 115 : train loss 0.0109665859 ; train accuracy 0.96875\n",
      "Step 116 : train loss 0.000234544917 ; train accuracy 0.969019413\n",
      "Step 117 : train loss 0.000413701433 ; train accuracy 0.969284177\n",
      "Step 118 : train loss 0.000197597401 ; train accuracy 0.96954447\n",
      "Step 119 : train loss 0.000390449655 ; train accuracy 0.969800413\n",
      "Step 120 : train loss 0.000182998934 ; train accuracy 0.970052063\n",
      "Step 121 : train loss 0.000201472969 ; train accuracy 0.970299602\n",
      "Step 122 : train loss 0.000137839903 ; train accuracy 0.970543\n",
      "Step 123 : train loss 0.000201247749 ; train accuracy 0.970782518\n",
      "Step 124 : train loss 0.000193294502 ; train accuracy 0.971018136\n",
      "Step 125 : train loss 0.000150711159 ; train accuracy 0.97125\n",
      "Step 126 : train loss 0.000138124815 ; train accuracy 0.971478164\n",
      "Step 127 : train loss 0.0002175634 ; train accuracy 0.971702754\n",
      "Step 128 : train loss 8.67253402e-05 ; train accuracy 0.971923828\n",
      "Step 129 : train loss 0.000175043664 ; train accuracy 0.972141445\n",
      "Step 130 : train loss 0.000298229075 ; train accuracy 0.972355783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 131 : train loss 7.81543276e-05 ; train accuracy 0.972566783\n",
      "Step 132 : train loss 9.89404944e-05 ; train accuracy 0.972774625\n",
      "Step 133 : train loss 0.000328603084 ; train accuracy 0.972979307\n",
      "Step 134 : train loss 0.000446135324 ; train accuracy 0.97318095\n",
      "Step 135 : train loss 7.01288591e-05 ; train accuracy 0.973379612\n",
      "Step 136 : train loss 0.000158887822 ; train accuracy 0.973575354\n",
      "Step 137 : train loss 0.00010194839 ; train accuracy 0.973768234\n",
      "Step 138 : train loss 0.000113884329 ; train accuracy 0.973958313\n",
      "Step 139 : train loss 0.000136332237 ; train accuracy 0.97414571\n",
      "Step 140 : train loss 7.83114447e-05 ; train accuracy 0.974330366\n",
      "Step 141 : train loss 0.00010874345 ; train accuracy 0.974512398\n",
      "Step 142 : train loss 0.000143837358 ; train accuracy 0.974691927\n",
      "Step 143 : train loss 6.61652593e-05 ; train accuracy 0.974868894\n",
      "Step 144 : train loss 6.78292781e-05 ; train accuracy 0.975043416\n",
      "Step 145 : train loss 0.000194419335 ; train accuracy 0.975215495\n",
      "Step 146 : train loss 7.65550358e-05 ; train accuracy 0.975385249\n",
      "Step 147 : train loss 6.49918147e-05 ; train accuracy 0.975552738\n",
      "Step 148 : train loss 0.000108126653 ; train accuracy 0.975717902\n",
      "Step 149 : train loss 3.98773955e-05 ; train accuracy 0.975880861\n",
      "Step 150 : train loss 6.10992356e-05 ; train accuracy 0.976041675\n",
      "Step 151 : train loss 4.52485911e-05 ; train accuracy 0.976200342\n",
      "Step 152 : train loss 7.57104e-05 ; train accuracy 0.976356924\n",
      "Step 153 : train loss 4.51364103e-05 ; train accuracy 0.976511419\n",
      "Step 154 : train loss 5.59570217e-05 ; train accuracy 0.976663947\n",
      "Step 155 : train loss 4.85016e-05 ; train accuracy 0.976814508\n",
      "Step 156 : train loss 5.30180332e-05 ; train accuracy 0.976963162\n",
      "Step 157 : train loss 5.47183845e-05 ; train accuracy 0.977109849\n",
      "Step 158 : train loss 6.86728599e-05 ; train accuracy 0.977254748\n",
      "Step 159 : train loss 0.000115749615 ; train accuracy 0.977397799\n",
      "Step 160 : train loss 3.18682432e-05 ; train accuracy 0.977539062\n",
      "Step 161 : train loss 9.18767328e-05 ; train accuracy 0.977678597\n",
      "Step 162 : train loss 2.92123314e-05 ; train accuracy 0.977816343\n",
      "Step 163 : train loss 8.47101255e-05 ; train accuracy 0.97795248\n",
      "Step 164 : train loss 2.95072659e-05 ; train accuracy 0.978086889\n",
      "Step 165 : train loss 0.000134240137 ; train accuracy 0.978219688\n",
      "Step 166 : train loss 2.64634364e-05 ; train accuracy 0.978350878\n",
      "Step 167 : train loss 0.000114630486 ; train accuracy 0.978480518\n",
      "Step 168 : train loss 2.38485809e-05 ; train accuracy 0.978608608\n",
      "Step 169 : train loss 2.91409597e-05 ; train accuracy 0.978735209\n",
      "Step 170 : train loss 4.13844682e-05 ; train accuracy 0.978860319\n",
      "Step 171 : train loss 2.36617634e-05 ; train accuracy 0.978983939\n",
      "Step 172 : train loss 0.000101104582 ; train accuracy 0.979106128\n",
      "Step 173 : train loss 1.36237413e-05 ; train accuracy 0.979159117\n",
      "val loss 1.35103744e-06 ; val accuracy 1\n",
      "Step 174 : train loss 1.27924168e-05 ; train accuracy 0.97927928\n",
      "Step 175 : train loss 5.06229226e-05 ; train accuracy 0.979398072\n",
      "Step 176 : train loss 3.142266e-05 ; train accuracy 0.979515493\n",
      "Step 177 : train loss 1.69568339e-05 ; train accuracy 0.979631603\n",
      "Step 178 : train loss 1.86965553e-05 ; train accuracy 0.979746401\n",
      "Step 179 : train loss 5.82166758e-05 ; train accuracy 0.979859889\n",
      "Step 180 : train loss 1.36752224e-05 ; train accuracy 0.979972124\n",
      "Step 181 : train loss 3.25775109e-05 ; train accuracy 0.980083108\n",
      "Step 182 : train loss 1.92772623e-05 ; train accuracy 0.9801929\n",
      "Step 183 : train loss 1.1119766e-05 ; train accuracy 0.980301499\n",
      "Step 184 : train loss 1.60811887e-05 ; train accuracy 0.980408847\n",
      "Step 185 : train loss 1.61742464e-05 ; train accuracy 0.980515063\n",
      "Step 186 : train loss 1.18126545e-05 ; train accuracy 0.980620146\n",
      "Step 187 : train loss 2.68505682e-05 ; train accuracy 0.980724096\n",
      "Step 188 : train loss 1.32203104e-05 ; train accuracy 0.980826914\n",
      "Step 189 : train loss 7.71129453e-06 ; train accuracy 0.980928719\n",
      "Step 190 : train loss 1.98644666e-05 ; train accuracy 0.981029391\n",
      "Step 191 : train loss 1.65771744e-05 ; train accuracy 0.981129\n",
      "Step 192 : train loss 1.04976907e-05 ; train accuracy 0.981227577\n",
      "Step 193 : train loss 1.53439942e-05 ; train accuracy 0.98132509\n",
      "Step 194 : train loss 9.55885116e-06 ; train accuracy 0.981421649\n",
      "Step 195 : train loss 2.01011699e-05 ; train accuracy 0.981517196\n",
      "Step 196 : train loss 9.89420187e-06 ; train accuracy 0.981611788\n",
      "Step 197 : train loss 1.23676436e-05 ; train accuracy 0.981705368\n",
      "Step 198 : train loss 9.16399767e-06 ; train accuracy 0.981798053\n",
      "Step 199 : train loss 1.51727691e-05 ; train accuracy 0.981889784\n",
      "Step 200 : train loss 6.49683443e-06 ; train accuracy 0.981980562\n",
      "Step 201 : train loss 8.31476427e-06 ; train accuracy 0.982070446\n",
      "Step 202 : train loss 1.11234367e-05 ; train accuracy 0.982159495\n",
      "Step 203 : train loss 1.23710033e-05 ; train accuracy 0.982247591\n",
      "Step 204 : train loss 5.96041127e-06 ; train accuracy 0.982334852\n",
      "Step 205 : train loss 4.649115e-06 ; train accuracy 0.982421279\n",
      "Step 206 : train loss 1.83119137e-05 ; train accuracy 0.982506871\n",
      "Step 207 : train loss 1.37198876e-05 ; train accuracy 0.982591569\n",
      "Step 208 : train loss 1.13245378e-05 ; train accuracy 0.982675493\n",
      "Step 209 : train loss 8.05771469e-06 ; train accuracy 0.982758641\n",
      "Step 210 : train loss 7.73361171e-06 ; train accuracy 0.982840955\n",
      "Step 211 : train loss 4.31757326e-06 ; train accuracy 0.982922494\n",
      "Step 212 : train loss 3.96741416e-06 ; train accuracy 0.983003259\n",
      "Step 213 : train loss 1.71904667e-05 ; train accuracy 0.983083248\n",
      "Step 214 : train loss 4.54107885e-06 ; train accuracy 0.983162522\n",
      "Step 215 : train loss 2.35809921e-06 ; train accuracy 0.983241\n",
      "Step 216 : train loss 5.09615165e-06 ; train accuracy 0.983318806\n",
      "Step 217 : train loss 4.615531e-06 ; train accuracy 0.983395875\n",
      "Step 218 : train loss 6.96613552e-06 ; train accuracy 0.983472288\n",
      "Step 219 : train loss 1.36926546e-05 ; train accuracy 0.983547926\n",
      "Step 220 : train loss 3.22981373e-06 ; train accuracy 0.983622909\n",
      "Step 221 : train loss 3.38254335e-06 ; train accuracy 0.983697176\n",
      "Step 222 : train loss 2.94668666e-06 ; train accuracy 0.983770788\n",
      "Step 223 : train loss 3.90407786e-06 ; train accuracy 0.983843803\n",
      "Step 224 : train loss 6.99593056e-06 ; train accuracy 0.983916104\n",
      "Step 225 : train loss 4.41071279e-06 ; train accuracy 0.983987749\n",
      "Step 226 : train loss 1.11751433e-05 ; train accuracy 0.984058797\n",
      "Step 227 : train loss 8.22525544e-06 ; train accuracy 0.98412919\n",
      "Step 228 : train loss 4.5522479e-06 ; train accuracy 0.984198928\n",
      "Step 229 : train loss 8.78766059e-06 ; train accuracy 0.984268129\n",
      "Step 230 : train loss 2.66356938e-06 ; train accuracy 0.984336674\n",
      "Step 231 : train loss 3.7699424e-06 ; train accuracy 0.984404683\n",
      "Step 232 : train loss 2.42515466e-06 ; train accuracy 0.984472036\n",
      "Step 233 : train loss 2.50337553e-06 ; train accuracy 0.984538853\n",
      "Step 234 : train loss 5.09236861e-06 ; train accuracy 0.984605074\n",
      "Step 235 : train loss 4.07544348e-06 ; train accuracy 0.984670758\n",
      "Step 236 : train loss 1.38208e-06 ; train accuracy 0.984735847\n",
      "Step 237 : train loss 1.92969401e-06 ; train accuracy 0.984800398\n",
      "Step 238 : train loss 4.58577961e-06 ; train accuracy 0.984864414\n",
      "Step 239 : train loss 1.76205231e-06 ; train accuracy 0.984927893\n",
      "Step 240 : train loss 1.32247442e-06 ; train accuracy 0.984990835\n",
      "Step 241 : train loss 1.91478807e-06 ; train accuracy 0.985053301\n",
      "Step 242 : train loss 2.12713371e-06 ; train accuracy 0.98511517\n",
      "Step 243 : train loss 1.97439067e-06 ; train accuracy 0.985176563\n",
      "Step 244 : train loss 1.60559625e-06 ; train accuracy 0.985237479\n",
      "Step 245 : train loss 2.13458384e-06 ; train accuracy 0.985297859\n",
      "Step 246 : train loss 2.17183242e-06 ; train accuracy 0.985357761\n",
      "Step 247 : train loss 1.6540248e-06 ; train accuracy 0.985417187\n",
      "Step 248 : train loss 1.18836556e-06 ; train accuracy 0.985476136\n",
      "Step 249 : train loss 1.02072659e-06 ; train accuracy 0.985534608\n",
      "Step 250 : train loss 1.97439795e-06 ; train accuracy 0.985592604\n",
      "Step 251 : train loss 1.084058e-06 ; train accuracy 0.985650122\n",
      "Step 252 : train loss 7.9348581e-07 ; train accuracy 0.985707164\n",
      "Step 253 : train loss 2.07124549e-06 ; train accuracy 0.985763788\n",
      "Step 254 : train loss 7.97211101e-07 ; train accuracy 0.98582\n",
      "Step 255 : train loss 2.60022034e-06 ; train accuracy 0.985875726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 256 : train loss 6.81727329e-07 ; train accuracy 0.985931\n",
      "Step 257 : train loss 4.55207737e-06 ; train accuracy 0.985985875\n",
      "Step 258 : train loss 3.23351719e-06 ; train accuracy 0.986040294\n",
      "Step 259 : train loss 8.23288303e-07 ; train accuracy 0.986094296\n",
      "Step 260 : train loss 1.15856233e-06 ; train accuracy 0.98614794\n",
      "Step 261 : train loss 1.16228875e-06 ; train accuracy 0.986201108\n",
      "Step 262 : train loss 8.60540183e-07 ; train accuracy 0.986253858\n",
      "Step 263 : train loss 1.15856085e-06 ; train accuracy 0.98630625\n",
      "Step 264 : train loss 8.30738543e-07 ; train accuracy 0.986358225\n",
      "Step 265 : train loss 9.23870687e-07 ; train accuracy 0.986409843\n",
      "Step 266 : train loss 1.65402139e-06 ; train accuracy 0.986461043\n",
      "Step 267 : train loss 1.07660333e-06 ; train accuracy 0.986511827\n",
      "Step 268 : train loss 1.0132751e-06 ; train accuracy 0.986562252\n",
      "Step 269 : train loss 6.0349646e-07 ; train accuracy 0.98661232\n",
      "Step 270 : train loss 5.550678e-07 ; train accuracy 0.98666203\n",
      "Step 271 : train loss 3.16649562e-07 ; train accuracy 0.986711323\n",
      "Step 272 : train loss 7.0035361e-07 ; train accuracy 0.986760318\n",
      "Step 273 : train loss 4.88012688e-07 ; train accuracy 0.986808896\n",
      "Step 274 : train loss 5.92320589e-07 ; train accuracy 0.986857116\n",
      "Step 275 : train loss 1.00582611e-06 ; train accuracy 0.986905038\n",
      "Step 276 : train loss 3.65078222e-07 ; train accuracy 0.986952603\n",
      "Step 277 : train loss 4.7311147e-07 ; train accuracy 0.98699975\n",
      "Step 278 : train loss 8.53090171e-07 ; train accuracy 0.987046659\n",
      "Step 279 : train loss 3.87429878e-07 ; train accuracy 0.987093151\n",
      "Step 280 : train loss 5.40166582e-07 ; train accuracy 0.987139344\n",
      "Step 281 : train loss 4.95462075e-07 ; train accuracy 0.98718518\n",
      "Step 282 : train loss 8.82891925e-07 ; train accuracy 0.987230718\n",
      "Step 283 : train loss 3.13288024e-06 ; train accuracy 0.987275958\n",
      "Step 284 : train loss 4.21323739e-06 ; train accuracy 0.98732084\n",
      "Step 285 : train loss 1.56461363e-06 ; train accuracy 0.987365425\n",
      "Step 286 : train loss 1.42304248e-06 ; train accuracy 0.987409651\n",
      "Step 287 : train loss 5.4016607e-07 ; train accuracy 0.98745364\n",
      "Step 288 : train loss 3.57627641e-07 ; train accuracy 0.98749727\n",
      "Step 289 : train loss 3.35275502e-07 ; train accuracy 0.987540603\n",
      "Step 290 : train loss 4.99188218e-07 ; train accuracy 0.987583697\n",
      "Step 291 : train loss 6.96628035e-07 ; train accuracy 0.987626433\n",
      "Step 292 : train loss 4.24682582e-07 ; train accuracy 0.987668872\n",
      "Step 293 : train loss 5.550678e-07 ; train accuracy 0.987711072\n",
      "Step 294 : train loss 3.35275729e-07 ; train accuracy 0.987752914\n",
      "Step 295 : train loss 3.42726537e-07 ; train accuracy 0.987794518\n",
      "Step 296 : train loss 2.42143784e-07 ; train accuracy 0.987835824\n",
      "Step 297 : train loss 2.57044945e-07 ; train accuracy 0.987876892\n",
      "Step 298 : train loss 2.34693189e-07 ; train accuracy 0.987917602\n",
      "Step 299 : train loss 6.59375246e-07 ; train accuracy 0.987958133\n",
      "Step 300 : train loss 6.03496233e-07 ; train accuracy 0.987998307\n",
      "Step 301 : train loss 5.81142842e-07 ; train accuracy 0.988038301\n",
      "Step 302 : train loss 5.21539846e-07 ; train accuracy 0.988077939\n",
      "Step 303 : train loss 2.71946078e-07 ; train accuracy 0.988117397\n",
      "Step 304 : train loss 2.19792028e-07 ; train accuracy 0.988156557\n",
      "Step 305 : train loss 3.65078165e-07 ; train accuracy 0.988195419\n",
      "Step 306 : train loss 3.76253752e-07 ; train accuracy 0.988234103\n",
      "Step 307 : train loss 1.00582817e-07 ; train accuracy 0.988272488\n",
      "Step 308 : train loss 4.99188104e-07 ; train accuracy 0.988310635\n",
      "Step 309 : train loss 2.86847069e-07 ; train accuracy 0.988348544\n",
      "Step 310 : train loss 1.04308114e-07 ; train accuracy 0.988386214\n",
      "Step 311 : train loss 4.54484734e-07 ; train accuracy 0.988423586\n",
      "Step 312 : train loss 5.9977026e-07 ; train accuracy 0.988460779\n",
      "Step 313 : train loss 8.34458888e-07 ; train accuracy 0.988497674\n",
      "Step 314 : train loss 3.68803455e-07 ; train accuracy 0.988534391\n",
      "Step 315 : train loss 2.1606678e-07 ; train accuracy 0.988570869\n",
      "Step 316 : train loss 2.45869046e-07 ; train accuracy 0.988607109\n",
      "Step 317 : train loss 9.3132229e-08 ; train accuracy 0.98864311\n",
      "Step 318 : train loss 2.38418394e-07 ; train accuracy 0.988678873\n",
      "Step 319 : train loss 7.04077593e-07 ; train accuracy 0.988714397\n",
      "Step 320 : train loss 7.22704385e-07 ; train accuracy 0.988749743\n",
      "Step 321 : train loss 2.16066653e-07 ; train accuracy 0.98878485\n",
      "Step 322 : train loss 1.37835684e-07 ; train accuracy 0.988819778\n",
      "Step 323 : train loss 1.34110422e-07 ; train accuracy 0.988854408\n",
      "Step 324 : train loss 6.92900926e-07 ; train accuracy 0.98888886\n",
      "Step 325 : train loss 2.71945964e-07 ; train accuracy 0.988923132\n",
      "Step 326 : train loss 8.38185429e-07 ; train accuracy 0.988957167\n",
      "Step 327 : train loss 2.19792042e-07 ; train accuracy 0.988991\n",
      "Step 328 : train loss 3.20374795e-07 ; train accuracy 0.989024639\n",
      "Step 329 : train loss 2.49594336e-07 ; train accuracy 0.989058\n",
      "Step 330 : train loss 1.34110394e-07 ; train accuracy 0.989091277\n",
      "Step 331 : train loss 1.82539154e-07 ; train accuracy 0.989124238\n",
      "Step 332 : train loss 5.14089379e-07 ; train accuracy 0.989157081\n",
      "Step 333 : train loss 2.08616171e-07 ; train accuracy 0.989189684\n",
      "Step 334 : train loss 1.20697803e-06 ; train accuracy 0.989222109\n",
      "Step 335 : train loss 5.25264e-07 ; train accuracy 0.989254355\n",
      "Step 336 : train loss 3.16649221e-07 ; train accuracy 0.989286363\n",
      "Step 337 : train loss 1.49011555e-07 ; train accuracy 0.989318252\n",
      "Step 338 : train loss 2.83121892e-07 ; train accuracy 0.989349902\n",
      "Step 339 : train loss 1.45286265e-07 ; train accuracy 0.989381373\n",
      "Step 340 : train loss 1.35970663e-06 ; train accuracy 0.989412606\n",
      "Step 341 : train loss 4.20957036e-07 ; train accuracy 0.989443719\n",
      "Step 342 : train loss 3.27817907e-06 ; train accuracy 0.989474654\n",
      "Step 343 : train loss 8.19560569e-07 ; train accuracy 0.98950541\n",
      "Step 344 : train loss 3.57627243e-07 ; train accuracy 0.989535928\n",
      "Step 345 : train loss 9.38766448e-07 ; train accuracy 0.989566326\n",
      "Step 346 : train loss 1.61783944e-07 ; train accuracy 0.989579558\n",
      "val loss 1.98682116e-07 ; val accuracy 1\n",
      "Step 347 : train loss 2.12341462e-07 ; train accuracy 0.989609659\n",
      "Step 348 : train loss 1.01699345e-06 ; train accuracy 0.98963964\n",
      "Step 349 : train loss 2.53319513e-07 ; train accuracy 0.989669442\n",
      "Step 350 : train loss 1.52736874e-07 ; train accuracy 0.989699\n",
      "Step 351 : train loss 1.89989521e-07 ; train accuracy 0.989728451\n",
      "Step 352 : train loss 1.88124909e-06 ; train accuracy 0.989757776\n",
      "Step 353 : train loss 4.43308693e-07 ; train accuracy 0.989786863\n",
      "Step 354 : train loss 1.49011527e-07 ; train accuracy 0.989815772\n",
      "Step 355 : train loss 4.54484535e-07 ; train accuracy 0.989844561\n",
      "Step 356 : train loss 1.34110394e-07 ; train accuracy 0.989873171\n",
      "Step 357 : train loss 1.34110337e-07 ; train accuracy 0.989901662\n",
      "Step 358 : train loss 1.7136324e-07 ; train accuracy 0.98993\n",
      "Step 359 : train loss 2.9802257e-07 ; train accuracy 0.989958107\n",
      "Step 360 : train loss 1.15483971e-07 ; train accuracy 0.989986062\n",
      "Step 361 : train loss 1.08033397e-07 ; train accuracy 0.990013897\n",
      "Step 362 : train loss 1.00582824e-07 ; train accuracy 0.990041554\n",
      "Step 363 : train loss 7.82310821e-08 ; train accuracy 0.990069091\n",
      "Step 364 : train loss 8.56816627e-08 ; train accuracy 0.99009645\n",
      "Step 365 : train loss 5.21540571e-08 ; train accuracy 0.990123689\n",
      "Step 366 : train loss 1.75088559e-07 ; train accuracy 0.99015075\n",
      "Step 367 : train loss 1.30385047e-07 ; train accuracy 0.990177631\n",
      "Step 368 : train loss 1.45286265e-07 ; train accuracy 0.990204453\n",
      "Step 369 : train loss 6.70552041e-08 ; train accuracy 0.990231037\n",
      "Step 370 : train loss 1.19209261e-07 ; train accuracy 0.990257561\n",
      "Step 371 : train loss 1.78813792e-07 ; train accuracy 0.990283906\n",
      "Step 372 : train loss 8.19563368e-08 ; train accuracy 0.990310073\n",
      "Step 373 : train loss 6.70552183e-08 ; train accuracy 0.99033612\n",
      "Step 374 : train loss 3.35276091e-08 ; train accuracy 0.990362048\n",
      "Step 375 : train loss 8.19563724e-08 ; train accuracy 0.990387857\n",
      "Step 376 : train loss 1.26659799e-07 ; train accuracy 0.990413487\n",
      "Step 377 : train loss 6.70552112e-08 ; train accuracy 0.990439\n",
      "Step 378 : train loss 5.58793474e-08 ; train accuracy 0.99046433\n",
      "Step 379 : train loss 1.00582803e-07 ; train accuracy 0.990489602\n",
      "Step 380 : train loss 1.19209247e-07 ; train accuracy 0.990514696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 381 : train loss 1.04308086e-07 ; train accuracy 0.99053967\n",
      "Step 382 : train loss 1.60187398e-07 ; train accuracy 0.990564466\n",
      "Step 383 : train loss 7.82310821e-08 ; train accuracy 0.990589201\n",
      "Step 384 : train loss 7.45057918e-08 ; train accuracy 0.990613759\n",
      "Step 385 : train loss 3.72529e-08 ; train accuracy 0.990638256\n",
      "Step 386 : train loss 2.60770303e-08 ; train accuracy 0.990662575\n",
      "Step 387 : train loss 1.93714982e-07 ; train accuracy 0.990686774\n",
      "Step 388 : train loss 3.35276091e-08 ; train accuracy 0.990710795\n",
      "Step 389 : train loss 5.58793403e-08 ; train accuracy 0.990734756\n",
      "Step 390 : train loss 8.94069103e-08 ; train accuracy 0.990758598\n",
      "Step 391 : train loss 1.04308107e-07 ; train accuracy 0.99078232\n",
      "Step 392 : train loss 5.21540571e-08 ; train accuracy 0.990805864\n",
      "Step 393 : train loss 1.7508853e-07 ; train accuracy 0.990829349\n",
      "Step 394 : train loss 4.47034765e-08 ; train accuracy 0.990852714\n",
      "Step 395 : train loss 9.31322433e-08 ; train accuracy 0.9908759\n",
      "Step 396 : train loss 2.30967728e-07 ; train accuracy 0.990899\n",
      "Step 397 : train loss 1.117587e-08 ; train accuracy 0.990922034\n",
      "Step 398 : train loss 9.68575122e-08 ; train accuracy 0.990944862\n",
      "Step 399 : train loss 6.33299209e-08 ; train accuracy 0.990967631\n",
      "Step 400 : train loss 9.31322148e-08 ; train accuracy 0.990990281\n",
      "Step 401 : train loss 8.94069245e-08 ; train accuracy 0.991012812\n",
      "Step 402 : train loss 9.68574909e-08 ; train accuracy 0.991035223\n",
      "Step 403 : train loss 8.19563795e-08 ; train accuracy 0.991057515\n",
      "Step 404 : train loss 7.8231075e-08 ; train accuracy 0.991079748\n",
      "Step 405 : train loss 7.45058e-08 ; train accuracy 0.991101801\n",
      "Step 406 : train loss 2.98023188e-08 ; train accuracy 0.991123796\n",
      "Step 407 : train loss 7.07805e-08 ; train accuracy 0.99114567\n",
      "Step 408 : train loss 1.15483971e-07 ; train accuracy 0.991167426\n",
      "Step 409 : train loss 4.470348e-08 ; train accuracy 0.991189063\n",
      "Step 410 : train loss 4.09781897e-08 ; train accuracy 0.991210639\n",
      "Step 411 : train loss 6.3329928e-08 ; train accuracy 0.991232097\n",
      "Step 412 : train loss 5.96046235e-08 ; train accuracy 0.991253436\n",
      "Step 413 : train loss 7.45057847e-08 ; train accuracy 0.991274655\n",
      "Step 414 : train loss 7.82310536e-08 ; train accuracy 0.991295815\n",
      "Step 415 : train loss 7.07805e-08 ; train accuracy 0.991316795\n",
      "Step 416 : train loss 3.01748116e-07 ; train accuracy 0.991337776\n",
      "Step 417 : train loss 7.82310821e-08 ; train accuracy 0.991358578\n",
      "Step 418 : train loss 6.33299209e-08 ; train accuracy 0.991379321\n",
      "Step 419 : train loss 8.19563652e-08 ; train accuracy 0.991399944\n",
      "Step 420 : train loss 1.41560861e-07 ; train accuracy 0.991420448\n",
      "Step 421 : train loss 5.58793474e-08 ; train accuracy 0.991440892\n",
      "Step 422 : train loss 7.07805e-08 ; train accuracy 0.991461217\n",
      "Step 423 : train loss 1.56462136e-07 ; train accuracy 0.991481483\n",
      "Step 424 : train loss 2.60770303e-08 ; train accuracy 0.991501629\n",
      "Step 425 : train loss 4.470348e-08 ; train accuracy 0.991521657\n",
      "Step 426 : train loss 1.08033397e-07 ; train accuracy 0.991541624\n",
      "Step 427 : train loss 1.86264497e-08 ; train accuracy 0.991561472\n",
      "Step 428 : train loss 7.82310678e-08 ; train accuracy 0.991581261\n",
      "Step 429 : train loss 4.09781897e-08 ; train accuracy 0.991600931\n",
      "Step 430 : train loss 2.235174e-08 ; train accuracy 0.991620541\n",
      "Step 431 : train loss 1.117587e-08 ; train accuracy 0.991640031\n",
      "Step 432 : train loss 2.60770303e-08 ; train accuracy 0.991659403\n",
      "Step 433 : train loss 8.94069458e-08 ; train accuracy 0.991678715\n",
      "Step 434 : train loss 4.47034765e-08 ; train accuracy 0.991697967\n",
      "Step 435 : train loss 8.56816555e-08 ; train accuracy 0.9917171\n",
      "Step 436 : train loss 2.235174e-08 ; train accuracy 0.991736114\n",
      "Step 437 : train loss 4.47034765e-08 ; train accuracy 0.991755068\n",
      "Step 438 : train loss 4.09781897e-08 ; train accuracy 0.991773963\n",
      "Step 439 : train loss 5.58793403e-08 ; train accuracy 0.991792738\n",
      "Step 440 : train loss 4.47034765e-08 ; train accuracy 0.991811454\n",
      "Step 441 : train loss 5.96046377e-08 ; train accuracy 0.991830051\n",
      "Step 442 : train loss 6.70552112e-08 ; train accuracy 0.991848588\n",
      "Step 443 : train loss 2.60770285e-08 ; train accuracy 0.991867065\n",
      "Step 444 : train loss 2.60770303e-08 ; train accuracy 0.991885424\n",
      "Step 445 : train loss 3.35276091e-08 ; train accuracy 0.991903663\n",
      "Step 446 : train loss 2.60770303e-08 ; train accuracy 0.991921902\n",
      "Step 447 : train loss 3.35276091e-08 ; train accuracy 0.99194\n",
      "Step 448 : train loss 9.3132229e-08 ; train accuracy 0.991958\n",
      "Step 449 : train loss 1.86264497e-08 ; train accuracy 0.991976\n",
      "Step 450 : train loss 2.98023188e-08 ; train accuracy 0.991993845\n",
      "Step 451 : train loss 7.45057918e-08 ; train accuracy 0.992011666\n",
      "Step 452 : train loss 9.68575193e-08 ; train accuracy 0.992029369\n",
      "Step 453 : train loss 3.72529e-08 ; train accuracy 0.992047\n",
      "Step 454 : train loss 5.215405e-08 ; train accuracy 0.992064595\n",
      "Step 455 : train loss 5.21540571e-08 ; train accuracy 0.992082059\n",
      "Step 456 : train loss 2.23517382e-08 ; train accuracy 0.992099464\n",
      "Step 457 : train loss 4.84287668e-08 ; train accuracy 0.992116809\n",
      "Step 458 : train loss 2.60770285e-08 ; train accuracy 0.992134035\n",
      "Step 459 : train loss 4.470348e-08 ; train accuracy 0.99215126\n",
      "Step 460 : train loss 7.82310678e-08 ; train accuracy 0.992168367\n",
      "Step 461 : train loss 5.58793403e-08 ; train accuracy 0.992185354\n",
      "Step 462 : train loss 3.35276056e-08 ; train accuracy 0.992202342\n",
      "Step 463 : train loss 5.21540535e-08 ; train accuracy 0.99221921\n",
      "Step 464 : train loss 7.45057918e-08 ; train accuracy 0.992236\n",
      "Step 465 : train loss 8.19563724e-08 ; train accuracy 0.992252767\n",
      "Step 466 : train loss 3.35276091e-08 ; train accuracy 0.992269456\n",
      "Step 467 : train loss 3.35276056e-08 ; train accuracy 0.992286\n",
      "Step 468 : train loss 5.21540571e-08 ; train accuracy 0.992302537\n",
      "Step 469 : train loss 5.21540571e-08 ; train accuracy 0.992319\n",
      "Step 470 : train loss 2.98023206e-08 ; train accuracy 0.992335379\n",
      "Step 471 : train loss 4.47034765e-08 ; train accuracy 0.992351711\n",
      "Step 472 : train loss 6.70552112e-08 ; train accuracy 0.992367923\n",
      "Step 473 : train loss 1.11758638e-07 ; train accuracy 0.992384136\n",
      "Step 474 : train loss 4.47034765e-08 ; train accuracy 0.992400229\n",
      "Step 475 : train loss 3.35276056e-08 ; train accuracy 0.992416263\n",
      "Step 476 : train loss 3.72529e-08 ; train accuracy 0.992432237\n",
      "Step 477 : train loss 3.72529e-08 ; train accuracy 0.992448151\n",
      "Step 478 : train loss 1.86264174e-07 ; train accuracy 0.992463946\n",
      "Step 479 : train loss 2.235174e-08 ; train accuracy 0.992479742\n",
      "Step 480 : train loss 2.98023188e-08 ; train accuracy 0.992495418\n",
      "Step 481 : train loss 5.21540535e-08 ; train accuracy 0.992511094\n",
      "Step 482 : train loss 1.86264497e-08 ; train accuracy 0.99252665\n",
      "Step 483 : train loss 2.98023188e-08 ; train accuracy 0.992542148\n",
      "Step 484 : train loss 1.49011603e-08 ; train accuracy 0.992557585\n",
      "Step 485 : train loss 1.86264497e-08 ; train accuracy 0.992572963\n",
      "Step 486 : train loss 1.52736789e-07 ; train accuracy 0.992588282\n",
      "Step 487 : train loss 1.11758638e-07 ; train accuracy 0.99260354\n",
      "Step 488 : train loss 2.23517382e-08 ; train accuracy 0.99261874\n",
      "Step 489 : train loss 2.235174e-08 ; train accuracy 0.992633879\n",
      "Step 490 : train loss 3.35276091e-08 ; train accuracy 0.992648959\n",
      "Step 491 : train loss 2.60770285e-08 ; train accuracy 0.99266392\n",
      "Step 492 : train loss 5.96046377e-08 ; train accuracy 0.992678881\n",
      "Step 493 : train loss 5.96046377e-08 ; train accuracy 0.992693782\n",
      "Step 494 : train loss 9.68575193e-08 ; train accuracy 0.992708623\n",
      "Step 495 : train loss 1.34110323e-07 ; train accuracy 0.992723346\n",
      "Step 496 : train loss 1.08033376e-07 ; train accuracy 0.992738068\n",
      "Step 497 : train loss 7.07804872e-08 ; train accuracy 0.992752731\n",
      "Step 498 : train loss 4.47034765e-08 ; train accuracy 0.992767274\n",
      "Step 499 : train loss 1.49011603e-08 ; train accuracy 0.992781818\n",
      "Step 500 : train loss 3.72529e-08 ; train accuracy 0.992796302\n",
      "Step 501 : train loss 7.45057918e-08 ; train accuracy 0.992810726\n",
      "Step 502 : train loss 5.21540571e-08 ; train accuracy 0.992825031\n",
      "Step 503 : train loss 4.47034765e-08 ; train accuracy 0.992839336\n",
      "Step 504 : train loss 4.09781897e-08 ; train accuracy 0.992853582\n",
      "Step 505 : train loss 1.49011603e-08 ; train accuracy 0.992867768\n",
      "Step 506 : train loss 4.09781862e-08 ; train accuracy 0.992881894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 507 : train loss 4.47034765e-08 ; train accuracy 0.992895961\n",
      "Step 508 : train loss 1.30385118e-07 ; train accuracy 0.992909968\n",
      "Step 509 : train loss 3.35276091e-08 ; train accuracy 0.992924\n",
      "Step 510 : train loss 1.86264497e-08 ; train accuracy 0.992937863\n",
      "Step 511 : train loss 2.98023188e-08 ; train accuracy 0.992951691\n",
      "Step 512 : train loss 5.96046164e-08 ; train accuracy 0.992965519\n",
      "Step 513 : train loss 6.3329928e-08 ; train accuracy 0.992979228\n",
      "Step 514 : train loss 7.07804659e-08 ; train accuracy 0.992992938\n",
      "Step 515 : train loss 1.117587e-08 ; train accuracy 0.993006587\n",
      "Step 516 : train loss 3.35276056e-08 ; train accuracy 0.993020177\n",
      "Step 517 : train loss 9.31321864e-08 ; train accuracy 0.993033707\n",
      "Step 518 : train loss 7.45058e-09 ; train accuracy 0.993047178\n",
      "Step 519 : train loss 1.70298975e-08 ; train accuracy 0.993053\n",
      "val loss 3.97364275e-08 ; val accuracy 1\n",
      "Step 520 : train loss 1.117587e-08 ; train accuracy 0.99306643\n",
      "Step 521 : train loss 2.235174e-08 ; train accuracy 0.993079782\n",
      "Step 522 : train loss 7.45058e-09 ; train accuracy 0.993093073\n",
      "Step 523 : train loss 7.07805e-08 ; train accuracy 0.993106365\n",
      "Step 524 : train loss 1.60187312e-07 ; train accuracy 0.993119538\n",
      "Step 525 : train loss 0 ; train accuracy 0.99313271\n",
      "Step 526 : train loss 8.19563581e-08 ; train accuracy 0.993145764\n",
      "Step 527 : train loss 5.21540571e-08 ; train accuracy 0.993158817\n",
      "Step 528 : train loss 4.09781862e-08 ; train accuracy 0.993171811\n",
      "Step 529 : train loss 1.19209147e-07 ; train accuracy 0.993184805\n",
      "Step 530 : train loss 1.49011594e-08 ; train accuracy 0.99319768\n",
      "Step 531 : train loss 3.35276091e-08 ; train accuracy 0.993210554\n",
      "Step 532 : train loss 3.72528959e-08 ; train accuracy 0.99322331\n",
      "Step 533 : train loss 2.60770285e-08 ; train accuracy 0.993236065\n",
      "Step 534 : train loss 3.72529e-08 ; train accuracy 0.99324882\n",
      "Step 535 : train loss 1.30385018e-07 ; train accuracy 0.993261456\n",
      "Step 536 : train loss 2.60770285e-08 ; train accuracy 0.993274093\n",
      "Step 537 : train loss 1.86264497e-08 ; train accuracy 0.99328661\n",
      "Step 538 : train loss 1.86264497e-08 ; train accuracy 0.993299127\n",
      "Step 539 : train loss 3.72529e-08 ; train accuracy 0.993311644\n",
      "Step 540 : train loss 2.23517382e-08 ; train accuracy 0.993324041\n",
      "Step 541 : train loss 2.98023188e-08 ; train accuracy 0.993336439\n",
      "Step 542 : train loss 1.117587e-08 ; train accuracy 0.993348777\n",
      "Step 543 : train loss 1.117587e-08 ; train accuracy 0.993361056\n",
      "Step 544 : train loss 7.45058e-09 ; train accuracy 0.993373275\n",
      "Step 545 : train loss 1.117587e-08 ; train accuracy 0.993385494\n",
      "Step 546 : train loss 1.117587e-08 ; train accuracy 0.993397653\n",
      "Step 547 : train loss 2.235174e-08 ; train accuracy 0.993409753\n",
      "Step 548 : train loss 8.56816058e-08 ; train accuracy 0.993421793\n",
      "Step 549 : train loss 2.98023188e-08 ; train accuracy 0.993433833\n",
      "Step 550 : train loss 2.98023188e-08 ; train accuracy 0.993445814\n",
      "Step 551 : train loss 1.49011603e-08 ; train accuracy 0.993457735\n",
      "Step 552 : train loss 3.35276091e-08 ; train accuracy 0.993469596\n",
      "Step 553 : train loss 3.35276091e-08 ; train accuracy 0.993481457\n",
      "Step 554 : train loss 4.09781897e-08 ; train accuracy 0.993493259\n",
      "Step 555 : train loss 1.11758659e-07 ; train accuracy 0.993505\n",
      "Step 556 : train loss 4.09781755e-08 ; train accuracy 0.993516743\n",
      "Step 557 : train loss 2.235174e-08 ; train accuracy 0.993528426\n",
      "Step 558 : train loss 1.86264497e-08 ; train accuracy 0.993540049\n",
      "Step 559 : train loss 3.72529e-09 ; train accuracy 0.993551672\n",
      "Step 560 : train loss 2.98023153e-08 ; train accuracy 0.993563175\n",
      "Step 561 : train loss 5.215405e-08 ; train accuracy 0.993574679\n",
      "Step 562 : train loss 6.70552112e-08 ; train accuracy 0.993586183\n",
      "Step 563 : train loss 1.86264497e-08 ; train accuracy 0.993597567\n",
      "Step 564 : train loss 1.86264497e-08 ; train accuracy 0.993608952\n",
      "Step 565 : train loss 2.23517382e-08 ; train accuracy 0.993620336\n",
      "Step 566 : train loss 1.117587e-08 ; train accuracy 0.993631661\n",
      "Step 567 : train loss 1.86264497e-08 ; train accuracy 0.993642926\n",
      "Step 568 : train loss 2.235174e-08 ; train accuracy 0.993654132\n",
      "Step 569 : train loss 1.117587e-08 ; train accuracy 0.993665338\n",
      "Step 570 : train loss 7.45057918e-08 ; train accuracy 0.993676484\n",
      "Step 571 : train loss 2.235174e-08 ; train accuracy 0.99368757\n",
      "Step 572 : train loss 2.235174e-08 ; train accuracy 0.993698657\n",
      "Step 573 : train loss 4.09781897e-08 ; train accuracy 0.993709683\n",
      "Step 574 : train loss 8.94069103e-08 ; train accuracy 0.993720651\n",
      "Step 575 : train loss 9.3132158e-08 ; train accuracy 0.993731618\n",
      "Step 576 : train loss 3.35276091e-08 ; train accuracy 0.993742526\n",
      "Step 577 : train loss 5.58793438e-08 ; train accuracy 0.993753374\n",
      "Step 578 : train loss 1.49011603e-08 ; train accuracy 0.993764222\n",
      "Step 579 : train loss 2.235174e-08 ; train accuracy 0.993775\n",
      "Step 580 : train loss 1.49011603e-08 ; train accuracy 0.993785799\n",
      "Step 581 : train loss 2.23517382e-08 ; train accuracy 0.993796527\n",
      "Step 582 : train loss 1.117587e-08 ; train accuracy 0.993807197\n",
      "Step 583 : train loss 5.21540606e-08 ; train accuracy 0.993817866\n",
      "Step 584 : train loss 1.49011603e-08 ; train accuracy 0.993828475\n",
      "Step 585 : train loss 2.98023188e-08 ; train accuracy 0.993839085\n",
      "Step 586 : train loss 2.98023188e-08 ; train accuracy 0.993849635\n",
      "Step 587 : train loss 1.49011594e-08 ; train accuracy 0.993860126\n",
      "Step 588 : train loss 6.33299138e-08 ; train accuracy 0.993870616\n",
      "Step 589 : train loss 5.58793332e-08 ; train accuracy 0.993881047\n",
      "Step 590 : train loss 1.86264497e-08 ; train accuracy 0.993891418\n",
      "Step 591 : train loss 2.98023206e-08 ; train accuracy 0.993901789\n",
      "Step 592 : train loss 3.72529e-08 ; train accuracy 0.993912101\n",
      "Step 593 : train loss 8.94068961e-08 ; train accuracy 0.993922412\n",
      "Step 594 : train loss 1.49011594e-08 ; train accuracy 0.993932664\n",
      "Step 595 : train loss 4.47034765e-08 ; train accuracy 0.993942916\n",
      "Step 596 : train loss 3.72529e-09 ; train accuracy 0.993953109\n",
      "Step 597 : train loss 2.235174e-08 ; train accuracy 0.993963242\n",
      "Step 598 : train loss 2.60770303e-08 ; train accuracy 0.993973374\n",
      "Step 599 : train loss 1.86264497e-08 ; train accuracy 0.993983448\n",
      "Step 600 : train loss 2.98023188e-08 ; train accuracy 0.993993521\n",
      "Step 601 : train loss 3.35276091e-08 ; train accuracy 0.994003534\n",
      "Step 602 : train loss 2.98023188e-08 ; train accuracy 0.994013548\n",
      "Step 603 : train loss 3.35276091e-08 ; train accuracy 0.994023502\n",
      "Step 604 : train loss 2.98023188e-08 ; train accuracy 0.994033396\n",
      "Step 605 : train loss 1.86264497e-08 ; train accuracy 0.994043291\n",
      "Step 606 : train loss 3.72529e-08 ; train accuracy 0.994053185\n",
      "Step 607 : train loss 1.117587e-08 ; train accuracy 0.99406296\n",
      "Step 608 : train loss 2.60770303e-08 ; train accuracy 0.994072795\n",
      "Step 609 : train loss 3.72529e-09 ; train accuracy 0.99408251\n",
      "Step 610 : train loss 2.23517382e-08 ; train accuracy 0.994092286\n",
      "Step 611 : train loss 4.47034729e-08 ; train accuracy 0.994101942\n",
      "Step 612 : train loss 7.45058e-09 ; train accuracy 0.994111598\n",
      "Step 613 : train loss 4.470348e-08 ; train accuracy 0.994121253\n",
      "Step 614 : train loss 4.47034765e-08 ; train accuracy 0.99413085\n",
      "Step 615 : train loss 7.45058e-09 ; train accuracy 0.994140446\n",
      "Step 616 : train loss 1.86264497e-08 ; train accuracy 0.99415\n",
      "Step 617 : train loss 1.86264497e-08 ; train accuracy 0.99415946\n",
      "Step 618 : train loss 1.49011603e-08 ; train accuracy 0.994168937\n",
      "Step 619 : train loss 2.98023171e-08 ; train accuracy 0.994178414\n",
      "Step 620 : train loss 1.86264497e-08 ; train accuracy 0.994187832\n",
      "Step 621 : train loss 2.60770285e-08 ; train accuracy 0.99419719\n",
      "Step 622 : train loss 3.72529e-09 ; train accuracy 0.994206548\n",
      "Step 623 : train loss 5.21540571e-08 ; train accuracy 0.994215846\n",
      "Step 624 : train loss 3.72529e-09 ; train accuracy 0.994225144\n",
      "Step 625 : train loss 2.235174e-08 ; train accuracy 0.994234443\n",
      "Step 626 : train loss 0 ; train accuracy 0.994243681\n",
      "Step 627 : train loss 2.235174e-08 ; train accuracy 0.994252861\n",
      "Step 628 : train loss 7.07804659e-08 ; train accuracy 0.99426204\n",
      "Step 629 : train loss 3.72529e-08 ; train accuracy 0.994271219\n",
      "Step 630 : train loss 3.72529e-09 ; train accuracy 0.994280338\n",
      "Step 631 : train loss 5.96046377e-08 ; train accuracy 0.994289398\n",
      "Step 632 : train loss 5.21540571e-08 ; train accuracy 0.994298458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 633 : train loss 2.60770285e-08 ; train accuracy 0.994307518\n",
      "Step 634 : train loss 1.49011594e-08 ; train accuracy 0.994316518\n",
      "Step 635 : train loss 1.117587e-08 ; train accuracy 0.994325459\n",
      "Step 636 : train loss 3.35276091e-08 ; train accuracy 0.9943344\n",
      "Step 637 : train loss 2.235174e-08 ; train accuracy 0.99434334\n",
      "Step 638 : train loss 3.72529e-09 ; train accuracy 0.994352221\n",
      "Step 639 : train loss 2.98023188e-08 ; train accuracy 0.994361103\n",
      "Step 640 : train loss 2.23517382e-08 ; train accuracy 0.994369924\n",
      "Step 641 : train loss 2.98023188e-08 ; train accuracy 0.994378746\n",
      "Step 642 : train loss 5.58793225e-08 ; train accuracy 0.994387507\n",
      "Step 643 : train loss 3.72529e-09 ; train accuracy 0.994396269\n",
      "Step 644 : train loss 2.60770285e-08 ; train accuracy 0.994405\n",
      "Step 645 : train loss 2.235174e-08 ; train accuracy 0.994413674\n",
      "Step 646 : train loss 1.117587e-08 ; train accuracy 0.994422376\n",
      "Step 647 : train loss 2.60770303e-08 ; train accuracy 0.994431\n",
      "Step 648 : train loss 1.49011594e-08 ; train accuracy 0.994439602\n",
      "Step 649 : train loss 7.45058e-09 ; train accuracy 0.994448185\n",
      "Step 650 : train loss 1.117587e-08 ; train accuracy 0.994456768\n",
      "Step 651 : train loss 1.86264479e-08 ; train accuracy 0.994465292\n",
      "Step 652 : train loss 3.35276091e-08 ; train accuracy 0.994473815\n",
      "Step 653 : train loss 5.58793403e-08 ; train accuracy 0.994482279\n",
      "Step 654 : train loss 1.86264497e-08 ; train accuracy 0.994490743\n",
      "Step 655 : train loss 1.86264497e-08 ; train accuracy 0.994499207\n",
      "Step 656 : train loss 1.117587e-08 ; train accuracy 0.994507611\n",
      "Step 657 : train loss 3.35276056e-08 ; train accuracy 0.994515955\n",
      "Step 658 : train loss 5.96046341e-08 ; train accuracy 0.99452436\n",
      "Step 659 : train loss 2.60770285e-08 ; train accuracy 0.994532645\n",
      "Step 660 : train loss 2.60770285e-08 ; train accuracy 0.994541\n",
      "Step 661 : train loss 7.45058e-09 ; train accuracy 0.994549274\n",
      "Step 662 : train loss 5.58793332e-08 ; train accuracy 0.9945575\n",
      "Step 663 : train loss 1.117587e-08 ; train accuracy 0.994565725\n",
      "Step 664 : train loss 1.86264497e-08 ; train accuracy 0.994573951\n",
      "Step 665 : train loss 7.45057633e-08 ; train accuracy 0.994582117\n",
      "Step 666 : train loss 4.84287668e-08 ; train accuracy 0.994590282\n",
      "Step 667 : train loss 1.86264497e-08 ; train accuracy 0.994598389\n",
      "Step 668 : train loss 2.98023188e-08 ; train accuracy 0.994606495\n",
      "Step 669 : train loss 1.49011594e-08 ; train accuracy 0.994614601\n",
      "Step 670 : train loss 1.117587e-08 ; train accuracy 0.994622648\n",
      "Step 671 : train loss 5.96046377e-08 ; train accuracy 0.994630694\n",
      "Step 672 : train loss 3.72528923e-08 ; train accuracy 0.994638681\n",
      "Step 673 : train loss 3.35276091e-08 ; train accuracy 0.994646668\n",
      "Step 674 : train loss 5.21540571e-08 ; train accuracy 0.994654655\n",
      "Step 675 : train loss 2.98023188e-08 ; train accuracy 0.994662583\n",
      "Step 676 : train loss 1.86264497e-08 ; train accuracy 0.99467051\n",
      "Step 677 : train loss 1.117587e-08 ; train accuracy 0.994678378\n",
      "Step 678 : train loss 2.60770285e-08 ; train accuracy 0.994686246\n",
      "Step 679 : train loss 1.49011603e-08 ; train accuracy 0.994694114\n",
      "Step 680 : train loss 4.84287632e-08 ; train accuracy 0.994701922\n",
      "Step 681 : train loss 4.84287668e-08 ; train accuracy 0.99470973\n",
      "Step 682 : train loss 7.07804872e-08 ; train accuracy 0.994717479\n",
      "Step 683 : train loss 3.72529e-09 ; train accuracy 0.994725227\n",
      "Step 684 : train loss 1.86264497e-08 ; train accuracy 0.994733\n",
      "Step 685 : train loss 1.86264497e-08 ; train accuracy 0.994740665\n",
      "Step 686 : train loss 2.98023188e-08 ; train accuracy 0.994748354\n",
      "Step 687 : train loss 2.235174e-08 ; train accuracy 0.994756043\n",
      "Step 688 : train loss 4.47034729e-08 ; train accuracy 0.994763672\n",
      "Step 689 : train loss 7.45058e-09 ; train accuracy 0.994771302\n",
      "Step 690 : train loss 1.49011603e-08 ; train accuracy 0.994778872\n",
      "Step 691 : train loss 2.60770285e-08 ; train accuracy 0.994786501\n",
      "Step 692 : train loss 8.51494875e-09 ; train accuracy 0.994789779\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 693 : train loss 5.96046235e-08 ; train accuracy 0.994797349\n",
      "Step 694 : train loss 1.86264497e-08 ; train accuracy 0.994804859\n",
      "Step 695 : train loss 1.86264479e-08 ; train accuracy 0.994812369\n",
      "Step 696 : train loss 3.72529e-08 ; train accuracy 0.99481982\n",
      "Step 697 : train loss 3.72529e-08 ; train accuracy 0.994827271\n",
      "Step 698 : train loss 1.49011603e-08 ; train accuracy 0.994834721\n",
      "Step 699 : train loss 1.117587e-08 ; train accuracy 0.994842112\n",
      "Step 700 : train loss 2.23517382e-08 ; train accuracy 0.994849503\n",
      "Step 701 : train loss 3.72528959e-08 ; train accuracy 0.994856894\n",
      "Step 702 : train loss 7.45058e-09 ; train accuracy 0.994864225\n",
      "Step 703 : train loss 7.45058e-09 ; train accuracy 0.994871557\n",
      "Step 704 : train loss 1.49011594e-08 ; train accuracy 0.994878888\n",
      "Step 705 : train loss 3.72529e-09 ; train accuracy 0.99488616\n",
      "Step 706 : train loss 3.35276091e-08 ; train accuracy 0.994893432\n",
      "Step 707 : train loss 3.35276056e-08 ; train accuracy 0.994900703\n",
      "Step 708 : train loss 4.84287597e-08 ; train accuracy 0.994907916\n",
      "Step 709 : train loss 2.60770285e-08 ; train accuracy 0.994915128\n",
      "Step 710 : train loss 2.23517382e-08 ; train accuracy 0.99492228\n",
      "Step 711 : train loss 1.117587e-08 ; train accuracy 0.994929433\n",
      "Step 712 : train loss 1.49011603e-08 ; train accuracy 0.994936585\n",
      "Step 713 : train loss 1.117587e-08 ; train accuracy 0.994943738\n",
      "Step 714 : train loss 1.117587e-08 ; train accuracy 0.994950831\n",
      "Step 715 : train loss 3.3527602e-08 ; train accuracy 0.994957924\n",
      "Step 716 : train loss 6.70551898e-08 ; train accuracy 0.994964957\n",
      "Step 717 : train loss 2.98023171e-08 ; train accuracy 0.994972\n",
      "Step 718 : train loss 1.49011594e-08 ; train accuracy 0.994979\n",
      "Step 719 : train loss 7.45057971e-09 ; train accuracy 0.994986057\n",
      "Step 720 : train loss 7.45058e-09 ; train accuracy 0.994993031\n",
      "Step 721 : train loss 7.45058e-09 ; train accuracy 0.995\n",
      "Step 722 : train loss 3.35276091e-08 ; train accuracy 0.995006919\n",
      "Step 723 : train loss 4.84287419e-08 ; train accuracy 0.995013893\n",
      "Step 724 : train loss 7.45057971e-09 ; train accuracy 0.995020807\n",
      "Step 725 : train loss 3.72528923e-08 ; train accuracy 0.995027661\n",
      "Step 726 : train loss 3.72529e-09 ; train accuracy 0.995034516\n",
      "Step 727 : train loss 4.84287597e-08 ; train accuracy 0.99504137\n",
      "Step 728 : train loss 1.117587e-08 ; train accuracy 0.995048225\n",
      "Step 729 : train loss 1.49011603e-08 ; train accuracy 0.995055\n",
      "Step 730 : train loss 1.49011594e-08 ; train accuracy 0.995061815\n",
      "Step 731 : train loss 2.235174e-08 ; train accuracy 0.99506861\n",
      "Step 732 : train loss 7.45058e-09 ; train accuracy 0.995075345\n",
      "Step 733 : train loss 1.117587e-08 ; train accuracy 0.99508208\n",
      "Step 734 : train loss 3.35276091e-08 ; train accuracy 0.995088816\n",
      "Step 735 : train loss 3.3527602e-08 ; train accuracy 0.995095551\n",
      "Step 736 : train loss 2.60770285e-08 ; train accuracy 0.995102227\n",
      "Step 737 : train loss 3.72529e-09 ; train accuracy 0.995108902\n",
      "Step 738 : train loss 1.117587e-08 ; train accuracy 0.995115519\n",
      "Step 739 : train loss 7.45058e-09 ; train accuracy 0.995122135\n",
      "Step 740 : train loss 3.35276091e-08 ; train accuracy 0.995128751\n",
      "Step 741 : train loss 1.49011603e-08 ; train accuracy 0.995135367\n",
      "Step 742 : train loss 5.96046235e-08 ; train accuracy 0.995141923\n",
      "Step 743 : train loss 0 ; train accuracy 0.99514848\n",
      "Step 744 : train loss 4.84287668e-08 ; train accuracy 0.995155036\n",
      "Step 745 : train loss 2.235174e-08 ; train accuracy 0.995161533\n",
      "Step 746 : train loss 3.72528852e-08 ; train accuracy 0.99516809\n",
      "Step 747 : train loss 2.60770268e-08 ; train accuracy 0.995174527\n",
      "Step 748 : train loss 2.60770285e-08 ; train accuracy 0.995181\n",
      "Step 749 : train loss 2.98023171e-08 ; train accuracy 0.995187461\n",
      "Step 750 : train loss 1.86264497e-08 ; train accuracy 0.995193899\n",
      "Step 751 : train loss 5.21540571e-08 ; train accuracy 0.995200336\n",
      "Step 752 : train loss 7.45058e-09 ; train accuracy 0.995206714\n",
      "Step 753 : train loss 2.98023153e-08 ; train accuracy 0.995213091\n",
      "Step 754 : train loss 7.45058e-09 ; train accuracy 0.995219469\n",
      "Step 755 : train loss 7.45057971e-09 ; train accuracy 0.995225847\n",
      "Step 756 : train loss 1.86264497e-08 ; train accuracy 0.995232165\n",
      "Step 757 : train loss 3.35276056e-08 ; train accuracy 0.995238483\n",
      "Step 758 : train loss 1.49011603e-08 ; train accuracy 0.995244801\n",
      "Step 759 : train loss 4.47034765e-08 ; train accuracy 0.99525106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 760 : train loss 1.86264497e-08 ; train accuracy 0.995257318\n",
      "Step 761 : train loss 5.21540571e-08 ; train accuracy 0.995263577\n",
      "Step 762 : train loss 7.45057971e-09 ; train accuracy 0.995269835\n",
      "Step 763 : train loss 1.86264497e-08 ; train accuracy 0.995276034\n",
      "Step 764 : train loss 1.86264497e-08 ; train accuracy 0.995282233\n",
      "Step 765 : train loss 2.98023188e-08 ; train accuracy 0.995288432\n",
      "Step 766 : train loss 2.60770285e-08 ; train accuracy 0.995294571\n",
      "Step 767 : train loss 5.96046128e-08 ; train accuracy 0.99530077\n",
      "Step 768 : train loss 1.86264497e-08 ; train accuracy 0.995306909\n",
      "Step 769 : train loss 3.72529e-09 ; train accuracy 0.995313\n",
      "Step 770 : train loss 3.72529e-09 ; train accuracy 0.995319128\n",
      "Step 771 : train loss 1.117587e-08 ; train accuracy 0.995325208\n",
      "Step 772 : train loss 2.235174e-08 ; train accuracy 0.995331287\n",
      "Step 773 : train loss 1.49011603e-08 ; train accuracy 0.995337307\n",
      "Step 774 : train loss 1.117587e-08 ; train accuracy 0.995343387\n",
      "Step 775 : train loss 1.117587e-08 ; train accuracy 0.995349407\n",
      "Step 776 : train loss 1.117587e-08 ; train accuracy 0.995355427\n",
      "Step 777 : train loss 2.60770303e-08 ; train accuracy 0.995361388\n",
      "Step 778 : train loss 1.86264497e-08 ; train accuracy 0.995367408\n",
      "Step 779 : train loss 7.45058e-09 ; train accuracy 0.995373368\n",
      "Step 780 : train loss 1.117587e-08 ; train accuracy 0.995379329\n",
      "Step 781 : train loss 7.45057971e-09 ; train accuracy 0.99538523\n",
      "Step 782 : train loss 2.60770268e-08 ; train accuracy 0.99539113\n",
      "Step 783 : train loss 2.60770285e-08 ; train accuracy 0.995397031\n",
      "Step 784 : train loss 2.235174e-08 ; train accuracy 0.995402932\n",
      "Step 785 : train loss 1.86264497e-08 ; train accuracy 0.995408833\n",
      "Step 786 : train loss 7.45058e-09 ; train accuracy 0.995414674\n",
      "Step 787 : train loss 1.49011603e-08 ; train accuracy 0.995420516\n",
      "Step 788 : train loss 1.117587e-08 ; train accuracy 0.995426357\n",
      "Step 789 : train loss 1.86264479e-08 ; train accuracy 0.995432138\n",
      "Step 790 : train loss 3.72529e-09 ; train accuracy 0.995438\n",
      "Step 791 : train loss 1.117587e-08 ; train accuracy 0.995443761\n",
      "Step 792 : train loss 2.60770285e-08 ; train accuracy 0.995449483\n",
      "Step 793 : train loss 1.86264497e-08 ; train accuracy 0.995455265\n",
      "Step 794 : train loss 7.45058e-09 ; train accuracy 0.995461\n",
      "Step 795 : train loss 7.45058e-09 ; train accuracy 0.995466709\n",
      "Step 796 : train loss 4.47034765e-08 ; train accuracy 0.995472431\n",
      "Step 797 : train loss 7.45058e-09 ; train accuracy 0.995478153\n",
      "Step 798 : train loss 1.11758691e-08 ; train accuracy 0.995483816\n",
      "Step 799 : train loss 2.23517365e-08 ; train accuracy 0.995489478\n",
      "Step 800 : train loss 1.86264497e-08 ; train accuracy 0.995495141\n",
      "Step 801 : train loss 1.49011603e-08 ; train accuracy 0.995500803\n",
      "Step 802 : train loss 5.21540429e-08 ; train accuracy 0.995506406\n",
      "Step 803 : train loss 2.98023188e-08 ; train accuracy 0.995512\n",
      "Step 804 : train loss 2.23517382e-08 ; train accuracy 0.995517612\n",
      "Step 805 : train loss 2.60770285e-08 ; train accuracy 0.995523214\n",
      "Step 806 : train loss 7.45058e-09 ; train accuracy 0.995528758\n",
      "Step 807 : train loss 2.98023188e-08 ; train accuracy 0.995534301\n",
      "Step 808 : train loss 1.117587e-08 ; train accuracy 0.995539844\n",
      "Step 809 : train loss 0 ; train accuracy 0.995545387\n",
      "Step 810 : train loss 2.98023188e-08 ; train accuracy 0.995550931\n",
      "Step 811 : train loss 2.60770303e-08 ; train accuracy 0.995556414\n",
      "Step 812 : train loss 3.72529e-09 ; train accuracy 0.995561898\n",
      "Step 813 : train loss 5.21540429e-08 ; train accuracy 0.995567381\n",
      "Step 814 : train loss 1.117587e-08 ; train accuracy 0.995572865\n",
      "Step 815 : train loss 1.49011603e-08 ; train accuracy 0.995578289\n",
      "Step 816 : train loss 2.235174e-08 ; train accuracy 0.995583713\n",
      "Step 817 : train loss 1.117587e-08 ; train accuracy 0.995589137\n",
      "Step 818 : train loss 3.35276091e-08 ; train accuracy 0.995594561\n",
      "Step 819 : train loss 1.86264497e-08 ; train accuracy 0.995599926\n",
      "Step 820 : train loss 3.72529e-09 ; train accuracy 0.99560529\n",
      "Step 821 : train loss 7.45058e-09 ; train accuracy 0.995610714\n",
      "Step 822 : train loss 1.49011603e-08 ; train accuracy 0.995616\n",
      "Step 823 : train loss 1.49011603e-08 ; train accuracy 0.995621383\n",
      "Step 824 : train loss 7.45058e-09 ; train accuracy 0.995626688\n",
      "Step 825 : train loss 1.86264497e-08 ; train accuracy 0.995632052\n",
      "Step 826 : train loss 1.49011603e-08 ; train accuracy 0.995637357\n",
      "Step 827 : train loss 5.21540464e-08 ; train accuracy 0.995642602\n",
      "Step 828 : train loss 3.72529e-09 ; train accuracy 0.995647907\n",
      "Step 829 : train loss 7.45058e-09 ; train accuracy 0.995653152\n",
      "Step 830 : train loss 1.86264497e-08 ; train accuracy 0.995658398\n",
      "Step 831 : train loss 3.72529e-08 ; train accuracy 0.995663643\n",
      "Step 832 : train loss 2.6077025e-08 ; train accuracy 0.995668888\n",
      "Step 833 : train loss 1.49011603e-08 ; train accuracy 0.995674074\n",
      "Step 834 : train loss 1.49011594e-08 ; train accuracy 0.995679319\n",
      "Step 835 : train loss 7.45058e-09 ; train accuracy 0.995684505\n",
      "Step 836 : train loss 1.117587e-08 ; train accuracy 0.995689631\n",
      "Step 837 : train loss 1.86264497e-08 ; train accuracy 0.995694816\n",
      "Step 838 : train loss 5.96046164e-08 ; train accuracy 0.995699942\n",
      "Step 839 : train loss 2.235174e-08 ; train accuracy 0.995705128\n",
      "Step 840 : train loss 7.45058e-09 ; train accuracy 0.995710254\n",
      "Step 841 : train loss 1.86264497e-08 ; train accuracy 0.99571538\n",
      "Step 842 : train loss 2.98023153e-08 ; train accuracy 0.995720446\n",
      "Step 843 : train loss 1.49011603e-08 ; train accuracy 0.995725572\n",
      "Step 844 : train loss 1.117587e-08 ; train accuracy 0.995730639\n",
      "Step 845 : train loss 2.23517382e-08 ; train accuracy 0.995735705\n",
      "Step 846 : train loss 7.45058e-09 ; train accuracy 0.995740712\n",
      "Step 847 : train loss 1.49011594e-08 ; train accuracy 0.995745778\n",
      "Step 848 : train loss 5.215405e-08 ; train accuracy 0.995750785\n",
      "Step 849 : train loss 1.86264497e-08 ; train accuracy 0.995755851\n",
      "Step 850 : train loss 1.117587e-08 ; train accuracy 0.995760858\n",
      "Step 851 : train loss 1.117587e-08 ; train accuracy 0.995765805\n",
      "Step 852 : train loss 3.72529e-09 ; train accuracy 0.995770812\n",
      "Step 853 : train loss 2.6077025e-08 ; train accuracy 0.995775759\n",
      "Step 854 : train loss 7.45057971e-09 ; train accuracy 0.995780766\n",
      "Step 855 : train loss 5.58793332e-08 ; train accuracy 0.995785713\n",
      "Step 856 : train loss 1.49011603e-08 ; train accuracy 0.995790601\n",
      "Step 857 : train loss 3.35276091e-08 ; train accuracy 0.995795548\n",
      "Step 858 : train loss 3.72529e-09 ; train accuracy 0.995800495\n",
      "Step 859 : train loss 4.47034765e-08 ; train accuracy 0.995805383\n",
      "Step 860 : train loss 1.49011603e-08 ; train accuracy 0.99581027\n",
      "Step 861 : train loss 2.60770303e-08 ; train accuracy 0.995815158\n",
      "Step 862 : train loss 2.23517382e-08 ; train accuracy 0.99582\n",
      "Step 863 : train loss 2.98023171e-08 ; train accuracy 0.995824873\n",
      "Step 864 : train loss 2.60770303e-08 ; train accuracy 0.995829701\n",
      "Step 865 : train loss 0 ; train accuracy 0.995831847\n",
      "val loss 3.97364275e-08 ; val accuracy 1\n",
      "Step 866 : train loss 2.98023188e-08 ; train accuracy 0.995836675\n",
      "Step 867 : train loss 1.117587e-08 ; train accuracy 0.995841444\n",
      "Step 868 : train loss 3.35276091e-08 ; train accuracy 0.995846272\n",
      "Step 869 : train loss 3.72529e-09 ; train accuracy 0.995851099\n",
      "Step 870 : train loss 1.86264497e-08 ; train accuracy 0.995855868\n",
      "Step 871 : train loss 3.72529e-09 ; train accuracy 0.995860636\n",
      "Step 872 : train loss 1.49011594e-08 ; train accuracy 0.995865405\n",
      "Step 873 : train loss 1.49011594e-08 ; train accuracy 0.995870113\n",
      "Step 874 : train loss 2.60770285e-08 ; train accuracy 0.995874882\n",
      "Step 875 : train loss 4.09781862e-08 ; train accuracy 0.995879591\n",
      "Step 876 : train loss 1.49011603e-08 ; train accuracy 0.995884359\n",
      "Step 877 : train loss 1.86264497e-08 ; train accuracy 0.995889068\n",
      "Step 878 : train loss 4.47034623e-08 ; train accuracy 0.995893717\n",
      "Step 879 : train loss 0 ; train accuracy 0.995898426\n",
      "Step 880 : train loss 4.47034623e-08 ; train accuracy 0.995903075\n",
      "Step 881 : train loss 2.60770303e-08 ; train accuracy 0.995907784\n",
      "Step 882 : train loss 3.72528888e-08 ; train accuracy 0.995912433\n",
      "Step 883 : train loss 1.86264497e-08 ; train accuracy 0.995917082\n",
      "Step 884 : train loss 1.117587e-08 ; train accuracy 0.995921671\n",
      "Step 885 : train loss 3.72529e-09 ; train accuracy 0.995926321\n",
      "Step 886 : train loss 2.23517382e-08 ; train accuracy 0.99593091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 887 : train loss 5.9604627e-08 ; train accuracy 0.995935559\n",
      "Step 888 : train loss 1.49011603e-08 ; train accuracy 0.995940149\n",
      "Step 889 : train loss 1.49011603e-08 ; train accuracy 0.995944679\n",
      "Step 890 : train loss 3.72529e-09 ; train accuracy 0.995949268\n",
      "Step 891 : train loss 0 ; train accuracy 0.995953858\n",
      "Step 892 : train loss 1.86264497e-08 ; train accuracy 0.995958388\n",
      "Step 893 : train loss 3.72529e-09 ; train accuracy 0.995962918\n",
      "Step 894 : train loss 2.235174e-08 ; train accuracy 0.995967448\n",
      "Step 895 : train loss 3.72529e-09 ; train accuracy 0.995972\n",
      "Step 896 : train loss 1.49011594e-08 ; train accuracy 0.995976508\n",
      "Step 897 : train loss 7.45058e-09 ; train accuracy 0.995981\n",
      "Step 898 : train loss 1.86264462e-08 ; train accuracy 0.995985448\n",
      "Step 899 : train loss 1.49011603e-08 ; train accuracy 0.99599\n",
      "Step 900 : train loss 2.23517382e-08 ; train accuracy 0.995994449\n",
      "Step 901 : train loss 0 ; train accuracy 0.995998859\n",
      "Step 902 : train loss 3.72529e-09 ; train accuracy 0.99600333\n",
      "Step 903 : train loss 1.86264497e-08 ; train accuracy 0.9960078\n",
      "Step 904 : train loss 2.235174e-08 ; train accuracy 0.996012211\n",
      "Step 905 : train loss 7.45058e-09 ; train accuracy 0.996016622\n",
      "Step 906 : train loss 2.23517382e-08 ; train accuracy 0.996021032\n",
      "Step 907 : train loss 0 ; train accuracy 0.996025443\n",
      "Step 908 : train loss 2.98023153e-08 ; train accuracy 0.996029854\n",
      "Step 909 : train loss 1.86264497e-08 ; train accuracy 0.996034205\n",
      "Step 910 : train loss 2.235174e-08 ; train accuracy 0.996038556\n",
      "Step 911 : train loss 2.60770303e-08 ; train accuracy 0.996042967\n",
      "Step 912 : train loss 1.117587e-08 ; train accuracy 0.996047318\n",
      "Step 913 : train loss 3.72529e-08 ; train accuracy 0.99605161\n",
      "Step 914 : train loss 3.35276056e-08 ; train accuracy 0.996055961\n",
      "Step 915 : train loss 7.45058e-09 ; train accuracy 0.996060312\n",
      "Step 916 : train loss 1.49011603e-08 ; train accuracy 0.996064603\n",
      "Step 917 : train loss 4.47034694e-08 ; train accuracy 0.996068895\n",
      "Step 918 : train loss 1.49011594e-08 ; train accuracy 0.996073186\n",
      "Step 919 : train loss 1.49011594e-08 ; train accuracy 0.996077478\n",
      "Step 920 : train loss 2.235174e-08 ; train accuracy 0.996081769\n",
      "Step 921 : train loss 1.49011603e-08 ; train accuracy 0.996086061\n",
      "Step 922 : train loss 1.86264497e-08 ; train accuracy 0.996090293\n",
      "Step 923 : train loss 7.45058e-09 ; train accuracy 0.996094525\n",
      "Step 924 : train loss 1.49011603e-08 ; train accuracy 0.996098757\n",
      "Step 925 : train loss 2.98023188e-08 ; train accuracy 0.996103\n",
      "Step 926 : train loss 3.35276e-08 ; train accuracy 0.996107221\n",
      "Step 927 : train loss 4.09781862e-08 ; train accuracy 0.996111453\n",
      "Step 928 : train loss 1.117587e-08 ; train accuracy 0.996115625\n",
      "Step 929 : train loss 2.23517365e-08 ; train accuracy 0.996119857\n",
      "Step 930 : train loss 1.117587e-08 ; train accuracy 0.996124\n",
      "Step 931 : train loss 2.23517382e-08 ; train accuracy 0.996128201\n",
      "Step 932 : train loss 7.45058e-09 ; train accuracy 0.996132374\n",
      "Step 933 : train loss 0 ; train accuracy 0.996136546\n",
      "Step 934 : train loss 2.6077025e-08 ; train accuracy 0.996140659\n",
      "Step 935 : train loss 1.49011594e-08 ; train accuracy 0.996144831\n",
      "Step 936 : train loss 1.117587e-08 ; train accuracy 0.996148944\n",
      "Step 937 : train loss 1.117587e-08 ; train accuracy 0.996153057\n",
      "Step 938 : train loss 2.23517382e-08 ; train accuracy 0.996157169\n",
      "Step 939 : train loss 1.49011603e-08 ; train accuracy 0.996161282\n",
      "Step 940 : train loss 2.235174e-08 ; train accuracy 0.996165395\n",
      "Step 941 : train loss 3.72529e-09 ; train accuracy 0.996169448\n",
      "Step 942 : train loss 3.72529e-09 ; train accuracy 0.996173561\n",
      "Step 943 : train loss 1.117587e-08 ; train accuracy 0.996177614\n",
      "Step 944 : train loss 7.45058e-09 ; train accuracy 0.996181667\n",
      "Step 945 : train loss 7.45058e-09 ; train accuracy 0.99618572\n",
      "Step 946 : train loss 7.45057971e-09 ; train accuracy 0.996189773\n",
      "Step 947 : train loss 4.09781755e-08 ; train accuracy 0.996193826\n",
      "Step 948 : train loss 1.49011603e-08 ; train accuracy 0.99619782\n",
      "Step 949 : train loss 1.86264497e-08 ; train accuracy 0.996201873\n",
      "Step 950 : train loss 2.235174e-08 ; train accuracy 0.996205866\n",
      "Step 951 : train loss 1.86264497e-08 ; train accuracy 0.99620986\n",
      "Step 952 : train loss 7.45058e-09 ; train accuracy 0.996213853\n",
      "Step 953 : train loss 3.35276056e-08 ; train accuracy 0.996217847\n",
      "Step 954 : train loss 1.86264497e-08 ; train accuracy 0.99622184\n",
      "Step 955 : train loss 7.45058e-09 ; train accuracy 0.996225774\n",
      "Step 956 : train loss 1.117587e-08 ; train accuracy 0.996229768\n",
      "Step 957 : train loss 1.117587e-08 ; train accuracy 0.996233702\n",
      "Step 958 : train loss 3.72529e-09 ; train accuracy 0.996237636\n",
      "Step 959 : train loss 2.23517382e-08 ; train accuracy 0.99624157\n",
      "Step 960 : train loss 0 ; train accuracy 0.996245503\n",
      "Step 961 : train loss 7.45058e-09 ; train accuracy 0.996249437\n",
      "Step 962 : train loss 0 ; train accuracy 0.996253312\n",
      "Step 963 : train loss 1.117587e-08 ; train accuracy 0.996257246\n",
      "Step 964 : train loss 1.49011603e-08 ; train accuracy 0.99626112\n",
      "Step 965 : train loss 3.72529e-09 ; train accuracy 0.996265\n",
      "Step 966 : train loss 2.60770285e-08 ; train accuracy 0.996268928\n",
      "Step 967 : train loss 7.45058e-09 ; train accuracy 0.996272743\n",
      "Step 968 : train loss 1.49011603e-08 ; train accuracy 0.996276617\n",
      "Step 969 : train loss 0 ; train accuracy 0.996280491\n",
      "Step 970 : train loss 2.235174e-08 ; train accuracy 0.996284306\n",
      "Step 971 : train loss 3.72529e-09 ; train accuracy 0.99628818\n",
      "Step 972 : train loss 1.86264497e-08 ; train accuracy 0.996292\n",
      "Step 973 : train loss 1.49011603e-08 ; train accuracy 0.99629581\n",
      "Step 974 : train loss 0 ; train accuracy 0.996299624\n",
      "Step 975 : train loss 0 ; train accuracy 0.996303439\n",
      "Step 976 : train loss 1.117587e-08 ; train accuracy 0.996307254\n",
      "Step 977 : train loss 1.86264497e-08 ; train accuracy 0.996311\n",
      "Step 978 : train loss 1.86264479e-08 ; train accuracy 0.996314824\n",
      "Step 979 : train loss 1.49011603e-08 ; train accuracy 0.996318579\n",
      "Step 980 : train loss 1.49011603e-08 ; train accuracy 0.996322334\n",
      "Step 981 : train loss 3.35276091e-08 ; train accuracy 0.996326089\n",
      "Step 982 : train loss 4.09781755e-08 ; train accuracy 0.996329844\n",
      "Step 983 : train loss 2.235174e-08 ; train accuracy 0.996333599\n",
      "Step 984 : train loss 7.45058e-09 ; train accuracy 0.996337354\n",
      "Step 985 : train loss 1.86264497e-08 ; train accuracy 0.99634105\n",
      "Step 986 : train loss 7.45058e-09 ; train accuracy 0.996344805\n",
      "Step 987 : train loss 4.09781755e-08 ; train accuracy 0.9963485\n",
      "Step 988 : train loss 1.49011594e-08 ; train accuracy 0.996352196\n",
      "Step 989 : train loss 7.45058e-09 ; train accuracy 0.996355891\n",
      "Step 990 : train loss 7.45058e-09 ; train accuracy 0.996359587\n",
      "Step 991 : train loss 7.45058e-09 ; train accuracy 0.996363282\n",
      "Step 992 : train loss 7.45058e-09 ; train accuracy 0.996367\n",
      "Step 993 : train loss 1.86264497e-08 ; train accuracy 0.996370614\n",
      "Step 994 : train loss 7.45058e-09 ; train accuracy 0.996374309\n",
      "Step 995 : train loss 1.117587e-08 ; train accuracy 0.996377945\n",
      "Step 996 : train loss 1.49011603e-08 ; train accuracy 0.996381581\n",
      "Step 997 : train loss 1.86264497e-08 ; train accuracy 0.996385217\n",
      "Step 998 : train loss 7.45058e-09 ; train accuracy 0.996388853\n",
      "Step 999 : train loss 1.117587e-08 ; train accuracy 0.996392488\n",
      "Step 1000 : train loss 7.45057971e-09 ; train accuracy 0.996396124\n",
      "Step 1001 : train loss 1.49011594e-08 ; train accuracy 0.996399701\n",
      "Step 1002 : train loss 1.86264497e-08 ; train accuracy 0.996403337\n",
      "Step 1003 : train loss 1.117587e-08 ; train accuracy 0.996406913\n",
      "Step 1004 : train loss 1.86264497e-08 ; train accuracy 0.996410489\n",
      "Step 1005 : train loss 2.23517382e-08 ; train accuracy 0.996414065\n",
      "Step 1006 : train loss 2.235174e-08 ; train accuracy 0.996417642\n",
      "Step 1007 : train loss 3.72528888e-08 ; train accuracy 0.996421218\n",
      "Step 1008 : train loss 3.72529e-09 ; train accuracy 0.996424794\n",
      "Step 1009 : train loss 3.72529e-09 ; train accuracy 0.99642837\n",
      "Step 1010 : train loss 7.45058e-09 ; train accuracy 0.996431887\n",
      "Step 1011 : train loss 1.117587e-08 ; train accuracy 0.996435463\n",
      "Step 1012 : train loss 7.45058e-09 ; train accuracy 0.996439\n",
      "Step 1013 : train loss 0 ; train accuracy 0.996442497\n",
      "Step 1014 : train loss 1.86264479e-08 ; train accuracy 0.996446\n",
      "Step 1015 : train loss 2.235174e-08 ; train accuracy 0.99644953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1016 : train loss 1.86264497e-08 ; train accuracy 0.996453047\n",
      "Step 1017 : train loss 1.86264497e-08 ; train accuracy 0.996456504\n",
      "Step 1018 : train loss 1.117587e-08 ; train accuracy 0.99646\n",
      "Step 1019 : train loss 1.86264497e-08 ; train accuracy 0.996463478\n",
      "Step 1020 : train loss 7.45058e-09 ; train accuracy 0.996467\n",
      "Step 1021 : train loss 1.49011603e-08 ; train accuracy 0.996470451\n",
      "Step 1022 : train loss 7.07804944e-08 ; train accuracy 0.996473908\n",
      "Step 1023 : train loss 5.21540429e-08 ; train accuracy 0.996477365\n",
      "Step 1024 : train loss 7.45058e-09 ; train accuracy 0.996480823\n",
      "Step 1025 : train loss 1.117587e-08 ; train accuracy 0.99648428\n",
      "Step 1026 : train loss 4.09781826e-08 ; train accuracy 0.996487677\n",
      "Step 1027 : train loss 2.23517382e-08 ; train accuracy 0.996491134\n",
      "Step 1028 : train loss 1.86264497e-08 ; train accuracy 0.996494532\n",
      "Step 1029 : train loss 1.86264497e-08 ; train accuracy 0.996498\n",
      "Step 1030 : train loss 3.35276091e-08 ; train accuracy 0.996501386\n",
      "Step 1031 : train loss 1.117587e-08 ; train accuracy 0.996504784\n",
      "Step 1032 : train loss 1.49011603e-08 ; train accuracy 0.996508181\n",
      "Step 1033 : train loss 1.117587e-08 ; train accuracy 0.996511579\n",
      "Step 1034 : train loss 3.72529e-09 ; train accuracy 0.996514916\n",
      "Step 1035 : train loss 3.72529e-09 ; train accuracy 0.996518314\n",
      "Step 1036 : train loss 1.49011594e-08 ; train accuracy 0.996521711\n",
      "Step 1037 : train loss 2.98023153e-08 ; train accuracy 0.996525049\n",
      "Step 1038 : train loss 8.51494875e-09 ; train accuracy 0.996526539\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 1039 : train loss 2.60770285e-08 ; train accuracy 0.996529877\n",
      "Step 1040 : train loss 2.235174e-08 ; train accuracy 0.996533215\n",
      "Step 1041 : train loss 1.86264497e-08 ; train accuracy 0.996536553\n",
      "Step 1042 : train loss 7.45057971e-09 ; train accuracy 0.996539891\n",
      "Step 1043 : train loss 1.49011594e-08 ; train accuracy 0.996543229\n",
      "Step 1044 : train loss 1.49011576e-08 ; train accuracy 0.996546566\n",
      "Step 1045 : train loss 0 ; train accuracy 0.996549845\n",
      "Step 1046 : train loss 1.86264497e-08 ; train accuracy 0.996553183\n",
      "Step 1047 : train loss 4.47034623e-08 ; train accuracy 0.996556461\n",
      "Step 1048 : train loss 0 ; train accuracy 0.996559799\n",
      "Step 1049 : train loss 2.98023188e-08 ; train accuracy 0.996563077\n",
      "Step 1050 : train loss 1.86264497e-08 ; train accuracy 0.996566355\n",
      "Step 1051 : train loss 7.45058e-09 ; train accuracy 0.996569633\n",
      "Step 1052 : train loss 2.98023153e-08 ; train accuracy 0.996572912\n",
      "Step 1053 : train loss 0 ; train accuracy 0.99657613\n",
      "Step 1054 : train loss 3.35276e-08 ; train accuracy 0.996579409\n",
      "Step 1055 : train loss 1.86264497e-08 ; train accuracy 0.996582687\n",
      "Step 1056 : train loss 7.45058e-09 ; train accuracy 0.996585906\n",
      "Step 1057 : train loss 7.45058e-09 ; train accuracy 0.996589184\n",
      "Step 1058 : train loss 1.117587e-08 ; train accuracy 0.996592402\n",
      "Step 1059 : train loss 7.45058e-09 ; train accuracy 0.996595621\n",
      "Step 1060 : train loss 3.72529e-09 ; train accuracy 0.99659884\n",
      "Step 1061 : train loss 3.72529e-09 ; train accuracy 0.996602058\n",
      "Step 1062 : train loss 3.35276056e-08 ; train accuracy 0.996605277\n",
      "Step 1063 : train loss 0 ; train accuracy 0.996608496\n",
      "Step 1064 : train loss 7.45057971e-09 ; train accuracy 0.996611655\n",
      "Step 1065 : train loss 1.49011594e-08 ; train accuracy 0.996614873\n",
      "Step 1066 : train loss 2.6077025e-08 ; train accuracy 0.996618032\n",
      "Step 1067 : train loss 7.45058e-09 ; train accuracy 0.996621251\n",
      "Step 1068 : train loss 1.117587e-08 ; train accuracy 0.99662441\n",
      "Step 1069 : train loss 1.86264497e-08 ; train accuracy 0.996627569\n",
      "Step 1070 : train loss 1.117587e-08 ; train accuracy 0.996630728\n",
      "Step 1071 : train loss 0 ; train accuracy 0.996633887\n",
      "Step 1072 : train loss 7.45058e-09 ; train accuracy 0.996637046\n",
      "Step 1073 : train loss 2.98023188e-08 ; train accuracy 0.996640205\n",
      "Step 1074 : train loss 1.49011603e-08 ; train accuracy 0.996643305\n",
      "Step 1075 : train loss 1.86264497e-08 ; train accuracy 0.996646464\n",
      "Step 1076 : train loss 1.49011603e-08 ; train accuracy 0.996649563\n",
      "Step 1077 : train loss 7.45058e-09 ; train accuracy 0.996652722\n",
      "Step 1078 : train loss 7.45058e-09 ; train accuracy 0.996655822\n",
      "Step 1079 : train loss 1.49011594e-08 ; train accuracy 0.996658921\n",
      "Step 1080 : train loss 7.45058e-09 ; train accuracy 0.996662\n",
      "Step 1081 : train loss 1.86264462e-08 ; train accuracy 0.99666512\n",
      "Step 1082 : train loss 4.09781897e-08 ; train accuracy 0.99666822\n",
      "Step 1083 : train loss 2.235174e-08 ; train accuracy 0.996671319\n",
      "Step 1084 : train loss 2.235174e-08 ; train accuracy 0.996674359\n",
      "Step 1085 : train loss 3.72529e-09 ; train accuracy 0.996677458\n",
      "Step 1086 : train loss 1.117587e-08 ; train accuracy 0.996680498\n",
      "Step 1087 : train loss 7.45058e-09 ; train accuracy 0.996683598\n",
      "Step 1088 : train loss 2.235174e-08 ; train accuracy 0.996686637\n",
      "Step 1089 : train loss 7.45058e-09 ; train accuracy 0.996689677\n",
      "Step 1090 : train loss 1.49011594e-08 ; train accuracy 0.996692717\n",
      "Step 1091 : train loss 0 ; train accuracy 0.996695757\n",
      "Step 1092 : train loss 2.98023153e-08 ; train accuracy 0.996698797\n",
      "Step 1093 : train loss 4.47034765e-08 ; train accuracy 0.996701837\n",
      "Step 1094 : train loss 1.117587e-08 ; train accuracy 0.996704876\n",
      "Step 1095 : train loss 1.86264497e-08 ; train accuracy 0.996707916\n",
      "Step 1096 : train loss 7.45058e-09 ; train accuracy 0.996710896\n",
      "Step 1097 : train loss 1.117587e-08 ; train accuracy 0.996713936\n",
      "Step 1098 : train loss 3.35276e-08 ; train accuracy 0.996716917\n",
      "Step 1099 : train loss 1.49011603e-08 ; train accuracy 0.996719897\n",
      "Step 1100 : train loss 2.23517365e-08 ; train accuracy 0.996722877\n",
      "Step 1101 : train loss 3.72529e-09 ; train accuracy 0.996725857\n",
      "Step 1102 : train loss 7.45058e-09 ; train accuracy 0.996728837\n",
      "Step 1103 : train loss 1.117587e-08 ; train accuracy 0.996731818\n",
      "Step 1104 : train loss 1.86264497e-08 ; train accuracy 0.996734798\n",
      "Step 1105 : train loss 1.49011603e-08 ; train accuracy 0.996737778\n",
      "Step 1106 : train loss 2.23517382e-08 ; train accuracy 0.996740758\n",
      "Step 1107 : train loss 1.117587e-08 ; train accuracy 0.996743679\n",
      "Step 1108 : train loss 1.49011603e-08 ; train accuracy 0.996746659\n",
      "Step 1109 : train loss 7.45058e-09 ; train accuracy 0.99674958\n",
      "Step 1110 : train loss 1.49011594e-08 ; train accuracy 0.996752501\n",
      "Step 1111 : train loss 1.49011603e-08 ; train accuracy 0.996755421\n",
      "Step 1112 : train loss 0 ; train accuracy 0.996758401\n",
      "Step 1113 : train loss 1.117587e-08 ; train accuracy 0.996761322\n",
      "Step 1114 : train loss 1.49011603e-08 ; train accuracy 0.996764183\n",
      "Step 1115 : train loss 3.72529e-09 ; train accuracy 0.996767104\n",
      "Step 1116 : train loss 5.215405e-08 ; train accuracy 0.99677\n",
      "Step 1117 : train loss 3.72529e-09 ; train accuracy 0.996772945\n",
      "Step 1118 : train loss 7.45058e-09 ; train accuracy 0.996775806\n",
      "Step 1119 : train loss 1.117587e-08 ; train accuracy 0.996778727\n",
      "Step 1120 : train loss 0 ; train accuracy 0.996781588\n",
      "Step 1121 : train loss 7.45058e-09 ; train accuracy 0.996784449\n",
      "Step 1122 : train loss 4.47034765e-08 ; train accuracy 0.996787369\n",
      "Step 1123 : train loss 1.117587e-08 ; train accuracy 0.99679023\n",
      "Step 1124 : train loss 7.45058e-09 ; train accuracy 0.996793091\n",
      "Step 1125 : train loss 7.45057971e-09 ; train accuracy 0.996795952\n",
      "Step 1126 : train loss 0 ; train accuracy 0.996798813\n",
      "Step 1127 : train loss 1.86264462e-08 ; train accuracy 0.996801674\n",
      "Step 1128 : train loss 1.117587e-08 ; train accuracy 0.996804476\n",
      "Step 1129 : train loss 7.45058e-09 ; train accuracy 0.996807337\n",
      "Step 1130 : train loss 1.86264497e-08 ; train accuracy 0.996810138\n",
      "Step 1131 : train loss 2.23517382e-08 ; train accuracy 0.996813\n",
      "Step 1132 : train loss 1.49011603e-08 ; train accuracy 0.996815801\n",
      "Step 1133 : train loss 7.45057971e-09 ; train accuracy 0.996818662\n",
      "Step 1134 : train loss 7.45058e-09 ; train accuracy 0.996821463\n",
      "Step 1135 : train loss 1.117587e-08 ; train accuracy 0.996824265\n",
      "Step 1136 : train loss 7.45058e-09 ; train accuracy 0.996827066\n",
      "Step 1137 : train loss 1.49011594e-08 ; train accuracy 0.996829867\n",
      "Step 1138 : train loss 3.72529e-09 ; train accuracy 0.996832669\n",
      "Step 1139 : train loss 3.72529e-09 ; train accuracy 0.99683547\n",
      "Step 1140 : train loss 3.72529e-09 ; train accuracy 0.996838212\n",
      "Step 1141 : train loss 3.72529e-09 ; train accuracy 0.996841\n",
      "Step 1142 : train loss 7.45058e-09 ; train accuracy 0.996843755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1143 : train loss 1.86264497e-08 ; train accuracy 0.996846557\n",
      "Step 1144 : train loss 1.117587e-08 ; train accuracy 0.996849298\n",
      "Step 1145 : train loss 3.72529e-09 ; train accuracy 0.9968521\n",
      "Step 1146 : train loss 1.117587e-08 ; train accuracy 0.996854842\n",
      "Step 1147 : train loss 0 ; train accuracy 0.996857584\n",
      "Step 1148 : train loss 1.49011603e-08 ; train accuracy 0.996860325\n",
      "Step 1149 : train loss 1.117587e-08 ; train accuracy 0.996863067\n",
      "Step 1150 : train loss 3.72529e-09 ; train accuracy 0.996865809\n",
      "Step 1151 : train loss 1.86264497e-08 ; train accuracy 0.996868551\n",
      "Step 1152 : train loss 2.60770303e-08 ; train accuracy 0.996871233\n",
      "Step 1153 : train loss 1.86264497e-08 ; train accuracy 0.996874\n",
      "Step 1154 : train loss 4.09781897e-08 ; train accuracy 0.996876717\n",
      "Step 1155 : train loss 1.117587e-08 ; train accuracy 0.996879399\n",
      "Step 1156 : train loss 0 ; train accuracy 0.996882141\n",
      "Step 1157 : train loss 3.35276e-08 ; train accuracy 0.996884823\n",
      "Step 1158 : train loss 7.45058e-09 ; train accuracy 0.996887505\n",
      "Step 1159 : train loss 1.117587e-08 ; train accuracy 0.996890187\n",
      "Step 1160 : train loss 7.45058e-09 ; train accuracy 0.996892929\n",
      "Step 1161 : train loss 3.72528888e-08 ; train accuracy 0.996895611\n",
      "Step 1162 : train loss 7.45057971e-09 ; train accuracy 0.996898234\n",
      "Step 1163 : train loss 0 ; train accuracy 0.996900916\n",
      "Step 1164 : train loss 3.72529e-09 ; train accuracy 0.996903598\n",
      "Step 1165 : train loss 7.45058e-09 ; train accuracy 0.996906281\n",
      "Step 1166 : train loss 1.117587e-08 ; train accuracy 0.996908963\n",
      "Step 1167 : train loss 0 ; train accuracy 0.996911585\n",
      "Step 1168 : train loss 3.72529e-09 ; train accuracy 0.996914268\n",
      "Step 1169 : train loss 7.45058e-09 ; train accuracy 0.99691689\n",
      "Step 1170 : train loss 3.72529e-09 ; train accuracy 0.996919513\n",
      "Step 1171 : train loss 2.235174e-08 ; train accuracy 0.996922195\n",
      "Step 1172 : train loss 3.35276e-08 ; train accuracy 0.996924818\n",
      "Step 1173 : train loss 1.86264479e-08 ; train accuracy 0.99692744\n",
      "Step 1174 : train loss 2.60770285e-08 ; train accuracy 0.996930063\n",
      "Step 1175 : train loss 1.117587e-08 ; train accuracy 0.996932685\n",
      "Step 1176 : train loss 1.117587e-08 ; train accuracy 0.996935308\n",
      "Step 1177 : train loss 1.117587e-08 ; train accuracy 0.996937931\n",
      "Step 1178 : train loss 2.235174e-08 ; train accuracy 0.996940494\n",
      "Step 1179 : train loss 1.86264497e-08 ; train accuracy 0.996943116\n",
      "Step 1180 : train loss 7.45058e-09 ; train accuracy 0.996945739\n",
      "Step 1181 : train loss 1.117587e-08 ; train accuracy 0.996948302\n",
      "Step 1182 : train loss 0 ; train accuracy 0.996950924\n",
      "Step 1183 : train loss 2.235174e-08 ; train accuracy 0.996953487\n",
      "Step 1184 : train loss 7.45058e-09 ; train accuracy 0.99695605\n",
      "Step 1185 : train loss 4.84287561e-08 ; train accuracy 0.996958613\n",
      "Step 1186 : train loss 7.45058e-09 ; train accuracy 0.996961236\n",
      "Step 1187 : train loss 1.49011594e-08 ; train accuracy 0.996963799\n",
      "Step 1188 : train loss 1.117587e-08 ; train accuracy 0.996966362\n",
      "Step 1189 : train loss 1.49011603e-08 ; train accuracy 0.996968925\n",
      "Step 1190 : train loss 0 ; train accuracy 0.996971428\n",
      "Step 1191 : train loss 1.86264497e-08 ; train accuracy 0.996974\n",
      "Step 1192 : train loss 1.86264497e-08 ; train accuracy 0.996976554\n",
      "Step 1193 : train loss 1.117587e-08 ; train accuracy 0.996979117\n",
      "Step 1194 : train loss 2.23517382e-08 ; train accuracy 0.996981621\n",
      "Step 1195 : train loss 0 ; train accuracy 0.996984184\n",
      "Step 1196 : train loss 1.49011594e-08 ; train accuracy 0.996986687\n",
      "Step 1197 : train loss 2.60770268e-08 ; train accuracy 0.996989191\n",
      "Step 1198 : train loss 1.117587e-08 ; train accuracy 0.996991754\n",
      "Step 1199 : train loss 1.86264479e-08 ; train accuracy 0.996994257\n",
      "Step 1200 : train loss 1.86264497e-08 ; train accuracy 0.99699676\n",
      "Step 1201 : train loss 7.45058e-09 ; train accuracy 0.996999264\n",
      "Step 1202 : train loss 2.23517382e-08 ; train accuracy 0.997001767\n",
      "Step 1203 : train loss 7.45058e-09 ; train accuracy 0.997004271\n",
      "Step 1204 : train loss 4.47034765e-08 ; train accuracy 0.997006774\n",
      "Step 1205 : train loss 0 ; train accuracy 0.997009277\n",
      "Step 1206 : train loss 1.117587e-08 ; train accuracy 0.997011721\n",
      "Step 1207 : train loss 1.86264497e-08 ; train accuracy 0.997014225\n",
      "Step 1208 : train loss 7.45058e-09 ; train accuracy 0.997016728\n",
      "Step 1209 : train loss 7.45058e-09 ; train accuracy 0.997019172\n",
      "Step 1210 : train loss 1.117587e-08 ; train accuracy 0.997021675\n",
      "Step 1211 : train loss 1.70298975e-08 ; train accuracy 0.997022748\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 1212 : train loss 2.98023153e-08 ; train accuracy 0.997025192\n",
      "Step 1213 : train loss 1.86264497e-08 ; train accuracy 0.997027636\n",
      "Step 1214 : train loss 3.72529e-09 ; train accuracy 0.997030139\n",
      "Step 1215 : train loss 3.72529e-09 ; train accuracy 0.997032583\n",
      "Step 1216 : train loss 1.86264497e-08 ; train accuracy 0.997035\n",
      "Step 1217 : train loss 1.86264497e-08 ; train accuracy 0.99703747\n",
      "Step 1218 : train loss 3.72529e-09 ; train accuracy 0.997039914\n",
      "Step 1219 : train loss 1.117587e-08 ; train accuracy 0.997042358\n",
      "Step 1220 : train loss 1.49011603e-08 ; train accuracy 0.997044742\n",
      "Step 1221 : train loss 1.49011603e-08 ; train accuracy 0.997047186\n",
      "Step 1222 : train loss 2.235174e-08 ; train accuracy 0.99704963\n",
      "Step 1223 : train loss 4.09781862e-08 ; train accuracy 0.997052\n",
      "Step 1224 : train loss 2.98023117e-08 ; train accuracy 0.997054458\n",
      "Step 1225 : train loss 3.72529e-09 ; train accuracy 0.997056842\n",
      "Step 1226 : train loss 1.117587e-08 ; train accuracy 0.997059286\n",
      "Step 1227 : train loss 7.45058e-09 ; train accuracy 0.99706167\n",
      "Step 1228 : train loss 2.98023153e-08 ; train accuracy 0.997064054\n",
      "Step 1229 : train loss 7.45058e-09 ; train accuracy 0.997066498\n",
      "Step 1230 : train loss 2.98023153e-08 ; train accuracy 0.997068882\n",
      "Step 1231 : train loss 3.72529e-09 ; train accuracy 0.997071266\n",
      "Step 1232 : train loss 1.86264497e-08 ; train accuracy 0.99707365\n",
      "Step 1233 : train loss 2.60770285e-08 ; train accuracy 0.997076035\n",
      "Step 1234 : train loss 2.23517382e-08 ; train accuracy 0.997078419\n",
      "Step 1235 : train loss 3.72529e-09 ; train accuracy 0.997080803\n",
      "Step 1236 : train loss 1.117587e-08 ; train accuracy 0.997083127\n",
      "Step 1237 : train loss 3.72529e-09 ; train accuracy 0.997085512\n",
      "Step 1238 : train loss 7.45057971e-09 ; train accuracy 0.997087896\n",
      "Step 1239 : train loss 3.72529e-09 ; train accuracy 0.99709022\n",
      "Step 1240 : train loss 3.72529e-09 ; train accuracy 0.997092605\n",
      "Step 1241 : train loss 1.117587e-08 ; train accuracy 0.997094929\n",
      "Step 1242 : train loss 3.72529e-09 ; train accuracy 0.997097254\n",
      "Step 1243 : train loss 3.72529e-09 ; train accuracy 0.997099638\n",
      "Step 1244 : train loss 1.117587e-08 ; train accuracy 0.997101963\n",
      "Step 1245 : train loss 3.72529e-09 ; train accuracy 0.997104287\n",
      "Step 1246 : train loss 0 ; train accuracy 0.997106612\n",
      "Step 1247 : train loss 1.86264479e-08 ; train accuracy 0.997108936\n",
      "Step 1248 : train loss 3.72529e-09 ; train accuracy 0.997111261\n",
      "Step 1249 : train loss 2.60770303e-08 ; train accuracy 0.997113585\n",
      "Step 1250 : train loss 1.49011603e-08 ; train accuracy 0.99711591\n",
      "Step 1251 : train loss 3.72529e-09 ; train accuracy 0.997118235\n",
      "Step 1252 : train loss 3.72529e-09 ; train accuracy 0.997120559\n",
      "Step 1253 : train loss 1.86264479e-08 ; train accuracy 0.997122824\n",
      "Step 1254 : train loss 3.35276091e-08 ; train accuracy 0.997125149\n",
      "Step 1255 : train loss 1.49011603e-08 ; train accuracy 0.997127414\n",
      "Step 1256 : train loss 1.49011594e-08 ; train accuracy 0.997129738\n",
      "Step 1257 : train loss 3.72529e-09 ; train accuracy 0.997132\n",
      "Step 1258 : train loss 1.117587e-08 ; train accuracy 0.997134328\n",
      "Step 1259 : train loss 0 ; train accuracy 0.997136593\n",
      "Step 1260 : train loss 1.86264497e-08 ; train accuracy 0.997138858\n",
      "Step 1261 : train loss 3.72528959e-08 ; train accuracy 0.997141123\n",
      "Step 1262 : train loss 1.117587e-08 ; train accuracy 0.997143447\n",
      "Step 1263 : train loss 3.72529e-09 ; train accuracy 0.997145712\n",
      "Step 1264 : train loss 3.35276056e-08 ; train accuracy 0.997148\n",
      "Step 1265 : train loss 2.60770285e-08 ; train accuracy 0.997150242\n",
      "Step 1266 : train loss 0 ; train accuracy 0.997152507\n",
      "Step 1267 : train loss 7.45058e-09 ; train accuracy 0.997154713\n",
      "Step 1268 : train loss 2.235174e-08 ; train accuracy 0.997157\n",
      "Step 1269 : train loss 1.117587e-08 ; train accuracy 0.997159243\n",
      "Step 1270 : train loss 1.49011603e-08 ; train accuracy 0.997161448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1271 : train loss 1.117587e-08 ; train accuracy 0.997163713\n",
      "Step 1272 : train loss 1.117587e-08 ; train accuracy 0.997166\n",
      "Step 1273 : train loss 1.117587e-08 ; train accuracy 0.997168183\n",
      "Step 1274 : train loss 1.86264479e-08 ; train accuracy 0.997170389\n",
      "Step 1275 : train loss 7.45058e-09 ; train accuracy 0.997172654\n",
      "Step 1276 : train loss 2.60770268e-08 ; train accuracy 0.997174859\n",
      "Step 1277 : train loss 1.117587e-08 ; train accuracy 0.997177064\n",
      "Step 1278 : train loss 3.72529e-09 ; train accuracy 0.99717927\n",
      "Step 1279 : train loss 0 ; train accuracy 0.997181535\n",
      "Step 1280 : train loss 3.72529e-09 ; train accuracy 0.99718374\n",
      "Step 1281 : train loss 0 ; train accuracy 0.997185946\n",
      "Step 1282 : train loss 1.49011594e-08 ; train accuracy 0.997188151\n",
      "Step 1283 : train loss 3.72529e-09 ; train accuracy 0.997190297\n",
      "Step 1284 : train loss 7.45058e-09 ; train accuracy 0.997192502\n",
      "Step 1285 : train loss 4.09781791e-08 ; train accuracy 0.997194707\n",
      "Step 1286 : train loss 3.72529e-09 ; train accuracy 0.997196913\n",
      "Step 1287 : train loss 0 ; train accuracy 0.997199059\n",
      "Step 1288 : train loss 3.72529e-09 ; train accuracy 0.997201264\n",
      "Step 1289 : train loss 1.86264497e-08 ; train accuracy 0.997203469\n",
      "Step 1290 : train loss 1.117587e-08 ; train accuracy 0.997205615\n",
      "Step 1291 : train loss 1.49011603e-08 ; train accuracy 0.997207761\n",
      "Step 1292 : train loss 3.72529e-09 ; train accuracy 0.997209966\n",
      "Step 1293 : train loss 2.235174e-08 ; train accuracy 0.997212112\n",
      "Step 1294 : train loss 1.117587e-08 ; train accuracy 0.997214258\n",
      "Step 1295 : train loss 1.117587e-08 ; train accuracy 0.997216463\n",
      "Step 1296 : train loss 0 ; train accuracy 0.997218609\n",
      "Step 1297 : train loss 1.49011594e-08 ; train accuracy 0.997220755\n",
      "Step 1298 : train loss 1.86264497e-08 ; train accuracy 0.9972229\n",
      "Step 1299 : train loss 7.45058e-09 ; train accuracy 0.997225046\n",
      "Step 1300 : train loss 2.60770285e-08 ; train accuracy 0.997227192\n",
      "Step 1301 : train loss 0 ; train accuracy 0.997229338\n",
      "Step 1302 : train loss 2.60770285e-08 ; train accuracy 0.997231424\n",
      "Step 1303 : train loss 7.45057971e-09 ; train accuracy 0.99723357\n",
      "Step 1304 : train loss 1.49011603e-08 ; train accuracy 0.997235715\n",
      "Step 1305 : train loss 1.117587e-08 ; train accuracy 0.997237861\n",
      "Step 1306 : train loss 0 ; train accuracy 0.997239947\n",
      "Step 1307 : train loss 1.86264497e-08 ; train accuracy 0.997242093\n",
      "Step 1308 : train loss 3.72529e-09 ; train accuracy 0.997244179\n",
      "Step 1309 : train loss 1.49011603e-08 ; train accuracy 0.997246325\n",
      "Step 1310 : train loss 0 ; train accuracy 0.997248411\n",
      "Step 1311 : train loss 3.72529e-09 ; train accuracy 0.997250497\n",
      "Step 1312 : train loss 3.72529e-09 ; train accuracy 0.997252643\n",
      "Step 1313 : train loss 7.45058e-09 ; train accuracy 0.997254729\n",
      "Step 1314 : train loss 3.72529e-09 ; train accuracy 0.997256815\n",
      "Step 1315 : train loss 7.45058e-09 ; train accuracy 0.997258902\n",
      "Step 1316 : train loss 3.72529e-09 ; train accuracy 0.997261\n",
      "Step 1317 : train loss 3.72529e-09 ; train accuracy 0.997263074\n",
      "Step 1318 : train loss 1.117587e-08 ; train accuracy 0.99726516\n",
      "Step 1319 : train loss 1.49011594e-08 ; train accuracy 0.997267246\n",
      "Step 1320 : train loss 1.117587e-08 ; train accuracy 0.997269332\n",
      "Step 1321 : train loss 1.86264497e-08 ; train accuracy 0.997271419\n",
      "Step 1322 : train loss 3.72529e-09 ; train accuracy 0.997273445\n",
      "Step 1323 : train loss 1.49011594e-08 ; train accuracy 0.997275531\n",
      "Step 1324 : train loss 3.72529e-09 ; train accuracy 0.997277617\n",
      "Step 1325 : train loss 3.72529e-09 ; train accuracy 0.997279644\n",
      "Step 1326 : train loss 7.45057971e-09 ; train accuracy 0.99728173\n",
      "Step 1327 : train loss 2.235174e-08 ; train accuracy 0.997283757\n",
      "Step 1328 : train loss 7.45058e-09 ; train accuracy 0.997285843\n",
      "Step 1329 : train loss 3.72529e-09 ; train accuracy 0.997287869\n",
      "Step 1330 : train loss 3.72528888e-08 ; train accuracy 0.997289896\n",
      "Step 1331 : train loss 7.45058e-09 ; train accuracy 0.997291923\n",
      "Step 1332 : train loss 1.86264497e-08 ; train accuracy 0.997294\n",
      "Step 1333 : train loss 7.45058e-09 ; train accuracy 0.997296035\n",
      "Step 1334 : train loss 2.98023117e-08 ; train accuracy 0.997298062\n",
      "Step 1335 : train loss 1.49011594e-08 ; train accuracy 0.997300088\n",
      "Step 1336 : train loss 7.45058e-09 ; train accuracy 0.997302115\n",
      "Step 1337 : train loss 3.72529e-09 ; train accuracy 0.997304142\n",
      "Step 1338 : train loss 1.117587e-08 ; train accuracy 0.997306168\n",
      "Step 1339 : train loss 7.45058e-09 ; train accuracy 0.997308195\n",
      "Step 1340 : train loss 7.45057971e-09 ; train accuracy 0.997310221\n",
      "Step 1341 : train loss 7.45058e-09 ; train accuracy 0.997312188\n",
      "Step 1342 : train loss 1.117587e-08 ; train accuracy 0.997314215\n",
      "Step 1343 : train loss 0 ; train accuracy 0.997316241\n",
      "Step 1344 : train loss 7.45058e-09 ; train accuracy 0.997318208\n",
      "Step 1345 : train loss 2.23517365e-08 ; train accuracy 0.997320235\n",
      "Step 1346 : train loss 3.72529e-09 ; train accuracy 0.997322202\n",
      "Step 1347 : train loss 3.72529e-09 ; train accuracy 0.997324228\n",
      "Step 1348 : train loss 2.235174e-08 ; train accuracy 0.997326195\n",
      "Step 1349 : train loss 2.235174e-08 ; train accuracy 0.997328162\n",
      "Step 1350 : train loss 7.45058e-09 ; train accuracy 0.997330189\n",
      "Step 1351 : train loss 1.49011594e-08 ; train accuracy 0.997332156\n",
      "Step 1352 : train loss 1.117587e-08 ; train accuracy 0.997334123\n",
      "Step 1353 : train loss 1.86264497e-08 ; train accuracy 0.99733609\n",
      "Step 1354 : train loss 3.72529e-09 ; train accuracy 0.997338057\n",
      "Step 1355 : train loss 5.96046306e-08 ; train accuracy 0.997340083\n",
      "Step 1356 : train loss 1.49011594e-08 ; train accuracy 0.99734205\n",
      "Step 1357 : train loss 1.86264497e-08 ; train accuracy 0.997344\n",
      "Step 1358 : train loss 1.117587e-08 ; train accuracy 0.997345924\n",
      "Step 1359 : train loss 1.117587e-08 ; train accuracy 0.997347891\n",
      "Step 1360 : train loss 1.117587e-08 ; train accuracy 0.997349858\n",
      "Step 1361 : train loss 1.117587e-08 ; train accuracy 0.997351825\n",
      "Step 1362 : train loss 1.86264497e-08 ; train accuracy 0.997353792\n",
      "Step 1363 : train loss 1.117587e-08 ; train accuracy 0.9973557\n",
      "Step 1364 : train loss 3.72529e-09 ; train accuracy 0.997357666\n",
      "Step 1365 : train loss 7.45057971e-09 ; train accuracy 0.997359574\n",
      "Step 1366 : train loss 1.117587e-08 ; train accuracy 0.997361541\n",
      "Step 1367 : train loss 3.35276056e-08 ; train accuracy 0.997363448\n",
      "Step 1368 : train loss 1.49011603e-08 ; train accuracy 0.997365415\n",
      "Step 1369 : train loss 7.45058e-09 ; train accuracy 0.997367322\n",
      "Step 1370 : train loss 2.98023153e-08 ; train accuracy 0.997369289\n",
      "Step 1371 : train loss 1.117587e-08 ; train accuracy 0.997371197\n",
      "Step 1372 : train loss 7.45058e-09 ; train accuracy 0.997373104\n",
      "Step 1373 : train loss 7.45058e-09 ; train accuracy 0.997375\n",
      "Step 1374 : train loss 2.98023188e-08 ; train accuracy 0.997376919\n",
      "Step 1375 : train loss 1.117587e-08 ; train accuracy 0.997378886\n",
      "Step 1376 : train loss 1.86264479e-08 ; train accuracy 0.997380793\n",
      "Step 1377 : train loss 1.49011603e-08 ; train accuracy 0.9973827\n",
      "Step 1378 : train loss 1.86264497e-08 ; train accuracy 0.997384608\n",
      "Step 1379 : train loss 1.86264497e-08 ; train accuracy 0.997386456\n",
      "Step 1380 : train loss 7.45058e-09 ; train accuracy 0.997388363\n",
      "Step 1381 : train loss 3.72529e-09 ; train accuracy 0.99739027\n",
      "Step 1382 : train loss 0 ; train accuracy 0.997392178\n",
      "Step 1383 : train loss 1.49011603e-08 ; train accuracy 0.997394085\n",
      "Step 1384 : train loss 5.9604627e-08 ; train accuracy 0.99739486\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 1385 : train loss 3.72529e-09 ; train accuracy 0.997396767\n",
      "Step 1386 : train loss 4.84287561e-08 ; train accuracy 0.997398674\n",
      "Step 1387 : train loss 3.72529e-09 ; train accuracy 0.997400522\n",
      "Step 1388 : train loss 2.98023188e-08 ; train accuracy 0.99740243\n",
      "Step 1389 : train loss 2.23517382e-08 ; train accuracy 0.997404277\n",
      "Step 1390 : train loss 3.72529e-09 ; train accuracy 0.997406185\n",
      "Step 1391 : train loss 7.45057971e-09 ; train accuracy 0.997408032\n",
      "Step 1392 : train loss 7.45058e-09 ; train accuracy 0.99740988\n",
      "Step 1393 : train loss 7.45057971e-09 ; train accuracy 0.997411788\n",
      "Step 1394 : train loss 0 ; train accuracy 0.997413635\n",
      "Step 1395 : train loss 0 ; train accuracy 0.997415483\n",
      "Step 1396 : train loss 1.117587e-08 ; train accuracy 0.997417331\n",
      "Step 1397 : train loss 7.45058e-09 ; train accuracy 0.997419238\n",
      "Step 1398 : train loss 0 ; train accuracy 0.997421086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1399 : train loss 4.09781791e-08 ; train accuracy 0.997422934\n",
      "Step 1400 : train loss 1.49011603e-08 ; train accuracy 0.997424781\n",
      "Step 1401 : train loss 2.60770268e-08 ; train accuracy 0.997426629\n",
      "Step 1402 : train loss 1.117587e-08 ; train accuracy 0.997428417\n",
      "Step 1403 : train loss 1.49011603e-08 ; train accuracy 0.997430265\n",
      "Step 1404 : train loss 7.45058e-09 ; train accuracy 0.997432113\n",
      "Step 1405 : train loss 1.117587e-08 ; train accuracy 0.99743396\n",
      "Step 1406 : train loss 0 ; train accuracy 0.997435808\n",
      "Step 1407 : train loss 1.86264479e-08 ; train accuracy 0.997437596\n",
      "Step 1408 : train loss 0 ; train accuracy 0.997439444\n",
      "Step 1409 : train loss 2.235174e-08 ; train accuracy 0.997441232\n",
      "Step 1410 : train loss 0 ; train accuracy 0.99744308\n",
      "Step 1411 : train loss 7.45058e-09 ; train accuracy 0.997444928\n",
      "Step 1412 : train loss 0 ; train accuracy 0.997446716\n",
      "Step 1413 : train loss 1.117587e-08 ; train accuracy 0.997448504\n",
      "Step 1414 : train loss 1.86264479e-08 ; train accuracy 0.997450352\n",
      "Step 1415 : train loss 3.72529e-09 ; train accuracy 0.99745214\n",
      "Step 1416 : train loss 1.117587e-08 ; train accuracy 0.997453928\n",
      "Step 1417 : train loss 1.117587e-08 ; train accuracy 0.997455776\n",
      "Step 1418 : train loss 1.49011603e-08 ; train accuracy 0.997457564\n",
      "Step 1419 : train loss 2.235174e-08 ; train accuracy 0.997459352\n",
      "Step 1420 : train loss 1.49011576e-08 ; train accuracy 0.99746114\n",
      "Step 1421 : train loss 2.6077025e-08 ; train accuracy 0.997462928\n",
      "Step 1422 : train loss 7.45057971e-09 ; train accuracy 0.997464716\n",
      "Step 1423 : train loss 1.117587e-08 ; train accuracy 0.997466505\n",
      "Step 1424 : train loss 1.86264497e-08 ; train accuracy 0.997468293\n",
      "Step 1425 : train loss 7.45058e-09 ; train accuracy 0.997470081\n",
      "Step 1426 : train loss 2.235174e-08 ; train accuracy 0.997471869\n",
      "Step 1427 : train loss 1.86264497e-08 ; train accuracy 0.997473657\n",
      "Step 1428 : train loss 0 ; train accuracy 0.997475386\n",
      "Step 1429 : train loss 0 ; train accuracy 0.997477174\n",
      "Step 1430 : train loss 7.45058e-09 ; train accuracy 0.997478962\n",
      "Step 1431 : train loss 7.45058e-09 ; train accuracy 0.99748075\n",
      "Step 1432 : train loss 7.45058e-09 ; train accuracy 0.997482479\n",
      "Step 1433 : train loss 3.72529e-09 ; train accuracy 0.997484267\n",
      "Step 1434 : train loss 7.45058e-09 ; train accuracy 0.997486\n",
      "Step 1435 : train loss 0 ; train accuracy 0.997487783\n",
      "Step 1436 : train loss 2.98023188e-08 ; train accuracy 0.997489512\n",
      "Step 1437 : train loss 1.86264497e-08 ; train accuracy 0.9974913\n",
      "Step 1438 : train loss 7.45058e-09 ; train accuracy 0.997493\n",
      "Step 1439 : train loss 0 ; train accuracy 0.997494757\n",
      "Step 1440 : train loss 3.72529e-09 ; train accuracy 0.997496545\n",
      "Step 1441 : train loss 1.86264497e-08 ; train accuracy 0.997498274\n",
      "Step 1442 : train loss 1.117587e-08 ; train accuracy 0.9975\n",
      "Step 1443 : train loss 3.72529e-09 ; train accuracy 0.997501731\n",
      "Step 1444 : train loss 3.72528959e-08 ; train accuracy 0.997503459\n",
      "Step 1445 : train loss 7.45058e-09 ; train accuracy 0.997505188\n",
      "Step 1446 : train loss 1.49011594e-08 ; train accuracy 0.997506917\n",
      "Step 1447 : train loss 1.49011603e-08 ; train accuracy 0.997508645\n",
      "Step 1448 : train loss 1.86264497e-08 ; train accuracy 0.997510374\n",
      "Step 1449 : train loss 0 ; train accuracy 0.997512102\n",
      "Step 1450 : train loss 7.45058e-09 ; train accuracy 0.997513831\n",
      "Step 1451 : train loss 7.45058e-09 ; train accuracy 0.997515559\n",
      "Step 1452 : train loss 3.72529e-09 ; train accuracy 0.997517288\n",
      "Step 1453 : train loss 7.45058e-09 ; train accuracy 0.997518957\n",
      "Step 1454 : train loss 0 ; train accuracy 0.997520685\n",
      "Step 1455 : train loss 7.45058e-09 ; train accuracy 0.997522414\n",
      "Step 1456 : train loss 2.23517382e-08 ; train accuracy 0.997524142\n",
      "Step 1457 : train loss 1.49011603e-08 ; train accuracy 0.997525811\n",
      "Step 1458 : train loss 7.45058e-09 ; train accuracy 0.99752754\n",
      "Step 1459 : train loss 0 ; train accuracy 0.997529209\n",
      "Step 1460 : train loss 1.49011594e-08 ; train accuracy 0.997530937\n",
      "Step 1461 : train loss 4.09781897e-08 ; train accuracy 0.997532606\n",
      "Step 1462 : train loss 7.45058e-09 ; train accuracy 0.997534335\n",
      "Step 1463 : train loss 3.72529e-09 ; train accuracy 0.997536\n",
      "Step 1464 : train loss 3.72528923e-08 ; train accuracy 0.997537673\n",
      "Step 1465 : train loss 1.49011603e-08 ; train accuracy 0.997539341\n",
      "Step 1466 : train loss 0 ; train accuracy 0.99754107\n",
      "Step 1467 : train loss 7.45058e-09 ; train accuracy 0.997542739\n",
      "Step 1468 : train loss 0 ; train accuracy 0.997544408\n",
      "Step 1469 : train loss 1.117587e-08 ; train accuracy 0.997546077\n",
      "Step 1470 : train loss 3.72529e-09 ; train accuracy 0.997547746\n",
      "Step 1471 : train loss 2.98023188e-08 ; train accuracy 0.997549415\n",
      "Step 1472 : train loss 0 ; train accuracy 0.997551084\n",
      "Step 1473 : train loss 2.235174e-08 ; train accuracy 0.997552752\n",
      "Step 1474 : train loss 1.49011603e-08 ; train accuracy 0.997554421\n",
      "Step 1475 : train loss 3.72529e-09 ; train accuracy 0.99755609\n",
      "Step 1476 : train loss 0 ; train accuracy 0.997557759\n",
      "Step 1477 : train loss 7.45058e-09 ; train accuracy 0.997559428\n",
      "Step 1478 : train loss 1.117587e-08 ; train accuracy 0.997561097\n",
      "Step 1479 : train loss 1.86264497e-08 ; train accuracy 0.997562706\n",
      "Step 1480 : train loss 1.117587e-08 ; train accuracy 0.997564375\n",
      "Step 1481 : train loss 0 ; train accuracy 0.997566044\n",
      "Step 1482 : train loss 7.45058e-09 ; train accuracy 0.997567654\n",
      "Step 1483 : train loss 7.45057971e-09 ; train accuracy 0.997569323\n",
      "Step 1484 : train loss 7.45058e-09 ; train accuracy 0.997571\n",
      "Step 1485 : train loss 7.45058e-09 ; train accuracy 0.997572601\n",
      "Step 1486 : train loss 7.45058e-09 ; train accuracy 0.99757427\n",
      "Step 1487 : train loss 7.45058e-09 ; train accuracy 0.997575879\n",
      "Step 1488 : train loss 3.72529e-09 ; train accuracy 0.997577548\n",
      "Step 1489 : train loss 1.11758691e-08 ; train accuracy 0.997579157\n",
      "Step 1490 : train loss 3.72529e-09 ; train accuracy 0.997580767\n",
      "Step 1491 : train loss 1.49011603e-08 ; train accuracy 0.997582436\n",
      "Step 1492 : train loss 7.45057971e-09 ; train accuracy 0.997584045\n",
      "Step 1493 : train loss 3.72529e-09 ; train accuracy 0.997585654\n",
      "Step 1494 : train loss 7.45058e-09 ; train accuracy 0.997587264\n",
      "Step 1495 : train loss 1.49011603e-08 ; train accuracy 0.997588873\n",
      "Step 1496 : train loss 3.72529e-09 ; train accuracy 0.997590542\n",
      "Step 1497 : train loss 1.86264497e-08 ; train accuracy 0.997592151\n",
      "Step 1498 : train loss 1.11758691e-08 ; train accuracy 0.99759376\n",
      "Step 1499 : train loss 7.45058e-09 ; train accuracy 0.99759537\n",
      "Step 1500 : train loss 1.86264497e-08 ; train accuracy 0.997597\n",
      "Step 1501 : train loss 7.45058e-09 ; train accuracy 0.997598588\n",
      "Step 1502 : train loss 3.3527602e-08 ; train accuracy 0.997600138\n",
      "Step 1503 : train loss 7.45057971e-09 ; train accuracy 0.997601748\n",
      "Step 1504 : train loss 0 ; train accuracy 0.997603357\n",
      "Step 1505 : train loss 1.49011603e-08 ; train accuracy 0.997604966\n",
      "Step 1506 : train loss 2.235174e-08 ; train accuracy 0.997606575\n",
      "Step 1507 : train loss 0 ; train accuracy 0.997608125\n",
      "Step 1508 : train loss 1.49011603e-08 ; train accuracy 0.997609735\n",
      "Step 1509 : train loss 3.72529e-09 ; train accuracy 0.997611344\n",
      "Step 1510 : train loss 3.72529e-09 ; train accuracy 0.997612894\n",
      "Step 1511 : train loss 7.45058e-09 ; train accuracy 0.997614503\n",
      "Step 1512 : train loss 7.45057971e-09 ; train accuracy 0.997616112\n",
      "Step 1513 : train loss 0 ; train accuracy 0.997617662\n",
      "Step 1514 : train loss 3.72529e-09 ; train accuracy 0.997619271\n",
      "Step 1515 : train loss 1.117587e-08 ; train accuracy 0.997620821\n",
      "Step 1516 : train loss 1.117587e-08 ; train accuracy 0.997622371\n",
      "Step 1517 : train loss 0 ; train accuracy 0.997624\n",
      "Step 1518 : train loss 1.49011603e-08 ; train accuracy 0.99762553\n",
      "Step 1519 : train loss 3.72528923e-08 ; train accuracy 0.997627079\n",
      "Step 1520 : train loss 1.86264497e-08 ; train accuracy 0.997628689\n",
      "Step 1521 : train loss 1.49011603e-08 ; train accuracy 0.997630239\n",
      "Step 1522 : train loss 7.45058e-09 ; train accuracy 0.997631788\n",
      "Step 1523 : train loss 7.45058e-09 ; train accuracy 0.997633338\n",
      "Step 1524 : train loss 3.72529e-09 ; train accuracy 0.997634888\n",
      "Step 1525 : train loss 7.45058e-09 ; train accuracy 0.997636497\n",
      "Step 1526 : train loss 1.117587e-08 ; train accuracy 0.997638047\n",
      "Step 1527 : train loss 3.72529e-09 ; train accuracy 0.997639596\n",
      "Step 1528 : train loss 3.72529e-09 ; train accuracy 0.997641146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1529 : train loss 7.45058e-09 ; train accuracy 0.997642696\n",
      "Step 1530 : train loss 3.72529e-09 ; train accuracy 0.997644186\n",
      "Step 1531 : train loss 1.117587e-08 ; train accuracy 0.997645736\n",
      "Step 1532 : train loss 1.11758691e-08 ; train accuracy 0.997647285\n",
      "Step 1533 : train loss 3.72529e-09 ; train accuracy 0.997648835\n",
      "Step 1534 : train loss 2.235174e-08 ; train accuracy 0.997650385\n",
      "Step 1535 : train loss 4.47034729e-08 ; train accuracy 0.997651935\n",
      "Step 1536 : train loss 2.235174e-08 ; train accuracy 0.997653425\n",
      "Step 1537 : train loss 7.45058e-09 ; train accuracy 0.997655\n",
      "Step 1538 : train loss 3.35276091e-08 ; train accuracy 0.997656524\n",
      "Step 1539 : train loss 1.117587e-08 ; train accuracy 0.997658\n",
      "Step 1540 : train loss 7.45058e-09 ; train accuracy 0.997659564\n",
      "Step 1541 : train loss 2.6077025e-08 ; train accuracy 0.997661054\n",
      "Step 1542 : train loss 2.23517382e-08 ; train accuracy 0.997662604\n",
      "Step 1543 : train loss 7.45058e-09 ; train accuracy 0.997664094\n",
      "Step 1544 : train loss 1.117587e-08 ; train accuracy 0.997665644\n",
      "Step 1545 : train loss 1.117587e-08 ; train accuracy 0.997667134\n",
      "Step 1546 : train loss 7.45058e-09 ; train accuracy 0.997668684\n",
      "Step 1547 : train loss 1.86264497e-08 ; train accuracy 0.997670174\n",
      "Step 1548 : train loss 1.86264462e-08 ; train accuracy 0.997671664\n",
      "Step 1549 : train loss 2.235174e-08 ; train accuracy 0.997673213\n",
      "Step 1550 : train loss 0 ; train accuracy 0.997674704\n",
      "Step 1551 : train loss 3.72528959e-08 ; train accuracy 0.997676194\n",
      "Step 1552 : train loss 0 ; train accuracy 0.997677684\n",
      "Step 1553 : train loss 3.72529e-09 ; train accuracy 0.997679234\n",
      "Step 1554 : train loss 3.72529e-09 ; train accuracy 0.997680724\n",
      "Step 1555 : train loss 1.117587e-08 ; train accuracy 0.997682214\n",
      "Step 1556 : train loss 1.49011603e-08 ; train accuracy 0.997683704\n",
      "Step 1557 : train loss 2.55448445e-08 ; train accuracy 0.99768436\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 1558 : train loss 1.11758691e-08 ; train accuracy 0.99768585\n",
      "Step 1559 : train loss 2.6077025e-08 ; train accuracy 0.99768734\n",
      "Step 1560 : train loss 7.45057971e-09 ; train accuracy 0.99768883\n",
      "Step 1561 : train loss 3.72529e-09 ; train accuracy 0.99769032\n",
      "Step 1562 : train loss 1.86264479e-08 ; train accuracy 0.99769181\n",
      "Step 1563 : train loss 2.235174e-08 ; train accuracy 0.997693241\n",
      "Step 1564 : train loss 1.117587e-08 ; train accuracy 0.997694731\n",
      "Step 1565 : train loss 7.45058e-09 ; train accuracy 0.997696221\n",
      "Step 1566 : train loss 1.49011603e-08 ; train accuracy 0.997697711\n",
      "Step 1567 : train loss 1.49011603e-08 ; train accuracy 0.997699201\n",
      "Step 1568 : train loss 1.86264497e-08 ; train accuracy 0.997700632\n",
      "Step 1569 : train loss 3.72528923e-08 ; train accuracy 0.997702122\n",
      "Step 1570 : train loss 3.72529e-09 ; train accuracy 0.997703612\n",
      "Step 1571 : train loss 1.117587e-08 ; train accuracy 0.997705042\n",
      "Step 1572 : train loss 0 ; train accuracy 0.997706532\n",
      "Step 1573 : train loss 1.49011576e-08 ; train accuracy 0.997707963\n",
      "Step 1574 : train loss 3.72529e-09 ; train accuracy 0.997709453\n",
      "Step 1575 : train loss 1.117587e-08 ; train accuracy 0.997710884\n",
      "Step 1576 : train loss 7.45058e-09 ; train accuracy 0.997712374\n",
      "Step 1577 : train loss 0 ; train accuracy 0.997713804\n",
      "Step 1578 : train loss 3.72529e-09 ; train accuracy 0.997715235\n",
      "Step 1579 : train loss 3.72529e-09 ; train accuracy 0.997716725\n",
      "Step 1580 : train loss 0 ; train accuracy 0.997718155\n",
      "Step 1581 : train loss 3.72529e-09 ; train accuracy 0.997719586\n",
      "Step 1582 : train loss 3.72529e-09 ; train accuracy 0.997721076\n",
      "Step 1583 : train loss 3.72529e-09 ; train accuracy 0.997722507\n",
      "Step 1584 : train loss 1.11758691e-08 ; train accuracy 0.997723937\n",
      "Step 1585 : train loss 7.45058e-09 ; train accuracy 0.997725368\n",
      "Step 1586 : train loss 0 ; train accuracy 0.997726798\n",
      "Step 1587 : train loss 1.49011603e-08 ; train accuracy 0.997728288\n",
      "Step 1588 : train loss 7.45058e-09 ; train accuracy 0.997729719\n",
      "Step 1589 : train loss 0 ; train accuracy 0.997731149\n",
      "Step 1590 : train loss 0 ; train accuracy 0.99773258\n",
      "Step 1591 : train loss 1.117587e-08 ; train accuracy 0.997734\n",
      "Step 1592 : train loss 1.49011594e-08 ; train accuracy 0.997735441\n",
      "Step 1593 : train loss 1.49011594e-08 ; train accuracy 0.997736871\n",
      "Step 1594 : train loss 2.98023188e-08 ; train accuracy 0.997738242\n",
      "Step 1595 : train loss 3.72529e-09 ; train accuracy 0.997739673\n",
      "Step 1596 : train loss 3.72529e-09 ; train accuracy 0.997741103\n",
      "Step 1597 : train loss 1.117587e-08 ; train accuracy 0.997742534\n",
      "Step 1598 : train loss 2.235174e-08 ; train accuracy 0.997743964\n",
      "Step 1599 : train loss 3.72529e-09 ; train accuracy 0.997745335\n",
      "Step 1600 : train loss 7.45057971e-09 ; train accuracy 0.997746766\n",
      "Step 1601 : train loss 3.72529e-09 ; train accuracy 0.997748196\n",
      "Step 1602 : train loss 7.45058e-09 ; train accuracy 0.997749627\n",
      "Step 1603 : train loss 1.86264479e-08 ; train accuracy 0.997751\n",
      "Step 1604 : train loss 7.45057971e-09 ; train accuracy 0.997752428\n",
      "Step 1605 : train loss 3.72529e-09 ; train accuracy 0.997753799\n",
      "Step 1606 : train loss 1.117587e-08 ; train accuracy 0.997755229\n",
      "Step 1607 : train loss 7.45058e-09 ; train accuracy 0.9977566\n",
      "Step 1608 : train loss 1.117587e-08 ; train accuracy 0.997758031\n",
      "Step 1609 : train loss 2.60770285e-08 ; train accuracy 0.997759402\n",
      "Step 1610 : train loss 1.86264497e-08 ; train accuracy 0.997760832\n",
      "Step 1611 : train loss 0 ; train accuracy 0.997762203\n",
      "Step 1612 : train loss 3.72529e-09 ; train accuracy 0.997763574\n",
      "Step 1613 : train loss 3.72529e-09 ; train accuracy 0.997765\n",
      "Step 1614 : train loss 3.35276091e-08 ; train accuracy 0.997766376\n",
      "Step 1615 : train loss 1.49011576e-08 ; train accuracy 0.997767746\n",
      "Step 1616 : train loss 0 ; train accuracy 0.997769177\n",
      "Step 1617 : train loss 1.117587e-08 ; train accuracy 0.997770548\n",
      "Step 1618 : train loss 1.117587e-08 ; train accuracy 0.997771919\n",
      "Step 1619 : train loss 7.45058e-09 ; train accuracy 0.99777329\n",
      "Step 1620 : train loss 1.117587e-08 ; train accuracy 0.997774661\n",
      "Step 1621 : train loss 0 ; train accuracy 0.997776031\n",
      "Step 1622 : train loss 2.98023171e-08 ; train accuracy 0.997777462\n",
      "Step 1623 : train loss 1.86264497e-08 ; train accuracy 0.997778833\n",
      "Step 1624 : train loss 4.09781862e-08 ; train accuracy 0.997780204\n",
      "Step 1625 : train loss 1.117587e-08 ; train accuracy 0.997781575\n",
      "Step 1626 : train loss 0 ; train accuracy 0.997782946\n",
      "Step 1627 : train loss 2.60770303e-08 ; train accuracy 0.997784257\n",
      "Step 1628 : train loss 3.72529e-09 ; train accuracy 0.997785628\n",
      "Step 1629 : train loss 0 ; train accuracy 0.997787\n",
      "Step 1630 : train loss 1.117587e-08 ; train accuracy 0.99778837\n",
      "Step 1631 : train loss 3.72529e-09 ; train accuracy 0.997789741\n",
      "Step 1632 : train loss 3.72528923e-08 ; train accuracy 0.997791111\n",
      "Step 1633 : train loss 7.45058e-09 ; train accuracy 0.997792423\n",
      "Step 1634 : train loss 1.117587e-08 ; train accuracy 0.997793794\n",
      "Step 1635 : train loss 7.45058e-09 ; train accuracy 0.997795165\n",
      "Step 1636 : train loss 0 ; train accuracy 0.997796535\n",
      "Step 1637 : train loss 3.72529e-09 ; train accuracy 0.997797847\n",
      "Step 1638 : train loss 1.86264497e-08 ; train accuracy 0.997799218\n",
      "Step 1639 : train loss 7.45058e-09 ; train accuracy 0.997800529\n",
      "Step 1640 : train loss 7.45058e-09 ; train accuracy 0.9978019\n",
      "Step 1641 : train loss 0 ; train accuracy 0.997803271\n",
      "Step 1642 : train loss 7.45058e-09 ; train accuracy 0.997804582\n",
      "Step 1643 : train loss 7.45058e-09 ; train accuracy 0.997805953\n",
      "Step 1644 : train loss 7.45058e-09 ; train accuracy 0.997807264\n",
      "Step 1645 : train loss 1.49011594e-08 ; train accuracy 0.997808635\n",
      "Step 1646 : train loss 2.235174e-08 ; train accuracy 0.997809947\n",
      "Step 1647 : train loss 1.117587e-08 ; train accuracy 0.997811258\n",
      "Step 1648 : train loss 0 ; train accuracy 0.997812629\n",
      "Step 1649 : train loss 1.49011594e-08 ; train accuracy 0.99781394\n",
      "Step 1650 : train loss 0 ; train accuracy 0.997815251\n",
      "Step 1651 : train loss 3.72529e-09 ; train accuracy 0.997816622\n",
      "Step 1652 : train loss 7.45058e-09 ; train accuracy 0.997817934\n",
      "Step 1653 : train loss 1.117587e-08 ; train accuracy 0.997819245\n",
      "Step 1654 : train loss 1.117587e-08 ; train accuracy 0.997820556\n",
      "Step 1655 : train loss 0 ; train accuracy 0.997821867\n",
      "Step 1656 : train loss 1.49011594e-08 ; train accuracy 0.997823179\n",
      "Step 1657 : train loss 0 ; train accuracy 0.99782455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1658 : train loss 1.117587e-08 ; train accuracy 0.997825861\n",
      "Step 1659 : train loss 0 ; train accuracy 0.997827172\n",
      "Step 1660 : train loss 3.72529e-09 ; train accuracy 0.997828484\n",
      "Step 1661 : train loss 3.72529e-09 ; train accuracy 0.997829795\n",
      "Step 1662 : train loss 3.72529e-09 ; train accuracy 0.997831106\n",
      "Step 1663 : train loss 3.72529e-09 ; train accuracy 0.997832417\n",
      "Step 1664 : train loss 0 ; train accuracy 0.997833729\n",
      "Step 1665 : train loss 3.72529e-09 ; train accuracy 0.997835\n",
      "Step 1666 : train loss 2.235174e-08 ; train accuracy 0.997836292\n",
      "Step 1667 : train loss 3.72529e-09 ; train accuracy 0.997837603\n",
      "Step 1668 : train loss 3.72529e-09 ; train accuracy 0.997838914\n",
      "Step 1669 : train loss 1.49011603e-08 ; train accuracy 0.997840226\n",
      "Step 1670 : train loss 1.49011594e-08 ; train accuracy 0.997841537\n",
      "Step 1671 : train loss 3.72529e-09 ; train accuracy 0.997842789\n",
      "Step 1672 : train loss 1.117587e-08 ; train accuracy 0.9978441\n",
      "Step 1673 : train loss 7.45057971e-09 ; train accuracy 0.997845411\n",
      "Step 1674 : train loss 1.86264497e-08 ; train accuracy 0.997846663\n",
      "Step 1675 : train loss 1.49011603e-08 ; train accuracy 0.997848\n",
      "Step 1676 : train loss 3.72528923e-08 ; train accuracy 0.997849286\n",
      "Step 1677 : train loss 3.72529e-09 ; train accuracy 0.997850537\n",
      "Step 1678 : train loss 2.235174e-08 ; train accuracy 0.997851849\n",
      "Step 1679 : train loss 3.35276056e-08 ; train accuracy 0.9978531\n",
      "Step 1680 : train loss 3.72529e-09 ; train accuracy 0.997854412\n",
      "Step 1681 : train loss 7.45057971e-09 ; train accuracy 0.997855663\n",
      "Step 1682 : train loss 1.117587e-08 ; train accuracy 0.997857\n",
      "Step 1683 : train loss 0 ; train accuracy 0.997858226\n",
      "Step 1684 : train loss 7.45058e-09 ; train accuracy 0.997859538\n",
      "Step 1685 : train loss 7.45057971e-09 ; train accuracy 0.997860789\n",
      "Step 1686 : train loss 3.72529e-09 ; train accuracy 0.997862041\n",
      "Step 1687 : train loss 0 ; train accuracy 0.997863352\n",
      "Step 1688 : train loss 7.45058e-09 ; train accuracy 0.997864604\n",
      "Step 1689 : train loss 7.45058e-09 ; train accuracy 0.997865856\n",
      "Step 1690 : train loss 1.49011594e-08 ; train accuracy 0.997867107\n",
      "Step 1691 : train loss 7.45058e-09 ; train accuracy 0.997868419\n",
      "Step 1692 : train loss 3.72529e-09 ; train accuracy 0.99786967\n",
      "Step 1693 : train loss 1.86264497e-08 ; train accuracy 0.997870922\n",
      "Step 1694 : train loss 0 ; train accuracy 0.997872174\n",
      "Step 1695 : train loss 1.117587e-08 ; train accuracy 0.997873425\n",
      "Step 1696 : train loss 1.49011594e-08 ; train accuracy 0.997874677\n",
      "Step 1697 : train loss 3.72529e-09 ; train accuracy 0.997875929\n",
      "Step 1698 : train loss 1.49011603e-08 ; train accuracy 0.99787724\n",
      "Step 1699 : train loss 7.45058e-09 ; train accuracy 0.997878492\n",
      "Step 1700 : train loss 1.117587e-08 ; train accuracy 0.997879744\n",
      "Step 1701 : train loss 3.72529e-09 ; train accuracy 0.997881\n",
      "Step 1702 : train loss 7.45058e-09 ; train accuracy 0.997882187\n",
      "Step 1703 : train loss 1.86264479e-08 ; train accuracy 0.997883439\n",
      "Step 1704 : train loss 3.72529e-09 ; train accuracy 0.997884691\n",
      "Step 1705 : train loss 1.49011594e-08 ; train accuracy 0.997885942\n",
      "Step 1706 : train loss 3.72529e-09 ; train accuracy 0.997887194\n",
      "Step 1707 : train loss 1.49011603e-08 ; train accuracy 0.997888446\n",
      "Step 1708 : train loss 3.72529e-09 ; train accuracy 0.997889698\n",
      "Step 1709 : train loss 7.45058e-09 ; train accuracy 0.99789089\n",
      "Step 1710 : train loss 1.49011603e-08 ; train accuracy 0.997892141\n",
      "Step 1711 : train loss 1.49011603e-08 ; train accuracy 0.997893393\n",
      "Step 1712 : train loss 7.45058e-09 ; train accuracy 0.997894645\n",
      "Step 1713 : train loss 1.49011603e-08 ; train accuracy 0.997895837\n",
      "Step 1714 : train loss 2.235174e-08 ; train accuracy 0.997897089\n",
      "Step 1715 : train loss 1.117587e-08 ; train accuracy 0.99789834\n",
      "Step 1716 : train loss 4.09781862e-08 ; train accuracy 0.997899532\n",
      "Step 1717 : train loss 3.3527602e-08 ; train accuracy 0.997900784\n",
      "Step 1718 : train loss 2.60770285e-08 ; train accuracy 0.997902\n",
      "Step 1719 : train loss 3.72529e-09 ; train accuracy 0.997903228\n",
      "Step 1720 : train loss 1.86264497e-08 ; train accuracy 0.99790442\n",
      "Step 1721 : train loss 7.45058e-09 ; train accuracy 0.997905672\n",
      "Step 1722 : train loss 2.23517382e-08 ; train accuracy 0.997906864\n",
      "Step 1723 : train loss 3.72529e-09 ; train accuracy 0.997908115\n",
      "Step 1724 : train loss 1.117587e-08 ; train accuracy 0.997909307\n",
      "Step 1725 : train loss 7.45057971e-09 ; train accuracy 0.997910559\n",
      "Step 1726 : train loss 7.45058e-09 ; train accuracy 0.997911751\n",
      "Step 1727 : train loss 3.72529e-09 ; train accuracy 0.997912943\n",
      "Step 1728 : train loss 2.60770285e-08 ; train accuracy 0.997914195\n",
      "Step 1729 : train loss 7.45058e-09 ; train accuracy 0.997915387\n",
      "Step 1730 : train loss 8.51494875e-09 ; train accuracy 0.997915924\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 1731 : train loss 2.98023153e-08 ; train accuracy 0.997917116\n",
      "Step 1732 : train loss 0 ; train accuracy 0.997918308\n",
      "Step 1733 : train loss 1.49011594e-08 ; train accuracy 0.997919559\n",
      "Step 1734 : train loss 2.98023188e-08 ; train accuracy 0.997920752\n",
      "Step 1735 : train loss 7.45057971e-09 ; train accuracy 0.997921944\n",
      "Step 1736 : train loss 0 ; train accuracy 0.997923136\n",
      "Step 1737 : train loss 2.98023117e-08 ; train accuracy 0.997924328\n",
      "Step 1738 : train loss 7.45058e-09 ; train accuracy 0.99792552\n",
      "Step 1739 : train loss 0 ; train accuracy 0.997926712\n",
      "Step 1740 : train loss 1.49011603e-08 ; train accuracy 0.997927904\n",
      "Step 1741 : train loss 0 ; train accuracy 0.997929096\n",
      "Step 1742 : train loss 7.45058e-09 ; train accuracy 0.997930288\n",
      "Step 1743 : train loss 7.45057971e-09 ; train accuracy 0.99793148\n",
      "Step 1744 : train loss 3.72529e-09 ; train accuracy 0.997932673\n",
      "Step 1745 : train loss 1.117587e-08 ; train accuracy 0.997933865\n",
      "Step 1746 : train loss 1.117587e-08 ; train accuracy 0.997935057\n",
      "Step 1747 : train loss 3.72529e-09 ; train accuracy 0.997936249\n",
      "Step 1748 : train loss 3.72529e-09 ; train accuracy 0.997937441\n",
      "Step 1749 : train loss 2.23517382e-08 ; train accuracy 0.997938633\n",
      "Step 1750 : train loss 3.72529e-09 ; train accuracy 0.997939825\n",
      "Step 1751 : train loss 7.45057971e-09 ; train accuracy 0.997940958\n",
      "Step 1752 : train loss 1.86264497e-08 ; train accuracy 0.99794215\n",
      "Step 1753 : train loss 1.11758691e-08 ; train accuracy 0.997943342\n",
      "Step 1754 : train loss 0 ; train accuracy 0.997944534\n",
      "Step 1755 : train loss 7.45058e-09 ; train accuracy 0.997945666\n",
      "Step 1756 : train loss 0 ; train accuracy 0.997946858\n",
      "Step 1757 : train loss 1.49011576e-08 ; train accuracy 0.99794805\n",
      "Step 1758 : train loss 7.45058e-09 ; train accuracy 0.997949183\n",
      "Step 1759 : train loss 7.45058e-09 ; train accuracy 0.997950375\n",
      "Step 1760 : train loss 0 ; train accuracy 0.997951567\n",
      "Step 1761 : train loss 0 ; train accuracy 0.9979527\n",
      "Step 1762 : train loss 1.117587e-08 ; train accuracy 0.997953892\n",
      "Step 1763 : train loss 1.117587e-08 ; train accuracy 0.997955\n",
      "Step 1764 : train loss 3.72529e-09 ; train accuracy 0.997956216\n",
      "Step 1765 : train loss 1.49011576e-08 ; train accuracy 0.997957349\n",
      "Step 1766 : train loss 1.117587e-08 ; train accuracy 0.997958541\n",
      "Step 1767 : train loss 1.49011603e-08 ; train accuracy 0.997959673\n",
      "Step 1768 : train loss 0 ; train accuracy 0.997960865\n",
      "Step 1769 : train loss 1.86264497e-08 ; train accuracy 0.997962\n",
      "Step 1770 : train loss 0 ; train accuracy 0.99796313\n",
      "Step 1771 : train loss 1.49011603e-08 ; train accuracy 0.997964323\n",
      "Step 1772 : train loss 1.117587e-08 ; train accuracy 0.997965455\n",
      "Step 1773 : train loss 1.86264479e-08 ; train accuracy 0.997966588\n",
      "Step 1774 : train loss 1.11758691e-08 ; train accuracy 0.99796778\n",
      "Step 1775 : train loss 1.117587e-08 ; train accuracy 0.997968912\n",
      "Step 1776 : train loss 1.49011603e-08 ; train accuracy 0.997970045\n",
      "Step 1777 : train loss 7.45058e-09 ; train accuracy 0.997971237\n",
      "Step 1778 : train loss 0 ; train accuracy 0.997972369\n",
      "Step 1779 : train loss 1.117587e-08 ; train accuracy 0.997973502\n",
      "Step 1780 : train loss 3.72529e-09 ; train accuracy 0.997974634\n",
      "Step 1781 : train loss 1.49011603e-08 ; train accuracy 0.997975767\n",
      "Step 1782 : train loss 7.45057971e-09 ; train accuracy 0.997976899\n",
      "Step 1783 : train loss 1.117587e-08 ; train accuracy 0.997978032\n",
      "Step 1784 : train loss 0 ; train accuracy 0.997979224\n",
      "Step 1785 : train loss 1.49011603e-08 ; train accuracy 0.997980356\n",
      "Step 1786 : train loss 0 ; train accuracy 0.997981489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1787 : train loss 0 ; train accuracy 0.997982621\n",
      "Step 1788 : train loss 7.45057971e-09 ; train accuracy 0.997983754\n",
      "Step 1789 : train loss 3.72529e-09 ; train accuracy 0.997984886\n",
      "Step 1790 : train loss 1.117587e-08 ; train accuracy 0.997986\n",
      "Step 1791 : train loss 1.49011603e-08 ; train accuracy 0.997987092\n",
      "Step 1792 : train loss 0 ; train accuracy 0.997988224\n",
      "Step 1793 : train loss 7.45058e-09 ; train accuracy 0.997989357\n",
      "Step 1794 : train loss 2.98023171e-08 ; train accuracy 0.997990489\n",
      "Step 1795 : train loss 3.35276056e-08 ; train accuracy 0.997991621\n",
      "Step 1796 : train loss 0 ; train accuracy 0.997992754\n",
      "Step 1797 : train loss 1.86264497e-08 ; train accuracy 0.997993886\n",
      "Step 1798 : train loss 1.117587e-08 ; train accuracy 0.997994959\n",
      "Step 1799 : train loss 7.45058e-09 ; train accuracy 0.997996092\n",
      "Step 1800 : train loss 1.49011576e-08 ; train accuracy 0.997997224\n",
      "Step 1801 : train loss 3.72529e-09 ; train accuracy 0.997998357\n",
      "Step 1802 : train loss 1.49011594e-08 ; train accuracy 0.99799943\n",
      "Step 1803 : train loss 7.45058e-09 ; train accuracy 0.998000562\n",
      "Step 1804 : train loss 1.117587e-08 ; train accuracy 0.998001695\n",
      "Step 1805 : train loss 0 ; train accuracy 0.998002768\n",
      "Step 1806 : train loss 7.45058e-09 ; train accuracy 0.9980039\n",
      "Step 1807 : train loss 2.23517382e-08 ; train accuracy 0.998005\n",
      "Step 1808 : train loss 3.72529e-09 ; train accuracy 0.998006105\n",
      "Step 1809 : train loss 3.72529e-09 ; train accuracy 0.998007238\n",
      "Step 1810 : train loss 1.49011594e-08 ; train accuracy 0.998008311\n",
      "Step 1811 : train loss 7.45058e-09 ; train accuracy 0.998009443\n",
      "Step 1812 : train loss 7.45058e-09 ; train accuracy 0.998010516\n",
      "Step 1813 : train loss 3.72529e-09 ; train accuracy 0.998011649\n",
      "Step 1814 : train loss 3.72529e-09 ; train accuracy 0.998012722\n",
      "Step 1815 : train loss 1.117587e-08 ; train accuracy 0.998013794\n",
      "Step 1816 : train loss 1.117587e-08 ; train accuracy 0.998014927\n",
      "Step 1817 : train loss 1.49011603e-08 ; train accuracy 0.998016\n",
      "Step 1818 : train loss 3.72529e-09 ; train accuracy 0.998017132\n",
      "Step 1819 : train loss 7.45058e-09 ; train accuracy 0.998018205\n",
      "Step 1820 : train loss 1.49011594e-08 ; train accuracy 0.998019278\n",
      "Step 1821 : train loss 3.72529e-09 ; train accuracy 0.998020411\n",
      "Step 1822 : train loss 1.117587e-08 ; train accuracy 0.998021483\n",
      "Step 1823 : train loss 3.72529e-09 ; train accuracy 0.998022556\n",
      "Step 1824 : train loss 7.45058e-09 ; train accuracy 0.998023629\n",
      "Step 1825 : train loss 3.72529e-09 ; train accuracy 0.998024762\n",
      "Step 1826 : train loss 3.72529e-09 ; train accuracy 0.998025835\n",
      "Step 1827 : train loss 1.117587e-08 ; train accuracy 0.998026907\n",
      "Step 1828 : train loss 3.72529e-09 ; train accuracy 0.998028\n",
      "Step 1829 : train loss 0 ; train accuracy 0.998029053\n",
      "Step 1830 : train loss 1.86264497e-08 ; train accuracy 0.998030126\n",
      "Step 1831 : train loss 7.45058e-09 ; train accuracy 0.998031199\n",
      "Step 1832 : train loss 1.117587e-08 ; train accuracy 0.998032331\n",
      "Step 1833 : train loss 7.45058e-09 ; train accuracy 0.998033404\n",
      "Step 1834 : train loss 0 ; train accuracy 0.998034477\n",
      "Step 1835 : train loss 2.6077025e-08 ; train accuracy 0.99803555\n",
      "Step 1836 : train loss 7.45058e-09 ; train accuracy 0.998036623\n",
      "Step 1837 : train loss 7.45057971e-09 ; train accuracy 0.998037696\n",
      "Step 1838 : train loss 0 ; train accuracy 0.998038769\n",
      "Step 1839 : train loss 1.117587e-08 ; train accuracy 0.998039842\n",
      "Step 1840 : train loss 1.49011603e-08 ; train accuracy 0.998040915\n",
      "Step 1841 : train loss 1.49011603e-08 ; train accuracy 0.998041928\n",
      "Step 1842 : train loss 1.117587e-08 ; train accuracy 0.998043\n",
      "Step 1843 : train loss 3.72529e-09 ; train accuracy 0.998044074\n",
      "Step 1844 : train loss 0 ; train accuracy 0.998045146\n",
      "Step 1845 : train loss 7.45057971e-09 ; train accuracy 0.998046219\n",
      "Step 1846 : train loss 3.72529e-09 ; train accuracy 0.998047292\n",
      "Step 1847 : train loss 3.35276056e-08 ; train accuracy 0.998048306\n",
      "Step 1848 : train loss 7.45058e-09 ; train accuracy 0.998049378\n",
      "Step 1849 : train loss 7.45058e-09 ; train accuracy 0.998050451\n",
      "Step 1850 : train loss 7.45058e-09 ; train accuracy 0.998051524\n",
      "Step 1851 : train loss 1.49011594e-08 ; train accuracy 0.998052537\n",
      "Step 1852 : train loss 3.72529e-09 ; train accuracy 0.99805361\n",
      "Step 1853 : train loss 1.117587e-08 ; train accuracy 0.998054683\n",
      "Step 1854 : train loss 7.45058e-09 ; train accuracy 0.998055696\n",
      "Step 1855 : train loss 3.72528923e-08 ; train accuracy 0.998056769\n",
      "Step 1856 : train loss 1.117587e-08 ; train accuracy 0.998057842\n",
      "Step 1857 : train loss 0 ; train accuracy 0.998058856\n",
      "Step 1858 : train loss 0 ; train accuracy 0.998059928\n",
      "Step 1859 : train loss 3.72529e-08 ; train accuracy 0.998060942\n",
      "Step 1860 : train loss 7.45058e-09 ; train accuracy 0.998062\n",
      "Step 1861 : train loss 0 ; train accuracy 0.998063087\n",
      "Step 1862 : train loss 0 ; train accuracy 0.998064101\n",
      "Step 1863 : train loss 7.45058e-09 ; train accuracy 0.998065174\n",
      "Step 1864 : train loss 1.86264497e-08 ; train accuracy 0.998066187\n",
      "Step 1865 : train loss 7.45057971e-09 ; train accuracy 0.9980672\n",
      "Step 1866 : train loss 7.45058e-09 ; train accuracy 0.998068273\n",
      "Step 1867 : train loss 3.72529e-09 ; train accuracy 0.998069286\n",
      "Step 1868 : train loss 7.45057971e-09 ; train accuracy 0.998070359\n",
      "Step 1869 : train loss 7.45058e-09 ; train accuracy 0.998071373\n",
      "Step 1870 : train loss 1.117587e-08 ; train accuracy 0.998072386\n",
      "Step 1871 : train loss 3.72529e-09 ; train accuracy 0.998073459\n",
      "Step 1872 : train loss 1.117587e-08 ; train accuracy 0.998074472\n",
      "Step 1873 : train loss 3.72529e-09 ; train accuracy 0.998075485\n",
      "Step 1874 : train loss 3.72529e-09 ; train accuracy 0.998076558\n",
      "Step 1875 : train loss 3.35276091e-08 ; train accuracy 0.998077571\n",
      "Step 1876 : train loss 3.72529e-09 ; train accuracy 0.998078585\n",
      "Step 1877 : train loss 7.45058e-09 ; train accuracy 0.998079598\n",
      "Step 1878 : train loss 3.72529e-09 ; train accuracy 0.998080671\n",
      "Step 1879 : train loss 7.45058e-09 ; train accuracy 0.998081684\n",
      "Step 1880 : train loss 3.72529e-09 ; train accuracy 0.998082697\n",
      "Step 1881 : train loss 3.72529e-09 ; train accuracy 0.998083711\n",
      "Step 1882 : train loss 1.117587e-08 ; train accuracy 0.998084724\n",
      "Step 1883 : train loss 7.45058e-09 ; train accuracy 0.998085737\n",
      "Step 1884 : train loss 1.117587e-08 ; train accuracy 0.998086751\n",
      "Step 1885 : train loss 7.45057971e-09 ; train accuracy 0.998087823\n",
      "Step 1886 : train loss 2.98023153e-08 ; train accuracy 0.998088837\n",
      "Step 1887 : train loss 4.47034729e-08 ; train accuracy 0.99808985\n",
      "Step 1888 : train loss 7.45058e-09 ; train accuracy 0.998090863\n",
      "Step 1889 : train loss 3.35276056e-08 ; train accuracy 0.998091877\n",
      "Step 1890 : train loss 1.117587e-08 ; train accuracy 0.99809289\n",
      "Step 1891 : train loss 1.117587e-08 ; train accuracy 0.998093903\n",
      "Step 1892 : train loss 1.86264497e-08 ; train accuracy 0.998094916\n",
      "Step 1893 : train loss 1.86264479e-08 ; train accuracy 0.99809593\n",
      "Step 1894 : train loss 3.72529e-09 ; train accuracy 0.998096883\n",
      "Step 1895 : train loss 1.117587e-08 ; train accuracy 0.998097897\n",
      "Step 1896 : train loss 1.49011603e-08 ; train accuracy 0.99809891\n",
      "Step 1897 : train loss 3.72529e-09 ; train accuracy 0.998099923\n",
      "Step 1898 : train loss 7.45058e-09 ; train accuracy 0.998100936\n",
      "Step 1899 : train loss 1.117587e-08 ; train accuracy 0.99810195\n",
      "Step 1900 : train loss 3.72529e-09 ; train accuracy 0.998102963\n",
      "Step 1901 : train loss 7.45057971e-09 ; train accuracy 0.998103917\n",
      "Step 1902 : train loss 1.117587e-08 ; train accuracy 0.99810493\n",
      "Step 1903 : train loss 8.51494875e-09 ; train accuracy 0.998105347\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 1904 : train loss 1.117587e-08 ; train accuracy 0.99810636\n",
      "Step 1905 : train loss 3.72529e-09 ; train accuracy 0.998107374\n",
      "Step 1906 : train loss 0 ; train accuracy 0.998108387\n",
      "Step 1907 : train loss 3.35276091e-08 ; train accuracy 0.998109341\n",
      "Step 1908 : train loss 1.49011603e-08 ; train accuracy 0.998110354\n",
      "Step 1909 : train loss 4.09781791e-08 ; train accuracy 0.998111367\n",
      "Step 1910 : train loss 1.117587e-08 ; train accuracy 0.998112321\n",
      "Step 1911 : train loss 3.72529e-09 ; train accuracy 0.998113334\n",
      "Step 1912 : train loss 7.45058e-09 ; train accuracy 0.998114347\n",
      "Step 1913 : train loss 3.72529e-09 ; train accuracy 0.998115301\n",
      "Step 1914 : train loss 0 ; train accuracy 0.998116314\n",
      "Step 1915 : train loss 1.49011576e-08 ; train accuracy 0.998117268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1916 : train loss 7.45058e-09 ; train accuracy 0.998118281\n",
      "Step 1917 : train loss 3.72529e-09 ; train accuracy 0.998119235\n",
      "Step 1918 : train loss 0 ; train accuracy 0.998120248\n",
      "Step 1919 : train loss 7.45057971e-09 ; train accuracy 0.998121202\n",
      "Step 1920 : train loss 3.72529e-09 ; train accuracy 0.998122215\n",
      "Step 1921 : train loss 3.72529e-09 ; train accuracy 0.998123169\n",
      "Step 1922 : train loss 2.235174e-08 ; train accuracy 0.998124182\n",
      "Step 1923 : train loss 3.72529e-09 ; train accuracy 0.998125136\n",
      "Step 1924 : train loss 1.49011603e-08 ; train accuracy 0.998126149\n",
      "Step 1925 : train loss 1.49011594e-08 ; train accuracy 0.998127103\n",
      "Step 1926 : train loss 1.11758691e-08 ; train accuracy 0.998128057\n",
      "Step 1927 : train loss 2.23517365e-08 ; train accuracy 0.99812907\n",
      "Step 1928 : train loss 7.45058e-09 ; train accuracy 0.99813\n",
      "Step 1929 : train loss 7.45057971e-09 ; train accuracy 0.998131\n",
      "Step 1930 : train loss 0 ; train accuracy 0.998132\n",
      "Step 1931 : train loss 1.117587e-08 ; train accuracy 0.998132944\n",
      "Step 1932 : train loss 3.72529e-09 ; train accuracy 0.998133898\n",
      "Step 1933 : train loss 0 ; train accuracy 0.998134851\n",
      "Step 1934 : train loss 7.45058e-09 ; train accuracy 0.998135865\n",
      "Step 1935 : train loss 1.86264497e-08 ; train accuracy 0.998136818\n",
      "Step 1936 : train loss 3.72529e-09 ; train accuracy 0.998137772\n",
      "Step 1937 : train loss 1.49011603e-08 ; train accuracy 0.998138726\n",
      "Step 1938 : train loss 1.11758691e-08 ; train accuracy 0.998139679\n",
      "Step 1939 : train loss 0 ; train accuracy 0.998140633\n",
      "Step 1940 : train loss 7.45058e-09 ; train accuracy 0.998141646\n",
      "Step 1941 : train loss 3.72529e-09 ; train accuracy 0.9981426\n",
      "Step 1942 : train loss 1.117587e-08 ; train accuracy 0.998143554\n",
      "Step 1943 : train loss 1.117587e-08 ; train accuracy 0.998144507\n",
      "Step 1944 : train loss 0 ; train accuracy 0.998145461\n",
      "Step 1945 : train loss 1.117587e-08 ; train accuracy 0.998146415\n",
      "Step 1946 : train loss 1.117587e-08 ; train accuracy 0.998147368\n",
      "Step 1947 : train loss 0 ; train accuracy 0.998148322\n",
      "Step 1948 : train loss 3.72529e-09 ; train accuracy 0.998149276\n",
      "Step 1949 : train loss 1.117587e-08 ; train accuracy 0.998150229\n",
      "Step 1950 : train loss 3.72529e-09 ; train accuracy 0.998151183\n",
      "Step 1951 : train loss 7.45057971e-09 ; train accuracy 0.998152137\n",
      "Step 1952 : train loss 7.45058e-09 ; train accuracy 0.99815309\n",
      "Step 1953 : train loss 7.45057971e-09 ; train accuracy 0.998154044\n",
      "Step 1954 : train loss 7.45057971e-09 ; train accuracy 0.998155\n",
      "Step 1955 : train loss 1.86264479e-08 ; train accuracy 0.998155951\n",
      "Step 1956 : train loss 3.72529e-09 ; train accuracy 0.998156846\n",
      "Step 1957 : train loss 7.45058e-09 ; train accuracy 0.998157799\n",
      "Step 1958 : train loss 1.117587e-08 ; train accuracy 0.998158753\n",
      "Step 1959 : train loss 7.45058e-09 ; train accuracy 0.998159707\n",
      "Step 1960 : train loss 1.117587e-08 ; train accuracy 0.99816066\n",
      "Step 1961 : train loss 3.72529e-09 ; train accuracy 0.998161614\n",
      "Step 1962 : train loss 1.49011603e-08 ; train accuracy 0.998162508\n",
      "Step 1963 : train loss 0 ; train accuracy 0.998163462\n",
      "Step 1964 : train loss 3.72529e-09 ; train accuracy 0.998164415\n",
      "Step 1965 : train loss 2.23517382e-08 ; train accuracy 0.998165369\n",
      "Step 1966 : train loss 3.72528959e-08 ; train accuracy 0.998166263\n",
      "Step 1967 : train loss 2.60770285e-08 ; train accuracy 0.998167217\n",
      "Step 1968 : train loss 0 ; train accuracy 0.99816817\n",
      "Step 1969 : train loss 1.49011594e-08 ; train accuracy 0.998169065\n",
      "Step 1970 : train loss 1.49011576e-08 ; train accuracy 0.99817\n",
      "Step 1971 : train loss 0 ; train accuracy 0.998171\n",
      "Step 1972 : train loss 7.45058e-09 ; train accuracy 0.998171866\n",
      "Step 1973 : train loss 3.72529e-09 ; train accuracy 0.99817282\n",
      "Step 1974 : train loss 1.117587e-08 ; train accuracy 0.998173714\n",
      "Step 1975 : train loss 3.72529e-09 ; train accuracy 0.998174667\n",
      "Step 1976 : train loss 1.117587e-08 ; train accuracy 0.998175561\n",
      "Step 1977 : train loss 1.117587e-08 ; train accuracy 0.998176515\n",
      "Step 1978 : train loss 1.117587e-08 ; train accuracy 0.998177409\n",
      "Step 1979 : train loss 2.235174e-08 ; train accuracy 0.998178363\n",
      "Step 1980 : train loss 7.45058e-09 ; train accuracy 0.998179257\n",
      "Step 1981 : train loss 1.117587e-08 ; train accuracy 0.998180211\n",
      "Step 1982 : train loss 2.6077025e-08 ; train accuracy 0.998181105\n",
      "Step 1983 : train loss 3.72529e-09 ; train accuracy 0.998182058\n",
      "Step 1984 : train loss 3.72529e-09 ; train accuracy 0.998182952\n",
      "Step 1985 : train loss 3.72529e-09 ; train accuracy 0.998183906\n",
      "Step 1986 : train loss 3.72529e-09 ; train accuracy 0.9981848\n",
      "Step 1987 : train loss 7.45058e-09 ; train accuracy 0.998185694\n",
      "Step 1988 : train loss 7.45058e-09 ; train accuracy 0.998186648\n",
      "Step 1989 : train loss 1.117587e-08 ; train accuracy 0.998187542\n",
      "Step 1990 : train loss 1.11758691e-08 ; train accuracy 0.998188436\n",
      "Step 1991 : train loss 0 ; train accuracy 0.99818939\n",
      "Step 1992 : train loss 7.45058e-09 ; train accuracy 0.998190284\n",
      "Step 1993 : train loss 7.45058e-09 ; train accuracy 0.998191178\n",
      "Step 1994 : train loss 1.49011603e-08 ; train accuracy 0.998192132\n",
      "Step 1995 : train loss 2.60770285e-08 ; train accuracy 0.998193\n",
      "Step 1996 : train loss 3.72529e-09 ; train accuracy 0.99819392\n",
      "Step 1997 : train loss 0 ; train accuracy 0.998194814\n",
      "Step 1998 : train loss 1.86264497e-08 ; train accuracy 0.998195767\n",
      "Step 1999 : train loss 7.45058e-09 ; train accuracy 0.998196661\n",
      "Step 2000 : train loss 3.72529e-09 ; train accuracy 0.998197556\n",
      "Step 2001 : train loss 3.72529e-09 ; train accuracy 0.99819845\n",
      "Step 2002 : train loss 7.45057971e-09 ; train accuracy 0.998199344\n",
      "Step 2003 : train loss 0 ; train accuracy 0.998200238\n",
      "Step 2004 : train loss 3.72529e-09 ; train accuracy 0.998201132\n",
      "Step 2005 : train loss 3.72529e-09 ; train accuracy 0.998202085\n",
      "Step 2006 : train loss 3.72529e-09 ; train accuracy 0.998203\n",
      "Step 2007 : train loss 0 ; train accuracy 0.998203874\n",
      "Step 2008 : train loss 1.49011603e-08 ; train accuracy 0.998204768\n",
      "Step 2009 : train loss 0 ; train accuracy 0.998205662\n",
      "Step 2010 : train loss 1.117587e-08 ; train accuracy 0.998206556\n",
      "Step 2011 : train loss 0 ; train accuracy 0.99820745\n",
      "Step 2012 : train loss 7.45058e-09 ; train accuracy 0.998208344\n",
      "Step 2013 : train loss 7.45057971e-09 ; train accuracy 0.998209238\n",
      "Step 2014 : train loss 1.49011603e-08 ; train accuracy 0.998210132\n",
      "Step 2015 : train loss 3.72529e-09 ; train accuracy 0.998211\n",
      "Step 2016 : train loss 0 ; train accuracy 0.99821192\n",
      "Step 2017 : train loss 3.72529e-09 ; train accuracy 0.998212814\n",
      "Step 2018 : train loss 7.45058e-09 ; train accuracy 0.998213649\n",
      "Step 2019 : train loss 7.45058e-09 ; train accuracy 0.998214543\n",
      "Step 2020 : train loss 2.6077025e-08 ; train accuracy 0.998215437\n",
      "Step 2021 : train loss 0 ; train accuracy 0.998216331\n",
      "Step 2022 : train loss 1.117587e-08 ; train accuracy 0.998217225\n",
      "Step 2023 : train loss 7.45058e-09 ; train accuracy 0.998218119\n",
      "Step 2024 : train loss 3.72529e-09 ; train accuracy 0.998219\n",
      "Step 2025 : train loss 4.47034729e-08 ; train accuracy 0.998219848\n",
      "Step 2026 : train loss 1.49011603e-08 ; train accuracy 0.998220742\n",
      "Step 2027 : train loss 1.49011603e-08 ; train accuracy 0.998221636\n",
      "Step 2028 : train loss 1.49011603e-08 ; train accuracy 0.99822253\n",
      "Step 2029 : train loss 7.45057971e-09 ; train accuracy 0.998223364\n",
      "Step 2030 : train loss 7.45057971e-09 ; train accuracy 0.998224258\n",
      "Step 2031 : train loss 3.72529e-09 ; train accuracy 0.998225152\n",
      "Step 2032 : train loss 1.117587e-08 ; train accuracy 0.998226047\n",
      "Step 2033 : train loss 3.72529e-09 ; train accuracy 0.998226881\n",
      "Step 2034 : train loss 3.72529e-09 ; train accuracy 0.998227775\n",
      "Step 2035 : train loss 3.72529e-09 ; train accuracy 0.998228669\n",
      "Step 2036 : train loss 0 ; train accuracy 0.998229504\n",
      "Step 2037 : train loss 2.23517382e-08 ; train accuracy 0.998230398\n",
      "Step 2038 : train loss 0 ; train accuracy 0.998231232\n",
      "Step 2039 : train loss 1.86264497e-08 ; train accuracy 0.998232126\n",
      "Step 2040 : train loss 3.72529e-09 ; train accuracy 0.998233\n",
      "Step 2041 : train loss 3.72529e-09 ; train accuracy 0.998233855\n",
      "Step 2042 : train loss 7.45058e-09 ; train accuracy 0.998234749\n",
      "Step 2043 : train loss 3.72529e-09 ; train accuracy 0.998235583\n",
      "Step 2044 : train loss 1.117587e-08 ; train accuracy 0.998236477\n",
      "Step 2045 : train loss 0 ; train accuracy 0.998237312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2046 : train loss 7.45058e-09 ; train accuracy 0.998238206\n",
      "Step 2047 : train loss 1.49011603e-08 ; train accuracy 0.99823904\n",
      "Step 2048 : train loss 3.3527602e-08 ; train accuracy 0.998239934\n",
      "Step 2049 : train loss 0 ; train accuracy 0.998240769\n",
      "Step 2050 : train loss 3.72529e-09 ; train accuracy 0.998241663\n",
      "Step 2051 : train loss 3.72529e-09 ; train accuracy 0.998242497\n",
      "Step 2052 : train loss 1.49011603e-08 ; train accuracy 0.998243392\n",
      "Step 2053 : train loss 1.117587e-08 ; train accuracy 0.998244226\n",
      "Step 2054 : train loss 1.49011603e-08 ; train accuracy 0.99824506\n",
      "Step 2055 : train loss 1.117587e-08 ; train accuracy 0.998245955\n",
      "Step 2056 : train loss 1.117587e-08 ; train accuracy 0.998246789\n",
      "Step 2057 : train loss 1.49011603e-08 ; train accuracy 0.998247623\n",
      "Step 2058 : train loss 1.86264497e-08 ; train accuracy 0.998248518\n",
      "Step 2059 : train loss 7.45058e-09 ; train accuracy 0.998249352\n",
      "Step 2060 : train loss 3.72529e-09 ; train accuracy 0.998250186\n",
      "Step 2061 : train loss 1.117587e-08 ; train accuracy 0.998251081\n",
      "Step 2062 : train loss 1.49011594e-08 ; train accuracy 0.998251915\n",
      "Step 2063 : train loss 1.49011603e-08 ; train accuracy 0.998252749\n",
      "Step 2064 : train loss 2.23517347e-08 ; train accuracy 0.998253584\n",
      "Step 2065 : train loss 3.72529e-09 ; train accuracy 0.998254478\n",
      "Step 2066 : train loss 7.45058e-09 ; train accuracy 0.998255312\n",
      "Step 2067 : train loss 1.86264497e-08 ; train accuracy 0.998256147\n",
      "Step 2068 : train loss 1.117587e-08 ; train accuracy 0.998257\n",
      "Step 2069 : train loss 7.45058e-09 ; train accuracy 0.998257816\n",
      "Step 2070 : train loss 2.23517382e-08 ; train accuracy 0.99825871\n",
      "Step 2071 : train loss 1.49011603e-08 ; train accuracy 0.998259544\n",
      "Step 2072 : train loss 7.45058e-09 ; train accuracy 0.998260379\n",
      "Step 2073 : train loss 1.86264497e-08 ; train accuracy 0.998261213\n",
      "Step 2074 : train loss 1.117587e-08 ; train accuracy 0.998262048\n",
      "Step 2075 : train loss 7.45057971e-09 ; train accuracy 0.998262882\n",
      "Step 2076 : train loss 8.51494875e-09 ; train accuracy 0.99826324\n",
      "val loss 3.97364275e-08 ; val accuracy 1\n",
      "Step 2077 : train loss 2.60770303e-08 ; train accuracy 0.998264074\n",
      "Step 2078 : train loss 1.11758691e-08 ; train accuracy 0.998264909\n",
      "Step 2079 : train loss 2.98023171e-08 ; train accuracy 0.998265803\n",
      "Step 2080 : train loss 7.45058e-09 ; train accuracy 0.998266637\n",
      "Step 2081 : train loss 3.72529e-09 ; train accuracy 0.998267472\n",
      "Step 2082 : train loss 3.72529e-09 ; train accuracy 0.998268306\n",
      "Step 2083 : train loss 0 ; train accuracy 0.998269141\n",
      "Step 2084 : train loss 0 ; train accuracy 0.99827\n",
      "Step 2085 : train loss 1.86264497e-08 ; train accuracy 0.99827081\n",
      "Step 2086 : train loss 1.117587e-08 ; train accuracy 0.998271585\n",
      "Step 2087 : train loss 1.49011594e-08 ; train accuracy 0.998272419\n",
      "Step 2088 : train loss 0 ; train accuracy 0.998273253\n",
      "Step 2089 : train loss 2.6077025e-08 ; train accuracy 0.998274088\n",
      "Step 2090 : train loss 3.72529e-09 ; train accuracy 0.998274922\n",
      "Step 2091 : train loss 1.86264479e-08 ; train accuracy 0.998275757\n",
      "Step 2092 : train loss 3.72529e-09 ; train accuracy 0.998276591\n",
      "Step 2093 : train loss 0 ; train accuracy 0.998277426\n",
      "Step 2094 : train loss 3.72529e-09 ; train accuracy 0.99827826\n",
      "Step 2095 : train loss 7.45058e-09 ; train accuracy 0.998279035\n",
      "Step 2096 : train loss 3.72529e-09 ; train accuracy 0.99827987\n",
      "Step 2097 : train loss 1.117587e-08 ; train accuracy 0.998280704\n",
      "Step 2098 : train loss 7.45057971e-09 ; train accuracy 0.998281538\n",
      "Step 2099 : train loss 3.72529e-09 ; train accuracy 0.998282373\n",
      "Step 2100 : train loss 3.72529e-09 ; train accuracy 0.998283148\n",
      "Step 2101 : train loss 1.11758691e-08 ; train accuracy 0.998284\n",
      "Step 2102 : train loss 3.72529e-09 ; train accuracy 0.998284817\n",
      "Step 2103 : train loss 0 ; train accuracy 0.998285651\n",
      "Step 2104 : train loss 3.72529e-09 ; train accuracy 0.998286426\n",
      "Step 2105 : train loss 0 ; train accuracy 0.998287261\n",
      "Step 2106 : train loss 7.45058e-09 ; train accuracy 0.998288095\n",
      "Step 2107 : train loss 1.117587e-08 ; train accuracy 0.99828887\n",
      "Step 2108 : train loss 3.72529e-09 ; train accuracy 0.998289704\n",
      "Step 2109 : train loss 0 ; train accuracy 0.998290539\n",
      "Step 2110 : train loss 7.45057971e-09 ; train accuracy 0.998291314\n",
      "Step 2111 : train loss 1.49011594e-08 ; train accuracy 0.998292148\n",
      "Step 2112 : train loss 3.72529e-09 ; train accuracy 0.998293\n",
      "Step 2113 : train loss 3.72529e-09 ; train accuracy 0.998293757\n",
      "Step 2114 : train loss 1.117587e-08 ; train accuracy 0.998294592\n",
      "Step 2115 : train loss 1.49011594e-08 ; train accuracy 0.998295367\n",
      "Step 2116 : train loss 1.117587e-08 ; train accuracy 0.998296201\n",
      "Step 2117 : train loss 0 ; train accuracy 0.998297\n",
      "Step 2118 : train loss 1.117587e-08 ; train accuracy 0.998297811\n",
      "Step 2119 : train loss 0 ; train accuracy 0.998298645\n",
      "Step 2120 : train loss 3.72529e-09 ; train accuracy 0.99829942\n",
      "Step 2121 : train loss 1.117587e-08 ; train accuracy 0.998300254\n",
      "Step 2122 : train loss 1.86264497e-08 ; train accuracy 0.998301\n",
      "Step 2123 : train loss 3.72529e-09 ; train accuracy 0.998301804\n",
      "Step 2124 : train loss 1.49011594e-08 ; train accuracy 0.998302639\n",
      "Step 2125 : train loss 3.72529e-09 ; train accuracy 0.998303413\n",
      "Step 2126 : train loss 2.98023188e-08 ; train accuracy 0.998304248\n",
      "Step 2127 : train loss 3.72529e-09 ; train accuracy 0.998305\n",
      "Step 2128 : train loss 0 ; train accuracy 0.998305857\n",
      "Step 2129 : train loss 1.117587e-08 ; train accuracy 0.998306632\n",
      "Step 2130 : train loss 0 ; train accuracy 0.998307407\n",
      "Step 2131 : train loss 7.45058e-09 ; train accuracy 0.998308241\n",
      "Step 2132 : train loss 1.49011594e-08 ; train accuracy 0.998309\n",
      "Step 2133 : train loss 1.117587e-08 ; train accuracy 0.998309791\n",
      "Step 2134 : train loss 2.98023188e-08 ; train accuracy 0.998310626\n",
      "Step 2135 : train loss 7.45058e-09 ; train accuracy 0.9983114\n",
      "Step 2136 : train loss 0 ; train accuracy 0.998312175\n",
      "Step 2137 : train loss 2.60770285e-08 ; train accuracy 0.998313\n",
      "Step 2138 : train loss 1.49011603e-08 ; train accuracy 0.998313785\n",
      "Step 2139 : train loss 1.49011594e-08 ; train accuracy 0.998314559\n",
      "Step 2140 : train loss 3.72529e-09 ; train accuracy 0.998315334\n",
      "Step 2141 : train loss 1.117587e-08 ; train accuracy 0.998316169\n",
      "Step 2142 : train loss 0 ; train accuracy 0.998316944\n",
      "Step 2143 : train loss 1.49011576e-08 ; train accuracy 0.998317719\n",
      "Step 2144 : train loss 1.117587e-08 ; train accuracy 0.998318493\n",
      "Step 2145 : train loss 0 ; train accuracy 0.998319328\n",
      "Step 2146 : train loss 3.72529e-09 ; train accuracy 0.998320103\n",
      "Step 2147 : train loss 1.117587e-08 ; train accuracy 0.998320878\n",
      "Step 2148 : train loss 3.72529e-09 ; train accuracy 0.998321652\n",
      "Step 2149 : train loss 7.45058e-09 ; train accuracy 0.998322427\n",
      "Step 2150 : train loss 3.72529e-09 ; train accuracy 0.998323202\n",
      "Step 2151 : train loss 3.72529e-09 ; train accuracy 0.998324\n",
      "Step 2152 : train loss 1.49011603e-08 ; train accuracy 0.998324811\n",
      "Step 2153 : train loss 3.72529e-09 ; train accuracy 0.998325586\n",
      "Step 2154 : train loss 0 ; train accuracy 0.998326361\n",
      "Step 2155 : train loss 2.98023153e-08 ; train accuracy 0.998327136\n",
      "Step 2156 : train loss 7.45058e-09 ; train accuracy 0.998327911\n",
      "Step 2157 : train loss 3.72529e-09 ; train accuracy 0.998328686\n",
      "Step 2158 : train loss 7.45058e-09 ; train accuracy 0.998329461\n",
      "Step 2159 : train loss 0 ; train accuracy 0.998330235\n",
      "Step 2160 : train loss 2.23517382e-08 ; train accuracy 0.998331\n",
      "Step 2161 : train loss 3.72529e-09 ; train accuracy 0.998331785\n",
      "Step 2162 : train loss 1.49011603e-08 ; train accuracy 0.99833256\n",
      "Step 2163 : train loss 7.45058e-09 ; train accuracy 0.998333335\n",
      "Step 2164 : train loss 1.49011603e-08 ; train accuracy 0.99833411\n",
      "Step 2165 : train loss 1.117587e-08 ; train accuracy 0.998334885\n",
      "Step 2166 : train loss 1.49011603e-08 ; train accuracy 0.99833566\n",
      "Step 2167 : train loss 3.72529e-09 ; train accuracy 0.998336434\n",
      "Step 2168 : train loss 0 ; train accuracy 0.998337209\n",
      "Step 2169 : train loss 3.72529e-09 ; train accuracy 0.998338\n",
      "Step 2170 : train loss 7.45058e-09 ; train accuracy 0.998338699\n",
      "Step 2171 : train loss 3.72529e-09 ; train accuracy 0.998339474\n",
      "Step 2172 : train loss 1.117587e-08 ; train accuracy 0.998340249\n",
      "Step 2173 : train loss 3.72529e-09 ; train accuracy 0.998341\n",
      "Step 2174 : train loss 3.72529e-09 ; train accuracy 0.998341799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2175 : train loss 7.45058e-09 ; train accuracy 0.998342574\n",
      "Step 2176 : train loss 1.117587e-08 ; train accuracy 0.998343349\n",
      "Step 2177 : train loss 7.45058e-09 ; train accuracy 0.998344064\n",
      "Step 2178 : train loss 0 ; train accuracy 0.998344839\n",
      "Step 2179 : train loss 0 ; train accuracy 0.998345613\n",
      "Step 2180 : train loss 0 ; train accuracy 0.998346388\n",
      "Step 2181 : train loss 3.72529e-09 ; train accuracy 0.998347104\n",
      "Step 2182 : train loss 3.72529e-09 ; train accuracy 0.998347878\n",
      "Step 2183 : train loss 7.45058e-09 ; train accuracy 0.998348653\n",
      "Step 2184 : train loss 1.86264497e-08 ; train accuracy 0.998349428\n",
      "Step 2185 : train loss 0 ; train accuracy 0.998350143\n",
      "Step 2186 : train loss 3.72529e-09 ; train accuracy 0.998350918\n",
      "Step 2187 : train loss 1.117587e-08 ; train accuracy 0.998351693\n",
      "Step 2188 : train loss 3.72529e-09 ; train accuracy 0.998352408\n",
      "Step 2189 : train loss 7.45058e-09 ; train accuracy 0.998353183\n",
      "Step 2190 : train loss 1.117587e-08 ; train accuracy 0.998353958\n",
      "Step 2191 : train loss 7.45058e-09 ; train accuracy 0.998354673\n",
      "Step 2192 : train loss 3.72529e-09 ; train accuracy 0.998355448\n",
      "Step 2193 : train loss 1.117587e-08 ; train accuracy 0.998356223\n",
      "Step 2194 : train loss 0 ; train accuracy 0.998356938\n",
      "Step 2195 : train loss 0 ; train accuracy 0.998357713\n",
      "Step 2196 : train loss 1.86264497e-08 ; train accuracy 0.998358428\n",
      "Step 2197 : train loss 1.86264497e-08 ; train accuracy 0.998359203\n",
      "Step 2198 : train loss 2.98023117e-08 ; train accuracy 0.99836\n",
      "Step 2199 : train loss 1.117587e-08 ; train accuracy 0.998360693\n",
      "Step 2200 : train loss 3.72529e-09 ; train accuracy 0.998361468\n",
      "Step 2201 : train loss 3.72529e-09 ; train accuracy 0.998362184\n",
      "Step 2202 : train loss 7.45057971e-09 ; train accuracy 0.998362958\n",
      "Step 2203 : train loss 7.45057971e-09 ; train accuracy 0.998363674\n",
      "Step 2204 : train loss 7.45058e-09 ; train accuracy 0.998364449\n",
      "Step 2205 : train loss 2.98023153e-08 ; train accuracy 0.998365164\n",
      "Step 2206 : train loss 1.86264497e-08 ; train accuracy 0.998365939\n",
      "Step 2207 : train loss 7.45058e-09 ; train accuracy 0.998366654\n",
      "Step 2208 : train loss 1.117587e-08 ; train accuracy 0.998367429\n",
      "Step 2209 : train loss 7.45058e-09 ; train accuracy 0.998368144\n",
      "Step 2210 : train loss 1.11758691e-08 ; train accuracy 0.998368859\n",
      "Step 2211 : train loss 0 ; train accuracy 0.998369634\n",
      "Step 2212 : train loss 2.60770285e-08 ; train accuracy 0.998370349\n",
      "Step 2213 : train loss 0 ; train accuracy 0.998371124\n",
      "Step 2214 : train loss 0 ; train accuracy 0.99837184\n",
      "Step 2215 : train loss 3.72529e-09 ; train accuracy 0.998372555\n",
      "Step 2216 : train loss 1.117587e-08 ; train accuracy 0.99837333\n",
      "Step 2217 : train loss 1.117587e-08 ; train accuracy 0.998374045\n",
      "Step 2218 : train loss 1.117587e-08 ; train accuracy 0.99837476\n",
      "Step 2219 : train loss 0 ; train accuracy 0.998375535\n",
      "Step 2220 : train loss 1.117587e-08 ; train accuracy 0.99837625\n",
      "Step 2221 : train loss 3.72529e-09 ; train accuracy 0.998376966\n",
      "Step 2222 : train loss 1.86264497e-08 ; train accuracy 0.99837774\n",
      "Step 2223 : train loss 3.72529e-09 ; train accuracy 0.998378456\n",
      "Step 2224 : train loss 3.72529e-09 ; train accuracy 0.998379171\n",
      "Step 2225 : train loss 3.72529e-09 ; train accuracy 0.998379946\n",
      "Step 2226 : train loss 1.117587e-08 ; train accuracy 0.998380661\n",
      "Step 2227 : train loss 7.45058e-09 ; train accuracy 0.998381376\n",
      "Step 2228 : train loss 7.45058e-09 ; train accuracy 0.998382092\n",
      "Step 2229 : train loss 1.49011594e-08 ; train accuracy 0.998382807\n",
      "Step 2230 : train loss 7.45058e-09 ; train accuracy 0.998383582\n",
      "Step 2231 : train loss 1.117587e-08 ; train accuracy 0.998384297\n",
      "Step 2232 : train loss 3.72529e-09 ; train accuracy 0.998385\n",
      "Step 2233 : train loss 2.60770303e-08 ; train accuracy 0.998385727\n",
      "Step 2234 : train loss 3.72529e-09 ; train accuracy 0.998386443\n",
      "Step 2235 : train loss 7.45058e-09 ; train accuracy 0.998387158\n",
      "Step 2236 : train loss 1.49011603e-08 ; train accuracy 0.998387933\n",
      "Step 2237 : train loss 3.72529e-09 ; train accuracy 0.998388648\n",
      "Step 2238 : train loss 2.235174e-08 ; train accuracy 0.998389363\n",
      "Step 2239 : train loss 3.72528959e-08 ; train accuracy 0.998390079\n",
      "Step 2240 : train loss 2.98023153e-08 ; train accuracy 0.998390794\n",
      "Step 2241 : train loss 1.117587e-08 ; train accuracy 0.998391509\n",
      "Step 2242 : train loss 7.45057971e-09 ; train accuracy 0.998392224\n",
      "Step 2243 : train loss 3.72529e-09 ; train accuracy 0.99839294\n",
      "Step 2244 : train loss 7.45058e-09 ; train accuracy 0.998393655\n",
      "Step 2245 : train loss 3.72529e-09 ; train accuracy 0.99839437\n",
      "Step 2246 : train loss 0 ; train accuracy 0.998395085\n",
      "Step 2247 : train loss 2.235174e-08 ; train accuracy 0.998395801\n",
      "Step 2248 : train loss 7.45058e-09 ; train accuracy 0.998396516\n",
      "Step 2249 : train loss 1.70298975e-08 ; train accuracy 0.998396873\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 2250 : train loss 2.60770285e-08 ; train accuracy 0.998397589\n",
      "Step 2251 : train loss 7.45057971e-09 ; train accuracy 0.998398304\n",
      "Step 2252 : train loss 1.117587e-08 ; train accuracy 0.998399\n",
      "Step 2253 : train loss 1.49011603e-08 ; train accuracy 0.998399734\n",
      "Step 2254 : train loss 7.45058e-09 ; train accuracy 0.99840045\n",
      "Step 2255 : train loss 3.72529e-09 ; train accuracy 0.998401105\n",
      "Step 2256 : train loss 3.72529e-09 ; train accuracy 0.998401821\n",
      "Step 2257 : train loss 7.45058e-09 ; train accuracy 0.998402536\n",
      "Step 2258 : train loss 0 ; train accuracy 0.998403251\n",
      "Step 2259 : train loss 1.86264497e-08 ; train accuracy 0.998403966\n",
      "Step 2260 : train loss 7.45058e-09 ; train accuracy 0.998404682\n",
      "Step 2261 : train loss 7.45057971e-09 ; train accuracy 0.998405397\n",
      "Step 2262 : train loss 7.45058e-09 ; train accuracy 0.998406112\n",
      "Step 2263 : train loss 1.86264497e-08 ; train accuracy 0.998406827\n",
      "Step 2264 : train loss 0 ; train accuracy 0.998407483\n",
      "Step 2265 : train loss 0 ; train accuracy 0.998408198\n",
      "Step 2266 : train loss 7.45058e-09 ; train accuracy 0.998408914\n",
      "Step 2267 : train loss 1.49011576e-08 ; train accuracy 0.998409629\n",
      "Step 2268 : train loss 0 ; train accuracy 0.998410344\n",
      "Step 2269 : train loss 0 ; train accuracy 0.998411059\n",
      "Step 2270 : train loss 3.72529e-09 ; train accuracy 0.998411715\n",
      "Step 2271 : train loss 1.49011603e-08 ; train accuracy 0.99841243\n",
      "Step 2272 : train loss 0 ; train accuracy 0.998413146\n",
      "Step 2273 : train loss 1.117587e-08 ; train accuracy 0.998413861\n",
      "Step 2274 : train loss 3.72529e-09 ; train accuracy 0.998414516\n",
      "Step 2275 : train loss 0 ; train accuracy 0.998415232\n",
      "Step 2276 : train loss 2.98023117e-08 ; train accuracy 0.998415947\n",
      "Step 2277 : train loss 1.117587e-08 ; train accuracy 0.998416603\n",
      "Step 2278 : train loss 1.49011603e-08 ; train accuracy 0.998417318\n",
      "Step 2279 : train loss 0 ; train accuracy 0.998418033\n",
      "Step 2280 : train loss 2.60770303e-08 ; train accuracy 0.998418748\n",
      "Step 2281 : train loss 0 ; train accuracy 0.998419404\n",
      "Step 2282 : train loss 7.45058e-09 ; train accuracy 0.998420119\n",
      "Step 2283 : train loss 0 ; train accuracy 0.998420835\n",
      "Step 2284 : train loss 3.72529e-09 ; train accuracy 0.99842149\n",
      "Step 2285 : train loss 1.49011594e-08 ; train accuracy 0.998422205\n",
      "Step 2286 : train loss 1.11758691e-08 ; train accuracy 0.998422861\n",
      "Step 2287 : train loss 1.117587e-08 ; train accuracy 0.998423576\n",
      "Step 2288 : train loss 3.72529e-09 ; train accuracy 0.998424292\n",
      "Step 2289 : train loss 3.72529e-09 ; train accuracy 0.998424947\n",
      "Step 2290 : train loss 1.49011594e-08 ; train accuracy 0.998425663\n",
      "Step 2291 : train loss 1.86264497e-08 ; train accuracy 0.998426318\n",
      "Step 2292 : train loss 3.72529e-09 ; train accuracy 0.998427033\n",
      "Step 2293 : train loss 1.117587e-08 ; train accuracy 0.998427689\n",
      "Step 2294 : train loss 7.45058e-09 ; train accuracy 0.998428404\n",
      "Step 2295 : train loss 0 ; train accuracy 0.99842912\n",
      "Step 2296 : train loss 3.72529e-09 ; train accuracy 0.998429775\n",
      "Step 2297 : train loss 1.49011594e-08 ; train accuracy 0.99843049\n",
      "Step 2298 : train loss 1.86264497e-08 ; train accuracy 0.998431146\n",
      "Step 2299 : train loss 0 ; train accuracy 0.998431861\n",
      "Step 2300 : train loss 7.45058e-09 ; train accuracy 0.998432517\n",
      "Step 2301 : train loss 7.45057971e-09 ; train accuracy 0.998433173\n",
      "Step 2302 : train loss 1.49011603e-08 ; train accuracy 0.998433888\n",
      "Step 2303 : train loss 0 ; train accuracy 0.998434544\n",
      "Step 2304 : train loss 3.72529e-09 ; train accuracy 0.998435259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2305 : train loss 7.45058e-09 ; train accuracy 0.998435915\n",
      "Step 2306 : train loss 7.45058e-09 ; train accuracy 0.99843663\n",
      "Step 2307 : train loss 7.45058e-09 ; train accuracy 0.998437285\n",
      "Step 2308 : train loss 3.72529e-09 ; train accuracy 0.998437941\n",
      "Step 2309 : train loss 2.23517382e-08 ; train accuracy 0.998438656\n",
      "Step 2310 : train loss 2.23517382e-08 ; train accuracy 0.998439312\n",
      "Step 2311 : train loss 1.117587e-08 ; train accuracy 0.99844\n",
      "Step 2312 : train loss 1.117587e-08 ; train accuracy 0.998440683\n",
      "Step 2313 : train loss 7.45057971e-09 ; train accuracy 0.998441339\n",
      "Step 2314 : train loss 7.45058e-09 ; train accuracy 0.998442054\n",
      "Step 2315 : train loss 3.72529e-09 ; train accuracy 0.998442709\n",
      "Step 2316 : train loss 1.86264497e-08 ; train accuracy 0.998443365\n",
      "Step 2317 : train loss 7.45058e-09 ; train accuracy 0.99844408\n",
      "Step 2318 : train loss 0 ; train accuracy 0.998444736\n",
      "Step 2319 : train loss 3.72529e-09 ; train accuracy 0.998445392\n",
      "Step 2320 : train loss 1.49011603e-08 ; train accuracy 0.998446047\n",
      "Step 2321 : train loss 1.117587e-08 ; train accuracy 0.998446763\n",
      "Step 2322 : train loss 3.72529e-09 ; train accuracy 0.998447418\n",
      "Step 2323 : train loss 7.45057971e-09 ; train accuracy 0.998448074\n",
      "Step 2324 : train loss 1.117587e-08 ; train accuracy 0.99844873\n",
      "Step 2325 : train loss 2.23517347e-08 ; train accuracy 0.998449445\n",
      "Step 2326 : train loss 3.72529e-09 ; train accuracy 0.9984501\n",
      "Step 2327 : train loss 0 ; train accuracy 0.998450756\n",
      "Step 2328 : train loss 7.45058e-09 ; train accuracy 0.998451412\n",
      "Step 2329 : train loss 2.235174e-08 ; train accuracy 0.998452067\n",
      "Step 2330 : train loss 1.117587e-08 ; train accuracy 0.998452783\n",
      "Step 2331 : train loss 3.72529e-09 ; train accuracy 0.998453438\n",
      "Step 2332 : train loss 0 ; train accuracy 0.998454094\n",
      "Step 2333 : train loss 0 ; train accuracy 0.99845475\n",
      "Step 2334 : train loss 3.72529e-09 ; train accuracy 0.998455405\n",
      "Step 2335 : train loss 0 ; train accuracy 0.998456061\n",
      "Step 2336 : train loss 3.72529e-09 ; train accuracy 0.998456776\n",
      "Step 2337 : train loss 1.49011603e-08 ; train accuracy 0.998457432\n",
      "Step 2338 : train loss 1.49011603e-08 ; train accuracy 0.998458087\n",
      "Step 2339 : train loss 3.72529e-09 ; train accuracy 0.998458743\n",
      "Step 2340 : train loss 7.45058e-09 ; train accuracy 0.998459399\n",
      "Step 2341 : train loss 1.117587e-08 ; train accuracy 0.998460054\n",
      "Step 2342 : train loss 7.45058e-09 ; train accuracy 0.99846071\n",
      "Step 2343 : train loss 0 ; train accuracy 0.998461366\n",
      "Step 2344 : train loss 2.235174e-08 ; train accuracy 0.998462\n",
      "Step 2345 : train loss 1.49011594e-08 ; train accuracy 0.998462677\n",
      "Step 2346 : train loss 1.117587e-08 ; train accuracy 0.998463333\n",
      "Step 2347 : train loss 3.72529e-09 ; train accuracy 0.998464\n",
      "Step 2348 : train loss 0 ; train accuracy 0.998464644\n",
      "Step 2349 : train loss 1.117587e-08 ; train accuracy 0.9984653\n",
      "Step 2350 : train loss 3.72529e-09 ; train accuracy 0.998465955\n",
      "Step 2351 : train loss 7.45057971e-09 ; train accuracy 0.998466611\n",
      "Step 2352 : train loss 7.45058e-09 ; train accuracy 0.998467267\n",
      "Step 2353 : train loss 7.45058e-09 ; train accuracy 0.998467922\n",
      "Step 2354 : train loss 0 ; train accuracy 0.998468578\n",
      "Step 2355 : train loss 1.117587e-08 ; train accuracy 0.998469234\n",
      "Step 2356 : train loss 3.72529e-09 ; train accuracy 0.998469889\n",
      "Step 2357 : train loss 3.72529e-09 ; train accuracy 0.998470545\n",
      "Step 2358 : train loss 0 ; train accuracy 0.9984712\n",
      "Step 2359 : train loss 3.72529e-09 ; train accuracy 0.998471856\n",
      "Step 2360 : train loss 7.45058e-09 ; train accuracy 0.998472512\n",
      "Step 2361 : train loss 7.45058e-09 ; train accuracy 0.998473167\n",
      "Step 2362 : train loss 3.72529e-09 ; train accuracy 0.998473763\n",
      "Step 2363 : train loss 1.86264497e-08 ; train accuracy 0.998474419\n",
      "Step 2364 : train loss 1.49011603e-08 ; train accuracy 0.998475075\n",
      "Step 2365 : train loss 2.6077025e-08 ; train accuracy 0.99847573\n",
      "Step 2366 : train loss 3.72529e-09 ; train accuracy 0.998476386\n",
      "Step 2367 : train loss 7.45058e-09 ; train accuracy 0.998477042\n",
      "Step 2368 : train loss 3.72529e-09 ; train accuracy 0.998477697\n",
      "Step 2369 : train loss 1.117587e-08 ; train accuracy 0.998478293\n",
      "Step 2370 : train loss 7.45058e-09 ; train accuracy 0.998478949\n",
      "Step 2371 : train loss 1.117587e-08 ; train accuracy 0.998479605\n",
      "Step 2372 : train loss 3.72529e-09 ; train accuracy 0.99848026\n",
      "Step 2373 : train loss 0 ; train accuracy 0.998480856\n",
      "Step 2374 : train loss 1.49011603e-08 ; train accuracy 0.998481512\n",
      "Step 2375 : train loss 1.117587e-08 ; train accuracy 0.998482168\n",
      "Step 2376 : train loss 2.6077025e-08 ; train accuracy 0.998482823\n",
      "Step 2377 : train loss 0 ; train accuracy 0.998483479\n",
      "Step 2378 : train loss 3.72529e-09 ; train accuracy 0.998484075\n",
      "Step 2379 : train loss 7.45057971e-09 ; train accuracy 0.998484731\n",
      "Step 2380 : train loss 3.72529e-09 ; train accuracy 0.998485386\n",
      "Step 2381 : train loss 3.72529e-09 ; train accuracy 0.998486\n",
      "Step 2382 : train loss 7.45058e-09 ; train accuracy 0.998486638\n",
      "Step 2383 : train loss 1.117587e-08 ; train accuracy 0.998487294\n",
      "Step 2384 : train loss 7.45057971e-09 ; train accuracy 0.99848789\n",
      "Step 2385 : train loss 1.11758691e-08 ; train accuracy 0.998488545\n",
      "Step 2386 : train loss 3.72529e-09 ; train accuracy 0.998489201\n",
      "Step 2387 : train loss 0 ; train accuracy 0.998489797\n",
      "Step 2388 : train loss 3.72529e-09 ; train accuracy 0.998490453\n",
      "Step 2389 : train loss 7.45058e-09 ; train accuracy 0.998491108\n",
      "Step 2390 : train loss 3.72529e-09 ; train accuracy 0.998491704\n",
      "Step 2391 : train loss 3.72529e-09 ; train accuracy 0.99849236\n",
      "Step 2392 : train loss 3.72529e-09 ; train accuracy 0.998493\n",
      "Step 2393 : train loss 1.86264497e-08 ; train accuracy 0.998493612\n",
      "Step 2394 : train loss 1.117587e-08 ; train accuracy 0.998494267\n",
      "Step 2395 : train loss 1.117587e-08 ; train accuracy 0.998494864\n",
      "Step 2396 : train loss 3.72529e-09 ; train accuracy 0.998495519\n",
      "Step 2397 : train loss 7.45057971e-09 ; train accuracy 0.998496115\n",
      "Step 2398 : train loss 7.45058e-09 ; train accuracy 0.998496771\n",
      "Step 2399 : train loss 1.86264479e-08 ; train accuracy 0.998497427\n",
      "Step 2400 : train loss 1.86264497e-08 ; train accuracy 0.998498\n",
      "Step 2401 : train loss 2.6077025e-08 ; train accuracy 0.998498678\n",
      "Step 2402 : train loss 0 ; train accuracy 0.998499274\n",
      "Step 2403 : train loss 7.45058e-09 ; train accuracy 0.99849993\n",
      "Step 2404 : train loss 2.235174e-08 ; train accuracy 0.998500526\n",
      "Step 2405 : train loss 1.49011603e-08 ; train accuracy 0.998501182\n",
      "Step 2406 : train loss 7.45058e-09 ; train accuracy 0.998501778\n",
      "Step 2407 : train loss 3.72529e-09 ; train accuracy 0.998502433\n",
      "Step 2408 : train loss 2.23517382e-08 ; train accuracy 0.998503\n",
      "Step 2409 : train loss 1.49011603e-08 ; train accuracy 0.998503685\n",
      "Step 2410 : train loss 1.117587e-08 ; train accuracy 0.998504281\n",
      "Step 2411 : train loss 1.49011603e-08 ; train accuracy 0.998504877\n",
      "Step 2412 : train loss 3.72529e-09 ; train accuracy 0.998505533\n",
      "Step 2413 : train loss 3.72529e-09 ; train accuracy 0.998506129\n",
      "Step 2414 : train loss 1.86264497e-08 ; train accuracy 0.998506784\n",
      "Step 2415 : train loss 3.72529e-09 ; train accuracy 0.99850738\n",
      "Step 2416 : train loss 1.117587e-08 ; train accuracy 0.998508\n",
      "Step 2417 : train loss 1.86264497e-08 ; train accuracy 0.998508632\n",
      "Step 2418 : train loss 1.49011603e-08 ; train accuracy 0.998509228\n",
      "Step 2419 : train loss 7.45058e-09 ; train accuracy 0.998509884\n",
      "Step 2420 : train loss 2.23517382e-08 ; train accuracy 0.99851048\n",
      "Step 2421 : train loss 0 ; train accuracy 0.998511076\n",
      "Step 2422 : train loss 2.55448462e-08 ; train accuracy 0.998511374\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 2423 : train loss 1.117587e-08 ; train accuracy 0.99851197\n",
      "Step 2424 : train loss 7.45057971e-09 ; train accuracy 0.998512626\n",
      "Step 2425 : train loss 1.117587e-08 ; train accuracy 0.998513222\n",
      "Step 2426 : train loss 7.45057971e-09 ; train accuracy 0.998513818\n",
      "Step 2427 : train loss 3.72529e-09 ; train accuracy 0.998514414\n",
      "Step 2428 : train loss 1.117587e-08 ; train accuracy 0.998515069\n",
      "Step 2429 : train loss 3.72529e-09 ; train accuracy 0.998515666\n",
      "Step 2430 : train loss 1.49011594e-08 ; train accuracy 0.998516262\n",
      "Step 2431 : train loss 4.09781791e-08 ; train accuracy 0.998516917\n",
      "Step 2432 : train loss 3.72529e-09 ; train accuracy 0.998517513\n",
      "Step 2433 : train loss 0 ; train accuracy 0.998518109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2434 : train loss 0 ; train accuracy 0.998518705\n",
      "Step 2435 : train loss 1.117587e-08 ; train accuracy 0.998519361\n",
      "Step 2436 : train loss 3.72529e-09 ; train accuracy 0.998519957\n",
      "Step 2437 : train loss 1.49011594e-08 ; train accuracy 0.998520553\n",
      "Step 2438 : train loss 1.49011594e-08 ; train accuracy 0.998521149\n",
      "Step 2439 : train loss 7.45058e-09 ; train accuracy 0.998521745\n",
      "Step 2440 : train loss 1.49011603e-08 ; train accuracy 0.998522401\n",
      "Step 2441 : train loss 1.117587e-08 ; train accuracy 0.998523\n",
      "Step 2442 : train loss 0 ; train accuracy 0.998523593\n",
      "Step 2443 : train loss 0 ; train accuracy 0.998524189\n",
      "Step 2444 : train loss 1.86264479e-08 ; train accuracy 0.998524785\n",
      "Step 2445 : train loss 0 ; train accuracy 0.998525441\n",
      "Step 2446 : train loss 0 ; train accuracy 0.998526037\n",
      "Step 2447 : train loss 0 ; train accuracy 0.998526633\n",
      "Step 2448 : train loss 3.72529e-09 ; train accuracy 0.998527229\n",
      "Step 2449 : train loss 7.45057971e-09 ; train accuracy 0.998527825\n",
      "Step 2450 : train loss 3.72529e-09 ; train accuracy 0.998528421\n",
      "Step 2451 : train loss 0 ; train accuracy 0.998529\n",
      "Step 2452 : train loss 3.72529e-09 ; train accuracy 0.998529613\n",
      "Step 2453 : train loss 7.45057971e-09 ; train accuracy 0.998530209\n",
      "Step 2454 : train loss 7.45058e-09 ; train accuracy 0.998530865\n",
      "Step 2455 : train loss 1.117587e-08 ; train accuracy 0.998531461\n",
      "Step 2456 : train loss 1.11758691e-08 ; train accuracy 0.998532057\n",
      "Step 2457 : train loss 3.72529e-09 ; train accuracy 0.998532653\n",
      "Step 2458 : train loss 1.86264497e-08 ; train accuracy 0.998533249\n",
      "Step 2459 : train loss 3.72529e-09 ; train accuracy 0.998533845\n",
      "Step 2460 : train loss 0 ; train accuracy 0.998534441\n",
      "Step 2461 : train loss 3.72529e-09 ; train accuracy 0.998535037\n",
      "Step 2462 : train loss 1.49011594e-08 ; train accuracy 0.998535633\n",
      "Step 2463 : train loss 0 ; train accuracy 0.998536229\n",
      "Step 2464 : train loss 3.72529e-09 ; train accuracy 0.998536825\n",
      "Step 2465 : train loss 3.72529e-09 ; train accuracy 0.998537421\n",
      "Step 2466 : train loss 3.72529e-09 ; train accuracy 0.998538\n",
      "Step 2467 : train loss 1.117587e-08 ; train accuracy 0.998538613\n",
      "Step 2468 : train loss 3.72529e-09 ; train accuracy 0.998539209\n",
      "Step 2469 : train loss 3.72529e-09 ; train accuracy 0.998539805\n",
      "Step 2470 : train loss 2.235174e-08 ; train accuracy 0.998540401\n",
      "Step 2471 : train loss 3.72529e-09 ; train accuracy 0.998541\n",
      "Step 2472 : train loss 2.60770285e-08 ; train accuracy 0.998541594\n",
      "Step 2473 : train loss 7.45058e-09 ; train accuracy 0.99854219\n",
      "Step 2474 : train loss 1.49011594e-08 ; train accuracy 0.998542726\n",
      "Step 2475 : train loss 1.117587e-08 ; train accuracy 0.998543322\n",
      "Step 2476 : train loss 0 ; train accuracy 0.998543918\n",
      "Step 2477 : train loss 7.45058e-09 ; train accuracy 0.998544514\n",
      "Step 2478 : train loss 0 ; train accuracy 0.99854511\n",
      "Step 2479 : train loss 1.11758691e-08 ; train accuracy 0.998545706\n",
      "Step 2480 : train loss 7.45058e-09 ; train accuracy 0.998546302\n",
      "Step 2481 : train loss 3.72529e-09 ; train accuracy 0.998546898\n",
      "Step 2482 : train loss 7.45058e-09 ; train accuracy 0.998547494\n",
      "Step 2483 : train loss 3.72529e-09 ; train accuracy 0.998548031\n",
      "Step 2484 : train loss 1.49011594e-08 ; train accuracy 0.998548627\n",
      "Step 2485 : train loss 2.60770285e-08 ; train accuracy 0.998549223\n",
      "Step 2486 : train loss 2.60770285e-08 ; train accuracy 0.998549819\n",
      "Step 2487 : train loss 1.86264479e-08 ; train accuracy 0.998550415\n",
      "Step 2488 : train loss 7.45057971e-09 ; train accuracy 0.998550951\n",
      "Step 2489 : train loss 3.72529e-09 ; train accuracy 0.998551548\n",
      "Step 2490 : train loss 7.45057971e-09 ; train accuracy 0.998552144\n",
      "Step 2491 : train loss 0 ; train accuracy 0.99855274\n",
      "Step 2492 : train loss 0 ; train accuracy 0.998553336\n",
      "Step 2493 : train loss 3.72529e-09 ; train accuracy 0.998553872\n",
      "Step 2494 : train loss 0 ; train accuracy 0.998554468\n",
      "Step 2495 : train loss 1.49011603e-08 ; train accuracy 0.998555064\n",
      "Step 2496 : train loss 1.117587e-08 ; train accuracy 0.99855566\n",
      "Step 2497 : train loss 1.117587e-08 ; train accuracy 0.998556197\n",
      "Step 2498 : train loss 7.45058e-09 ; train accuracy 0.998556793\n",
      "Step 2499 : train loss 1.49011576e-08 ; train accuracy 0.998557389\n",
      "Step 2500 : train loss 3.72529e-09 ; train accuracy 0.998558\n",
      "Step 2501 : train loss 1.49011603e-08 ; train accuracy 0.998558521\n",
      "Step 2502 : train loss 7.45058e-09 ; train accuracy 0.998559117\n",
      "Step 2503 : train loss 1.117587e-08 ; train accuracy 0.998559713\n",
      "Step 2504 : train loss 3.72529e-09 ; train accuracy 0.99856025\n",
      "Step 2505 : train loss 2.23517382e-08 ; train accuracy 0.998560846\n",
      "Step 2506 : train loss 1.49011603e-08 ; train accuracy 0.998561442\n",
      "Step 2507 : train loss 3.72529e-09 ; train accuracy 0.998562\n",
      "Step 2508 : train loss 7.45058e-09 ; train accuracy 0.998562574\n",
      "Step 2509 : train loss 7.45057971e-09 ; train accuracy 0.99856317\n",
      "Step 2510 : train loss 1.49011603e-08 ; train accuracy 0.998563707\n",
      "Step 2511 : train loss 3.72529e-09 ; train accuracy 0.998564303\n",
      "Step 2512 : train loss 0 ; train accuracy 0.998564839\n",
      "Step 2513 : train loss 7.45058e-09 ; train accuracy 0.998565435\n",
      "Step 2514 : train loss 3.72529e-09 ; train accuracy 0.998566031\n",
      "Step 2515 : train loss 3.72529e-09 ; train accuracy 0.998566568\n",
      "Step 2516 : train loss 1.117587e-08 ; train accuracy 0.998567164\n",
      "Step 2517 : train loss 3.72529e-09 ; train accuracy 0.9985677\n",
      "Step 2518 : train loss 7.45058e-09 ; train accuracy 0.998568296\n",
      "Step 2519 : train loss 0 ; train accuracy 0.998568892\n",
      "Step 2520 : train loss 0 ; train accuracy 0.998569429\n",
      "Step 2521 : train loss 3.72529e-09 ; train accuracy 0.99857\n",
      "Step 2522 : train loss 0 ; train accuracy 0.998570561\n",
      "Step 2523 : train loss 1.117587e-08 ; train accuracy 0.998571157\n",
      "Step 2524 : train loss 7.45057971e-09 ; train accuracy 0.998571694\n",
      "Step 2525 : train loss 7.45058e-09 ; train accuracy 0.99857229\n",
      "Step 2526 : train loss 0 ; train accuracy 0.998572826\n",
      "Step 2527 : train loss 7.45058e-09 ; train accuracy 0.998573422\n",
      "Step 2528 : train loss 7.45058e-09 ; train accuracy 0.998573959\n",
      "Step 2529 : train loss 7.45057971e-09 ; train accuracy 0.998574555\n",
      "Step 2530 : train loss 7.45057971e-09 ; train accuracy 0.998575091\n",
      "Step 2531 : train loss 0 ; train accuracy 0.998575687\n",
      "Step 2532 : train loss 1.49011603e-08 ; train accuracy 0.998576224\n",
      "Step 2533 : train loss 3.72529e-09 ; train accuracy 0.99857682\n",
      "Step 2534 : train loss 1.117587e-08 ; train accuracy 0.998577356\n",
      "Step 2535 : train loss 1.117587e-08 ; train accuracy 0.998577952\n",
      "Step 2536 : train loss 3.72529e-09 ; train accuracy 0.998578489\n",
      "Step 2537 : train loss 3.72529e-09 ; train accuracy 0.998579\n",
      "Step 2538 : train loss 1.117587e-08 ; train accuracy 0.998579621\n",
      "Step 2539 : train loss 0 ; train accuracy 0.998580158\n",
      "Step 2540 : train loss 0 ; train accuracy 0.998580754\n",
      "Step 2541 : train loss 3.72528959e-08 ; train accuracy 0.99858129\n",
      "Step 2542 : train loss 3.72529e-09 ; train accuracy 0.998581886\n",
      "Step 2543 : train loss 7.45058e-09 ; train accuracy 0.998582423\n",
      "Step 2544 : train loss 3.72529e-09 ; train accuracy 0.998582959\n",
      "Step 2545 : train loss 3.72529e-09 ; train accuracy 0.998583555\n",
      "Step 2546 : train loss 3.72529e-09 ; train accuracy 0.998584092\n",
      "Step 2547 : train loss 1.86264462e-08 ; train accuracy 0.998584628\n",
      "Step 2548 : train loss 7.45058e-09 ; train accuracy 0.998585224\n",
      "Step 2549 : train loss 1.117587e-08 ; train accuracy 0.998585761\n",
      "Step 2550 : train loss 3.72529e-09 ; train accuracy 0.998586297\n",
      "Step 2551 : train loss 3.72529e-09 ; train accuracy 0.998586893\n",
      "Step 2552 : train loss 7.45058e-09 ; train accuracy 0.99858743\n",
      "Step 2553 : train loss 7.45058e-09 ; train accuracy 0.998587966\n",
      "Step 2554 : train loss 1.117587e-08 ; train accuracy 0.998588562\n",
      "Step 2555 : train loss 3.72529e-09 ; train accuracy 0.998589098\n",
      "Step 2556 : train loss 3.72529e-09 ; train accuracy 0.998589635\n",
      "Step 2557 : train loss 7.45058e-09 ; train accuracy 0.998590231\n",
      "Step 2558 : train loss 0 ; train accuracy 0.998590767\n",
      "Step 2559 : train loss 1.117587e-08 ; train accuracy 0.998591304\n",
      "Step 2560 : train loss 0 ; train accuracy 0.99859184\n",
      "Step 2561 : train loss 1.49011576e-08 ; train accuracy 0.998592436\n",
      "Step 2562 : train loss 7.45058e-09 ; train accuracy 0.998593\n",
      "Step 2563 : train loss 7.45058e-09 ; train accuracy 0.998593509\n",
      "Step 2564 : train loss 3.72529e-09 ; train accuracy 0.998594046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2565 : train loss 1.117587e-08 ; train accuracy 0.998594642\n",
      "Step 2566 : train loss 3.72529e-09 ; train accuracy 0.998595178\n",
      "Step 2567 : train loss 3.72529e-09 ; train accuracy 0.998595715\n",
      "Step 2568 : train loss 2.98023188e-08 ; train accuracy 0.998596251\n",
      "Step 2569 : train loss 1.49011594e-08 ; train accuracy 0.998596787\n",
      "Step 2570 : train loss 3.72529e-09 ; train accuracy 0.998597383\n",
      "Step 2571 : train loss 0 ; train accuracy 0.99859792\n",
      "Step 2572 : train loss 0 ; train accuracy 0.998598456\n",
      "Step 2573 : train loss 7.45058e-09 ; train accuracy 0.998599\n",
      "Step 2574 : train loss 2.235174e-08 ; train accuracy 0.998599529\n",
      "Step 2575 : train loss 7.45058e-09 ; train accuracy 0.998600066\n",
      "Step 2576 : train loss 3.72529e-09 ; train accuracy 0.998600662\n",
      "Step 2577 : train loss 2.6077025e-08 ; train accuracy 0.998601198\n",
      "Step 2578 : train loss 3.72529e-09 ; train accuracy 0.998601735\n",
      "Step 2579 : train loss 7.45058e-09 ; train accuracy 0.998602271\n",
      "Step 2580 : train loss 7.45058e-09 ; train accuracy 0.998602808\n",
      "Step 2581 : train loss 7.45058e-09 ; train accuracy 0.998603344\n",
      "Step 2582 : train loss 2.235174e-08 ; train accuracy 0.99860388\n",
      "Step 2583 : train loss 7.45058e-09 ; train accuracy 0.998604417\n",
      "Step 2584 : train loss 2.235174e-08 ; train accuracy 0.998604953\n",
      "Step 2585 : train loss 1.117587e-08 ; train accuracy 0.998605549\n",
      "Step 2586 : train loss 1.117587e-08 ; train accuracy 0.998606086\n",
      "Step 2587 : train loss 1.86264497e-08 ; train accuracy 0.998606622\n",
      "Step 2588 : train loss 3.72529e-09 ; train accuracy 0.998607159\n",
      "Step 2589 : train loss 2.98023171e-08 ; train accuracy 0.998607695\n",
      "Step 2590 : train loss 3.72529e-09 ; train accuracy 0.998608232\n",
      "Step 2591 : train loss 1.117587e-08 ; train accuracy 0.998608768\n",
      "Step 2592 : train loss 1.49011594e-08 ; train accuracy 0.998609304\n",
      "Step 2593 : train loss 1.49011594e-08 ; train accuracy 0.998609841\n",
      "Step 2594 : train loss 0 ; train accuracy 0.998610377\n",
      "Step 2595 : train loss 8.51494875e-09 ; train accuracy 0.998610616\n",
      "val loss 3.97364275e-08 ; val accuracy 1\n",
      "Step 2596 : train loss 7.45058e-09 ; train accuracy 0.998611152\n",
      "Step 2597 : train loss 2.98023117e-08 ; train accuracy 0.998611689\n",
      "Step 2598 : train loss 7.45058e-09 ; train accuracy 0.998612225\n",
      "Step 2599 : train loss 3.72529e-09 ; train accuracy 0.998612761\n",
      "Step 2600 : train loss 7.45057971e-09 ; train accuracy 0.998613298\n",
      "Step 2601 : train loss 1.49011594e-08 ; train accuracy 0.998613834\n",
      "Step 2602 : train loss 3.72529e-09 ; train accuracy 0.998614371\n",
      "Step 2603 : train loss 3.72529e-09 ; train accuracy 0.998614907\n",
      "Step 2604 : train loss 1.49011594e-08 ; train accuracy 0.998615444\n",
      "Step 2605 : train loss 7.45057971e-09 ; train accuracy 0.998616\n",
      "Step 2606 : train loss 7.45058e-09 ; train accuracy 0.998616517\n",
      "Step 2607 : train loss 1.117587e-08 ; train accuracy 0.998617053\n",
      "Step 2608 : train loss 2.98023188e-08 ; train accuracy 0.99861753\n",
      "Step 2609 : train loss 0 ; train accuracy 0.998618066\n",
      "Step 2610 : train loss 1.117587e-08 ; train accuracy 0.998618603\n",
      "Step 2611 : train loss 3.72529e-09 ; train accuracy 0.998619139\n",
      "Step 2612 : train loss 3.72529e-09 ; train accuracy 0.998619676\n",
      "Step 2613 : train loss 7.45058e-09 ; train accuracy 0.998620212\n",
      "Step 2614 : train loss 3.72529e-09 ; train accuracy 0.998620749\n",
      "Step 2615 : train loss 3.72529e-09 ; train accuracy 0.998621285\n",
      "Step 2616 : train loss 1.117587e-08 ; train accuracy 0.998621821\n",
      "Step 2617 : train loss 3.72529e-09 ; train accuracy 0.998622298\n",
      "Step 2618 : train loss 3.72529e-09 ; train accuracy 0.998622835\n",
      "Step 2619 : train loss 2.6077025e-08 ; train accuracy 0.998623371\n",
      "Step 2620 : train loss 3.72529e-09 ; train accuracy 0.998623908\n",
      "Step 2621 : train loss 3.72529e-09 ; train accuracy 0.998624444\n",
      "Step 2622 : train loss 3.72529e-09 ; train accuracy 0.998625\n",
      "Step 2623 : train loss 0 ; train accuracy 0.998625457\n",
      "Step 2624 : train loss 0 ; train accuracy 0.998626\n",
      "Step 2625 : train loss 1.117587e-08 ; train accuracy 0.99862653\n",
      "Step 2626 : train loss 7.45058e-09 ; train accuracy 0.998627067\n",
      "Step 2627 : train loss 1.117587e-08 ; train accuracy 0.998627603\n",
      "Step 2628 : train loss 3.72529e-09 ; train accuracy 0.998628139\n",
      "Step 2629 : train loss 7.45058e-09 ; train accuracy 0.998628616\n",
      "Step 2630 : train loss 1.117587e-08 ; train accuracy 0.998629153\n",
      "Step 2631 : train loss 0 ; train accuracy 0.998629689\n",
      "Step 2632 : train loss 2.23517382e-08 ; train accuracy 0.998630226\n",
      "Step 2633 : train loss 7.45058e-09 ; train accuracy 0.998630702\n",
      "Step 2634 : train loss 7.45058e-09 ; train accuracy 0.998631239\n",
      "Step 2635 : train loss 1.49011603e-08 ; train accuracy 0.998631775\n",
      "Step 2636 : train loss 1.49011603e-08 ; train accuracy 0.998632312\n",
      "Step 2637 : train loss 0 ; train accuracy 0.998632789\n",
      "Step 2638 : train loss 7.45057971e-09 ; train accuracy 0.998633325\n",
      "Step 2639 : train loss 3.72529e-09 ; train accuracy 0.998633862\n",
      "Step 2640 : train loss 7.45058e-09 ; train accuracy 0.998634338\n",
      "Step 2641 : train loss 3.72529e-09 ; train accuracy 0.998634875\n",
      "Step 2642 : train loss 3.72529e-09 ; train accuracy 0.998635411\n",
      "Step 2643 : train loss 3.72529e-09 ; train accuracy 0.998635948\n",
      "Step 2644 : train loss 3.72529e-09 ; train accuracy 0.998636425\n",
      "Step 2645 : train loss 2.98023188e-08 ; train accuracy 0.998636961\n",
      "Step 2646 : train loss 3.72529e-09 ; train accuracy 0.998637497\n",
      "Step 2647 : train loss 1.86264497e-08 ; train accuracy 0.998638\n",
      "Step 2648 : train loss 0 ; train accuracy 0.998638511\n",
      "Step 2649 : train loss 1.86264479e-08 ; train accuracy 0.998639047\n",
      "Step 2650 : train loss 2.23517382e-08 ; train accuracy 0.998639524\n",
      "Step 2651 : train loss 7.45057971e-09 ; train accuracy 0.99864006\n",
      "Step 2652 : train loss 3.72529e-09 ; train accuracy 0.998640537\n",
      "Step 2653 : train loss 7.45058e-09 ; train accuracy 0.998641074\n",
      "Step 2654 : train loss 1.117587e-08 ; train accuracy 0.99864161\n",
      "Step 2655 : train loss 0 ; train accuracy 0.998642087\n",
      "Step 2656 : train loss 1.117587e-08 ; train accuracy 0.998642623\n",
      "Step 2657 : train loss 3.72529e-09 ; train accuracy 0.99864316\n",
      "Step 2658 : train loss 1.117587e-08 ; train accuracy 0.998643637\n",
      "Step 2659 : train loss 3.72529e-09 ; train accuracy 0.998644173\n",
      "Step 2660 : train loss 0 ; train accuracy 0.99864465\n",
      "Step 2661 : train loss 1.11758691e-08 ; train accuracy 0.998645186\n",
      "Step 2662 : train loss 3.72529e-09 ; train accuracy 0.998645663\n",
      "Step 2663 : train loss 0 ; train accuracy 0.9986462\n",
      "Step 2664 : train loss 3.72529e-09 ; train accuracy 0.998646736\n",
      "Step 2665 : train loss 0 ; train accuracy 0.998647213\n",
      "Step 2666 : train loss 1.86264479e-08 ; train accuracy 0.998647749\n",
      "Step 2667 : train loss 1.11758691e-08 ; train accuracy 0.998648226\n",
      "Step 2668 : train loss 7.45058e-09 ; train accuracy 0.998648763\n",
      "Step 2669 : train loss 7.45058e-09 ; train accuracy 0.99864924\n",
      "Step 2670 : train loss 1.86264497e-08 ; train accuracy 0.998649776\n",
      "Step 2671 : train loss 3.72529e-09 ; train accuracy 0.998650253\n",
      "Step 2672 : train loss 7.45058e-09 ; train accuracy 0.998650789\n",
      "Step 2673 : train loss 7.45058e-09 ; train accuracy 0.998651266\n",
      "Step 2674 : train loss 1.117587e-08 ; train accuracy 0.998651803\n",
      "Step 2675 : train loss 1.117587e-08 ; train accuracy 0.998652279\n",
      "Step 2676 : train loss 7.45058e-09 ; train accuracy 0.998652816\n",
      "Step 2677 : train loss 1.49011576e-08 ; train accuracy 0.998653293\n",
      "Step 2678 : train loss 3.72529e-09 ; train accuracy 0.998653829\n",
      "Step 2679 : train loss 3.72529e-09 ; train accuracy 0.998654306\n",
      "Step 2680 : train loss 0 ; train accuracy 0.998654842\n",
      "Step 2681 : train loss 3.72529e-09 ; train accuracy 0.998655319\n",
      "Step 2682 : train loss 1.117587e-08 ; train accuracy 0.998655796\n",
      "Step 2683 : train loss 0 ; train accuracy 0.998656332\n",
      "Step 2684 : train loss 0 ; train accuracy 0.998656809\n",
      "Step 2685 : train loss 3.72529e-09 ; train accuracy 0.998657346\n",
      "Step 2686 : train loss 3.72529e-09 ; train accuracy 0.998657823\n",
      "Step 2687 : train loss 0 ; train accuracy 0.998658299\n",
      "Step 2688 : train loss 3.72529e-09 ; train accuracy 0.998658836\n",
      "Step 2689 : train loss 1.117587e-08 ; train accuracy 0.998659313\n",
      "Step 2690 : train loss 3.72529e-09 ; train accuracy 0.998659849\n",
      "Step 2691 : train loss 3.72529e-09 ; train accuracy 0.998660326\n",
      "Step 2692 : train loss 3.72529e-09 ; train accuracy 0.998660803\n",
      "Step 2693 : train loss 7.45058e-09 ; train accuracy 0.998661339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2694 : train loss 0 ; train accuracy 0.998661816\n",
      "Step 2695 : train loss 1.11758691e-08 ; train accuracy 0.998662353\n",
      "Step 2696 : train loss 1.49011603e-08 ; train accuracy 0.998662829\n",
      "Step 2697 : train loss 7.45057971e-09 ; train accuracy 0.998663306\n",
      "Step 2698 : train loss 7.45058e-09 ; train accuracy 0.998663843\n",
      "Step 2699 : train loss 7.45057971e-09 ; train accuracy 0.99866432\n",
      "Step 2700 : train loss 1.86264497e-08 ; train accuracy 0.998664796\n",
      "Step 2701 : train loss 0 ; train accuracy 0.998665333\n",
      "Step 2702 : train loss 3.72529e-09 ; train accuracy 0.99866581\n",
      "Step 2703 : train loss 3.72529e-09 ; train accuracy 0.998666286\n",
      "Step 2704 : train loss 7.45058e-09 ; train accuracy 0.998666763\n",
      "Step 2705 : train loss 3.72529e-09 ; train accuracy 0.9986673\n",
      "Step 2706 : train loss 0 ; train accuracy 0.998667777\n",
      "Step 2707 : train loss 1.11758691e-08 ; train accuracy 0.998668253\n",
      "Step 2708 : train loss 1.117587e-08 ; train accuracy 0.99866879\n",
      "Step 2709 : train loss 3.72529e-09 ; train accuracy 0.998669267\n",
      "Step 2710 : train loss 1.117587e-08 ; train accuracy 0.998669744\n",
      "Step 2711 : train loss 1.117587e-08 ; train accuracy 0.99867022\n",
      "Step 2712 : train loss 3.72529e-09 ; train accuracy 0.998670757\n",
      "Step 2713 : train loss 3.72529e-09 ; train accuracy 0.998671234\n",
      "Step 2714 : train loss 0 ; train accuracy 0.99867171\n",
      "Step 2715 : train loss 1.117587e-08 ; train accuracy 0.998672187\n",
      "Step 2716 : train loss 1.49011603e-08 ; train accuracy 0.998672724\n",
      "Step 2717 : train loss 0 ; train accuracy 0.998673201\n",
      "Step 2718 : train loss 7.45058e-09 ; train accuracy 0.998673677\n",
      "Step 2719 : train loss 7.45058e-09 ; train accuracy 0.998674154\n",
      "Step 2720 : train loss 0 ; train accuracy 0.998674631\n",
      "Step 2721 : train loss 7.45057971e-09 ; train accuracy 0.998675168\n",
      "Step 2722 : train loss 1.117587e-08 ; train accuracy 0.998675644\n",
      "Step 2723 : train loss 0 ; train accuracy 0.998676121\n",
      "Step 2724 : train loss 3.72529e-09 ; train accuracy 0.998676598\n",
      "Step 2725 : train loss 3.72529e-09 ; train accuracy 0.998677075\n",
      "Step 2726 : train loss 0 ; train accuracy 0.998677611\n",
      "Step 2727 : train loss 0 ; train accuracy 0.998678088\n",
      "Step 2728 : train loss 3.72529e-09 ; train accuracy 0.998678565\n",
      "Step 2729 : train loss 3.35276056e-08 ; train accuracy 0.998679042\n",
      "Step 2730 : train loss 3.72529e-09 ; train accuracy 0.998679519\n",
      "Step 2731 : train loss 3.72529e-09 ; train accuracy 0.99868\n",
      "Step 2732 : train loss 0 ; train accuracy 0.998680472\n",
      "Step 2733 : train loss 2.23517382e-08 ; train accuracy 0.998681\n",
      "Step 2734 : train loss 3.72529e-09 ; train accuracy 0.998681486\n",
      "Step 2735 : train loss 3.72529e-09 ; train accuracy 0.998681962\n",
      "Step 2736 : train loss 1.49011603e-08 ; train accuracy 0.998682439\n",
      "Step 2737 : train loss 7.45058e-09 ; train accuracy 0.998682916\n",
      "Step 2738 : train loss 7.45058e-09 ; train accuracy 0.998683393\n",
      "Step 2739 : train loss 2.98023188e-08 ; train accuracy 0.99868387\n",
      "Step 2740 : train loss 0 ; train accuracy 0.998684347\n",
      "Step 2741 : train loss 1.49011603e-08 ; train accuracy 0.998684824\n",
      "Step 2742 : train loss 7.45058e-09 ; train accuracy 0.9986853\n",
      "Step 2743 : train loss 1.117587e-08 ; train accuracy 0.998685777\n",
      "Step 2744 : train loss 2.98023153e-08 ; train accuracy 0.998686314\n",
      "Step 2745 : train loss 7.45058e-09 ; train accuracy 0.99868679\n",
      "Step 2746 : train loss 0 ; train accuracy 0.998687267\n",
      "Step 2747 : train loss 0 ; train accuracy 0.998687744\n",
      "Step 2748 : train loss 1.117587e-08 ; train accuracy 0.998688221\n",
      "Step 2749 : train loss 1.49011603e-08 ; train accuracy 0.998688698\n",
      "Step 2750 : train loss 1.117587e-08 ; train accuracy 0.998689175\n",
      "Step 2751 : train loss 3.72529e-09 ; train accuracy 0.998689651\n",
      "Step 2752 : train loss 1.117587e-08 ; train accuracy 0.998690128\n",
      "Step 2753 : train loss 1.49011603e-08 ; train accuracy 0.998690605\n",
      "Step 2754 : train loss 3.72529e-09 ; train accuracy 0.998691082\n",
      "Step 2755 : train loss 7.45058e-09 ; train accuracy 0.998691559\n",
      "Step 2756 : train loss 7.45058e-09 ; train accuracy 0.998692036\n",
      "Step 2757 : train loss 2.23517365e-08 ; train accuracy 0.998692513\n",
      "Step 2758 : train loss 0 ; train accuracy 0.998693\n",
      "Step 2759 : train loss 1.86264497e-08 ; train accuracy 0.998693466\n",
      "Step 2760 : train loss 1.86264497e-08 ; train accuracy 0.998693943\n",
      "Step 2761 : train loss 7.45058e-09 ; train accuracy 0.99869442\n",
      "Step 2762 : train loss 3.72529e-09 ; train accuracy 0.998694897\n",
      "Step 2763 : train loss 1.49011603e-08 ; train accuracy 0.998695374\n",
      "Step 2764 : train loss 1.49011603e-08 ; train accuracy 0.998695791\n",
      "Step 2765 : train loss 3.72529e-09 ; train accuracy 0.998696268\n",
      "Step 2766 : train loss 7.45058e-09 ; train accuracy 0.998696744\n",
      "Step 2767 : train loss 1.86264497e-08 ; train accuracy 0.998697221\n",
      "Step 2768 : train loss 0 ; train accuracy 0.99869746\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 2769 : train loss 1.49011603e-08 ; train accuracy 0.998697937\n",
      "Step 2770 : train loss 2.98023117e-08 ; train accuracy 0.998698413\n",
      "Step 2771 : train loss 1.117587e-08 ; train accuracy 0.998698831\n",
      "Step 2772 : train loss 3.72529e-09 ; train accuracy 0.998699307\n",
      "Step 2773 : train loss 0 ; train accuracy 0.998699784\n",
      "Step 2774 : train loss 7.45058e-09 ; train accuracy 0.998700261\n",
      "Step 2775 : train loss 7.45058e-09 ; train accuracy 0.998700738\n",
      "Step 2776 : train loss 7.45058e-09 ; train accuracy 0.998701215\n",
      "Step 2777 : train loss 3.72529e-09 ; train accuracy 0.998701692\n",
      "Step 2778 : train loss 1.86264479e-08 ; train accuracy 0.998702168\n",
      "Step 2779 : train loss 0 ; train accuracy 0.998702645\n",
      "Step 2780 : train loss 7.45058e-09 ; train accuracy 0.998703063\n",
      "Step 2781 : train loss 0 ; train accuracy 0.998703539\n",
      "Step 2782 : train loss 0 ; train accuracy 0.998704\n",
      "Step 2783 : train loss 7.45057971e-09 ; train accuracy 0.998704493\n",
      "Step 2784 : train loss 1.117587e-08 ; train accuracy 0.99870497\n",
      "Step 2785 : train loss 0 ; train accuracy 0.998705447\n",
      "Step 2786 : train loss 1.117587e-08 ; train accuracy 0.998705864\n",
      "Step 2787 : train loss 3.72529e-09 ; train accuracy 0.998706341\n",
      "Step 2788 : train loss 3.72529e-09 ; train accuracy 0.998706818\n",
      "Step 2789 : train loss 7.45057971e-09 ; train accuracy 0.998707294\n",
      "Step 2790 : train loss 1.49011603e-08 ; train accuracy 0.998707771\n",
      "Step 2791 : train loss 7.45058e-09 ; train accuracy 0.998708189\n",
      "Step 2792 : train loss 3.72529e-09 ; train accuracy 0.998708665\n",
      "Step 2793 : train loss 0 ; train accuracy 0.998709142\n",
      "Step 2794 : train loss 7.45058e-09 ; train accuracy 0.998709619\n",
      "Step 2795 : train loss 1.117587e-08 ; train accuracy 0.998710096\n",
      "Step 2796 : train loss 0 ; train accuracy 0.998710513\n",
      "Step 2797 : train loss 0 ; train accuracy 0.998711\n",
      "Step 2798 : train loss 0 ; train accuracy 0.998711467\n",
      "Step 2799 : train loss 2.60770285e-08 ; train accuracy 0.998711944\n",
      "Step 2800 : train loss 1.117587e-08 ; train accuracy 0.998712361\n",
      "Step 2801 : train loss 7.45058e-09 ; train accuracy 0.998712838\n",
      "Step 2802 : train loss 1.49011594e-08 ; train accuracy 0.998713315\n",
      "Step 2803 : train loss 0 ; train accuracy 0.998713791\n",
      "Step 2804 : train loss 0 ; train accuracy 0.998714209\n",
      "Step 2805 : train loss 7.45058e-09 ; train accuracy 0.998714685\n",
      "Step 2806 : train loss 1.117587e-08 ; train accuracy 0.998715162\n",
      "Step 2807 : train loss 0 ; train accuracy 0.99871558\n",
      "Step 2808 : train loss 2.23517347e-08 ; train accuracy 0.998716056\n",
      "Step 2809 : train loss 3.72529e-09 ; train accuracy 0.998716533\n",
      "Step 2810 : train loss 1.117587e-08 ; train accuracy 0.99871695\n",
      "Step 2811 : train loss 1.117587e-08 ; train accuracy 0.998717427\n",
      "Step 2812 : train loss 7.45058e-09 ; train accuracy 0.998717904\n",
      "Step 2813 : train loss 7.45058e-09 ; train accuracy 0.998718321\n",
      "Step 2814 : train loss 0 ; train accuracy 0.998718798\n",
      "Step 2815 : train loss 3.72529e-09 ; train accuracy 0.998719275\n",
      "Step 2816 : train loss 3.72529e-09 ; train accuracy 0.998719692\n",
      "Step 2817 : train loss 2.98023188e-08 ; train accuracy 0.998720169\n",
      "Step 2818 : train loss 0 ; train accuracy 0.998720646\n",
      "Step 2819 : train loss 2.235174e-08 ; train accuracy 0.998721063\n",
      "Step 2820 : train loss 3.72529e-09 ; train accuracy 0.99872154\n",
      "Step 2821 : train loss 3.72529e-09 ; train accuracy 0.998722\n",
      "Step 2822 : train loss 0 ; train accuracy 0.998722434\n",
      "Step 2823 : train loss 3.72529e-09 ; train accuracy 0.998722911\n",
      "Step 2824 : train loss 1.86264497e-08 ; train accuracy 0.998723328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2825 : train loss 7.45057971e-09 ; train accuracy 0.998723805\n",
      "Step 2826 : train loss 0 ; train accuracy 0.998724282\n",
      "Step 2827 : train loss 1.49011594e-08 ; train accuracy 0.998724699\n",
      "Step 2828 : train loss 3.72529e-09 ; train accuracy 0.998725176\n",
      "Step 2829 : train loss 2.23517382e-08 ; train accuracy 0.998725593\n",
      "Step 2830 : train loss 7.45058e-09 ; train accuracy 0.99872607\n",
      "Step 2831 : train loss 7.45058e-09 ; train accuracy 0.998726547\n",
      "Step 2832 : train loss 0 ; train accuracy 0.998726964\n",
      "Step 2833 : train loss 3.72529e-09 ; train accuracy 0.998727441\n",
      "Step 2834 : train loss 1.49011594e-08 ; train accuracy 0.998727858\n",
      "Step 2835 : train loss 2.23517382e-08 ; train accuracy 0.998728335\n",
      "Step 2836 : train loss 0 ; train accuracy 0.998728752\n",
      "Step 2837 : train loss 7.45058e-09 ; train accuracy 0.998729229\n",
      "Step 2838 : train loss 1.49011603e-08 ; train accuracy 0.998729646\n",
      "Step 2839 : train loss 1.49011594e-08 ; train accuracy 0.998730123\n",
      "Step 2840 : train loss 3.72529e-09 ; train accuracy 0.9987306\n",
      "Step 2841 : train loss 7.45058e-09 ; train accuracy 0.998731\n",
      "Step 2842 : train loss 3.72529e-09 ; train accuracy 0.998731494\n",
      "Step 2843 : train loss 1.49011576e-08 ; train accuracy 0.998731911\n",
      "Step 2844 : train loss 0 ; train accuracy 0.998732388\n",
      "Step 2845 : train loss 3.72529e-09 ; train accuracy 0.998732805\n",
      "Step 2846 : train loss 1.117587e-08 ; train accuracy 0.998733282\n",
      "Step 2847 : train loss 0 ; train accuracy 0.998733699\n",
      "Step 2848 : train loss 7.45057971e-09 ; train accuracy 0.998734176\n",
      "Step 2849 : train loss 0 ; train accuracy 0.998734593\n",
      "Step 2850 : train loss 1.117587e-08 ; train accuracy 0.99873507\n",
      "Step 2851 : train loss 0 ; train accuracy 0.998735487\n",
      "Step 2852 : train loss 0 ; train accuracy 0.998735905\n",
      "Step 2853 : train loss 7.45058e-09 ; train accuracy 0.998736382\n",
      "Step 2854 : train loss 1.117587e-08 ; train accuracy 0.998736799\n",
      "Step 2855 : train loss 3.72529e-09 ; train accuracy 0.998737276\n",
      "Step 2856 : train loss 0 ; train accuracy 0.998737693\n",
      "Step 2857 : train loss 7.45058e-09 ; train accuracy 0.99873817\n",
      "Step 2858 : train loss 1.117587e-08 ; train accuracy 0.998738587\n",
      "Step 2859 : train loss 1.49011603e-08 ; train accuracy 0.998739064\n",
      "Step 2860 : train loss 1.117587e-08 ; train accuracy 0.998739481\n",
      "Step 2861 : train loss 1.117587e-08 ; train accuracy 0.998739898\n",
      "Step 2862 : train loss 1.117587e-08 ; train accuracy 0.998740375\n",
      "Step 2863 : train loss 3.72529e-09 ; train accuracy 0.998740792\n",
      "Step 2864 : train loss 3.72529e-09 ; train accuracy 0.998741269\n",
      "Step 2865 : train loss 7.45058e-09 ; train accuracy 0.998741686\n",
      "Step 2866 : train loss 3.72529e-09 ; train accuracy 0.998742104\n",
      "Step 2867 : train loss 3.72529e-09 ; train accuracy 0.99874258\n",
      "Step 2868 : train loss 3.72529e-09 ; train accuracy 0.998743\n",
      "Step 2869 : train loss 0 ; train accuracy 0.998743415\n",
      "Step 2870 : train loss 0 ; train accuracy 0.998743892\n",
      "Step 2871 : train loss 7.45058e-09 ; train accuracy 0.998744309\n",
      "Step 2872 : train loss 3.72529e-09 ; train accuracy 0.998744786\n",
      "Step 2873 : train loss 3.72529e-09 ; train accuracy 0.998745203\n",
      "Step 2874 : train loss 0 ; train accuracy 0.99874562\n",
      "Step 2875 : train loss 3.72529e-09 ; train accuracy 0.998746097\n",
      "Step 2876 : train loss 7.45058e-09 ; train accuracy 0.998746514\n",
      "Step 2877 : train loss 7.45057971e-09 ; train accuracy 0.998746932\n",
      "Step 2878 : train loss 1.117587e-08 ; train accuracy 0.998747408\n",
      "Step 2879 : train loss 3.72529e-09 ; train accuracy 0.998747826\n",
      "Step 2880 : train loss 3.72529e-09 ; train accuracy 0.998748243\n",
      "Step 2881 : train loss 3.72529e-09 ; train accuracy 0.99874872\n",
      "Step 2882 : train loss 3.72529e-09 ; train accuracy 0.998749137\n",
      "Step 2883 : train loss 0 ; train accuracy 0.998749554\n",
      "Step 2884 : train loss 2.98023188e-08 ; train accuracy 0.99875\n",
      "Step 2885 : train loss 1.117587e-08 ; train accuracy 0.998750448\n",
      "Step 2886 : train loss 3.72529e-09 ; train accuracy 0.998750865\n",
      "Step 2887 : train loss 3.72529e-09 ; train accuracy 0.998751283\n",
      "Step 2888 : train loss 2.235174e-08 ; train accuracy 0.99875176\n",
      "Step 2889 : train loss 0 ; train accuracy 0.998752177\n",
      "Step 2890 : train loss 0 ; train accuracy 0.998752594\n",
      "Step 2891 : train loss 3.72529e-09 ; train accuracy 0.998753\n",
      "Step 2892 : train loss 0 ; train accuracy 0.998753488\n",
      "Step 2893 : train loss 0 ; train accuracy 0.998753905\n",
      "Step 2894 : train loss 7.45058e-09 ; train accuracy 0.998754323\n",
      "Step 2895 : train loss 3.72529e-09 ; train accuracy 0.99875474\n",
      "Step 2896 : train loss 7.45058e-09 ; train accuracy 0.998755217\n",
      "Step 2897 : train loss 1.86264462e-08 ; train accuracy 0.998755634\n",
      "Step 2898 : train loss 3.72529e-09 ; train accuracy 0.998756051\n",
      "Step 2899 : train loss 7.45058e-09 ; train accuracy 0.998756468\n",
      "Step 2900 : train loss 7.45058e-09 ; train accuracy 0.998756945\n",
      "Step 2901 : train loss 1.117587e-08 ; train accuracy 0.998757362\n",
      "Step 2902 : train loss 1.86264497e-08 ; train accuracy 0.99875778\n",
      "Step 2903 : train loss 0 ; train accuracy 0.998758197\n",
      "Step 2904 : train loss 0 ; train accuracy 0.998758614\n",
      "Step 2905 : train loss 3.72529e-09 ; train accuracy 0.998759091\n",
      "Step 2906 : train loss 3.72529e-09 ; train accuracy 0.998759508\n",
      "Step 2907 : train loss 3.72529e-09 ; train accuracy 0.998759925\n",
      "Step 2908 : train loss 1.86264497e-08 ; train accuracy 0.998760343\n",
      "Step 2909 : train loss 3.72529e-09 ; train accuracy 0.99876076\n",
      "Step 2910 : train loss 7.45057971e-09 ; train accuracy 0.998761177\n",
      "Step 2911 : train loss 0 ; train accuracy 0.998761654\n",
      "Step 2912 : train loss 0 ; train accuracy 0.998762071\n",
      "Step 2913 : train loss 7.45058e-09 ; train accuracy 0.998762488\n",
      "Step 2914 : train loss 1.86264497e-08 ; train accuracy 0.998762906\n",
      "Step 2915 : train loss 7.45058e-09 ; train accuracy 0.998763323\n",
      "Step 2916 : train loss 2.6077025e-08 ; train accuracy 0.99876374\n",
      "Step 2917 : train loss 7.45058e-09 ; train accuracy 0.998764157\n",
      "Step 2918 : train loss 7.45058e-09 ; train accuracy 0.998764634\n",
      "Step 2919 : train loss 3.72529e-09 ; train accuracy 0.998765051\n",
      "Step 2920 : train loss 2.60770268e-08 ; train accuracy 0.998765469\n",
      "Step 2921 : train loss 1.117587e-08 ; train accuracy 0.998765886\n",
      "Step 2922 : train loss 1.117587e-08 ; train accuracy 0.998766303\n",
      "Step 2923 : train loss 7.45058e-09 ; train accuracy 0.99876672\n",
      "Step 2924 : train loss 1.117587e-08 ; train accuracy 0.998767138\n",
      "Step 2925 : train loss 0 ; train accuracy 0.998767555\n",
      "Step 2926 : train loss 3.72529e-09 ; train accuracy 0.998768\n",
      "Step 2927 : train loss 7.45058e-09 ; train accuracy 0.998768449\n",
      "Step 2928 : train loss 1.49011603e-08 ; train accuracy 0.998768866\n",
      "Step 2929 : train loss 0 ; train accuracy 0.998769283\n",
      "Step 2930 : train loss 1.49011594e-08 ; train accuracy 0.998769701\n",
      "Step 2931 : train loss 2.60770285e-08 ; train accuracy 0.998770118\n",
      "Step 2932 : train loss 0 ; train accuracy 0.998770535\n",
      "Step 2933 : train loss 1.49011603e-08 ; train accuracy 0.998770952\n",
      "Step 2934 : train loss 1.117587e-08 ; train accuracy 0.998771369\n",
      "Step 2935 : train loss 7.45058e-09 ; train accuracy 0.998771787\n",
      "Step 2936 : train loss 1.117587e-08 ; train accuracy 0.998772204\n",
      "Step 2937 : train loss 7.45058e-09 ; train accuracy 0.998772621\n",
      "Step 2938 : train loss 1.49011603e-08 ; train accuracy 0.998773038\n",
      "Step 2939 : train loss 1.117587e-08 ; train accuracy 0.998773456\n",
      "Step 2940 : train loss 1.117587e-08 ; train accuracy 0.998773873\n",
      "Step 2941 : train loss 8.51494875e-09 ; train accuracy 0.998774052\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 2942 : train loss 1.49011603e-08 ; train accuracy 0.998774469\n",
      "Step 2943 : train loss 3.72529e-09 ; train accuracy 0.998774886\n",
      "Step 2944 : train loss 0 ; train accuracy 0.998775303\n",
      "Step 2945 : train loss 1.86264497e-08 ; train accuracy 0.998775721\n",
      "Step 2946 : train loss 0 ; train accuracy 0.998776138\n",
      "Step 2947 : train loss 7.45058e-09 ; train accuracy 0.998776555\n",
      "Step 2948 : train loss 1.117587e-08 ; train accuracy 0.998777\n",
      "Step 2949 : train loss 2.23517365e-08 ; train accuracy 0.99877739\n",
      "Step 2950 : train loss 1.117587e-08 ; train accuracy 0.998777807\n",
      "Step 2951 : train loss 1.11758691e-08 ; train accuracy 0.998778224\n",
      "Step 2952 : train loss 7.45058e-09 ; train accuracy 0.998778641\n",
      "Step 2953 : train loss 7.45058e-09 ; train accuracy 0.998779058\n",
      "Step 2954 : train loss 3.72529e-09 ; train accuracy 0.998779476\n",
      "Step 2955 : train loss 2.23517382e-08 ; train accuracy 0.998779893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2956 : train loss 1.117587e-08 ; train accuracy 0.99878031\n",
      "Step 2957 : train loss 0 ; train accuracy 0.998780727\n",
      "Step 2958 : train loss 7.45058e-09 ; train accuracy 0.998781145\n",
      "Step 2959 : train loss 3.72529e-09 ; train accuracy 0.998781562\n",
      "Step 2960 : train loss 0 ; train accuracy 0.998782\n",
      "Step 2961 : train loss 1.11758691e-08 ; train accuracy 0.998782396\n",
      "Step 2962 : train loss 1.117587e-08 ; train accuracy 0.998782814\n",
      "Step 2963 : train loss 1.117587e-08 ; train accuracy 0.998783171\n",
      "Step 2964 : train loss 7.45057971e-09 ; train accuracy 0.998783588\n",
      "Step 2965 : train loss 7.45058e-09 ; train accuracy 0.998784\n",
      "Step 2966 : train loss 7.45058e-09 ; train accuracy 0.998784423\n",
      "Step 2967 : train loss 0 ; train accuracy 0.99878484\n",
      "Step 2968 : train loss 0 ; train accuracy 0.998785257\n",
      "Step 2969 : train loss 3.72529e-09 ; train accuracy 0.998785675\n",
      "Step 2970 : train loss 3.72529e-09 ; train accuracy 0.998786092\n",
      "Step 2971 : train loss 7.45057971e-09 ; train accuracy 0.998786509\n",
      "Step 2972 : train loss 3.72529e-09 ; train accuracy 0.998786867\n",
      "Step 2973 : train loss 3.72529e-09 ; train accuracy 0.998787284\n",
      "Step 2974 : train loss 7.45058e-09 ; train accuracy 0.998787701\n",
      "Step 2975 : train loss 7.45058e-09 ; train accuracy 0.998788118\n",
      "Step 2976 : train loss 1.86264497e-08 ; train accuracy 0.998788536\n",
      "Step 2977 : train loss 0 ; train accuracy 0.998788953\n",
      "Step 2978 : train loss 0 ; train accuracy 0.99878937\n",
      "Step 2979 : train loss 1.117587e-08 ; train accuracy 0.998789728\n",
      "Step 2980 : train loss 3.72529e-09 ; train accuracy 0.998790145\n",
      "Step 2981 : train loss 7.45058e-09 ; train accuracy 0.998790562\n",
      "Step 2982 : train loss 3.72529e-09 ; train accuracy 0.998791\n",
      "Step 2983 : train loss 0 ; train accuracy 0.998791397\n",
      "Step 2984 : train loss 3.72529e-09 ; train accuracy 0.998791814\n",
      "Step 2985 : train loss 0 ; train accuracy 0.998792171\n",
      "Step 2986 : train loss 7.45057971e-09 ; train accuracy 0.998792589\n",
      "Step 2987 : train loss 7.45057971e-09 ; train accuracy 0.998793\n",
      "Step 2988 : train loss 1.49011603e-08 ; train accuracy 0.998793423\n",
      "Step 2989 : train loss 0 ; train accuracy 0.99879384\n",
      "Step 2990 : train loss 3.72529e-09 ; train accuracy 0.998794198\n",
      "Step 2991 : train loss 7.45058e-09 ; train accuracy 0.998794615\n",
      "Step 2992 : train loss 7.45058e-09 ; train accuracy 0.998795033\n",
      "Step 2993 : train loss 7.45058e-09 ; train accuracy 0.99879545\n",
      "Step 2994 : train loss 1.11758691e-08 ; train accuracy 0.998795807\n",
      "Step 2995 : train loss 1.86264497e-08 ; train accuracy 0.998796225\n",
      "Step 2996 : train loss 3.72529e-09 ; train accuracy 0.998796642\n",
      "Step 2997 : train loss 7.45058e-09 ; train accuracy 0.998797059\n",
      "Step 2998 : train loss 1.117587e-08 ; train accuracy 0.998797476\n",
      "Step 2999 : train loss 1.49011603e-08 ; train accuracy 0.998797834\n",
      "Step 3000 : train loss 3.72529e-09 ; train accuracy 0.998798251\n",
      "Step 3001 : train loss 1.49011603e-08 ; train accuracy 0.998798668\n",
      "Step 3002 : train loss 3.72529e-09 ; train accuracy 0.998799086\n",
      "Step 3003 : train loss 1.86264497e-08 ; train accuracy 0.998799443\n",
      "Step 3004 : train loss 7.45057971e-09 ; train accuracy 0.99879986\n",
      "Step 3005 : train loss 0 ; train accuracy 0.998800278\n",
      "Step 3006 : train loss 0 ; train accuracy 0.998800635\n",
      "Step 3007 : train loss 3.72529e-09 ; train accuracy 0.998801053\n",
      "Step 3008 : train loss 3.72529e-09 ; train accuracy 0.99880147\n",
      "Step 3009 : train loss 3.72529e-09 ; train accuracy 0.998801887\n",
      "Step 3010 : train loss 1.117587e-08 ; train accuracy 0.998802245\n",
      "Step 3011 : train loss 1.86264479e-08 ; train accuracy 0.998802662\n",
      "Step 3012 : train loss 0 ; train accuracy 0.998803079\n",
      "Step 3013 : train loss 1.49011594e-08 ; train accuracy 0.998803437\n",
      "Step 3014 : train loss 3.72529e-09 ; train accuracy 0.998803854\n",
      "Step 3015 : train loss 0 ; train accuracy 0.998804271\n",
      "Step 3016 : train loss 1.86264479e-08 ; train accuracy 0.998804629\n",
      "Step 3017 : train loss 0 ; train accuracy 0.998805046\n",
      "Step 3018 : train loss 0 ; train accuracy 0.998805463\n",
      "Step 3019 : train loss 3.72529e-09 ; train accuracy 0.998805821\n",
      "Step 3020 : train loss 1.117587e-08 ; train accuracy 0.998806238\n",
      "Step 3021 : train loss 3.72529e-09 ; train accuracy 0.998806655\n",
      "Step 3022 : train loss 1.117587e-08 ; train accuracy 0.998807\n",
      "Step 3023 : train loss 0 ; train accuracy 0.99880743\n",
      "Step 3024 : train loss 2.235174e-08 ; train accuracy 0.998807847\n",
      "Step 3025 : train loss 3.72529e-09 ; train accuracy 0.998808205\n",
      "Step 3026 : train loss 3.72529e-09 ; train accuracy 0.998808622\n",
      "Step 3027 : train loss 0 ; train accuracy 0.998809\n",
      "Step 3028 : train loss 7.45058e-09 ; train accuracy 0.998809397\n",
      "Step 3029 : train loss 1.117587e-08 ; train accuracy 0.998809814\n",
      "Step 3030 : train loss 3.72529e-09 ; train accuracy 0.998810172\n",
      "Step 3031 : train loss 7.45058e-09 ; train accuracy 0.998810589\n",
      "Step 3032 : train loss 3.72529e-09 ; train accuracy 0.998810947\n",
      "Step 3033 : train loss 1.49011603e-08 ; train accuracy 0.998811364\n",
      "Step 3034 : train loss 0 ; train accuracy 0.998811781\n",
      "Step 3035 : train loss 3.72529e-09 ; train accuracy 0.998812139\n",
      "Step 3036 : train loss 7.45057971e-09 ; train accuracy 0.998812556\n",
      "Step 3037 : train loss 3.72529e-09 ; train accuracy 0.998812914\n",
      "Step 3038 : train loss 3.72529e-09 ; train accuracy 0.998813331\n",
      "Step 3039 : train loss 1.117587e-08 ; train accuracy 0.998813748\n",
      "Step 3040 : train loss 0 ; train accuracy 0.998814106\n",
      "Step 3041 : train loss 7.45058e-09 ; train accuracy 0.998814523\n",
      "Step 3042 : train loss 3.72529e-09 ; train accuracy 0.998814881\n",
      "Step 3043 : train loss 3.72529e-09 ; train accuracy 0.998815298\n",
      "Step 3044 : train loss 7.45058e-09 ; train accuracy 0.998815656\n",
      "Step 3045 : train loss 3.72529e-09 ; train accuracy 0.998816073\n",
      "Step 3046 : train loss 3.72529e-09 ; train accuracy 0.998816431\n",
      "Step 3047 : train loss 7.45058e-09 ; train accuracy 0.998816848\n",
      "Step 3048 : train loss 1.117587e-08 ; train accuracy 0.998817265\n",
      "Step 3049 : train loss 0 ; train accuracy 0.998817623\n",
      "Step 3050 : train loss 0 ; train accuracy 0.99881804\n",
      "Step 3051 : train loss 0 ; train accuracy 0.998818398\n",
      "Step 3052 : train loss 1.49011594e-08 ; train accuracy 0.998818815\n",
      "Step 3053 : train loss 0 ; train accuracy 0.998819172\n",
      "Step 3054 : train loss 1.86264497e-08 ; train accuracy 0.99881959\n",
      "Step 3055 : train loss 1.49011594e-08 ; train accuracy 0.998819947\n",
      "Step 3056 : train loss 0 ; train accuracy 0.998820364\n",
      "Step 3057 : train loss 3.72529e-09 ; train accuracy 0.998820722\n",
      "Step 3058 : train loss 3.72529e-09 ; train accuracy 0.998821139\n",
      "Step 3059 : train loss 3.72529e-09 ; train accuracy 0.998821497\n",
      "Step 3060 : train loss 0 ; train accuracy 0.998821914\n",
      "Step 3061 : train loss 3.72529e-09 ; train accuracy 0.998822272\n",
      "Step 3062 : train loss 3.72529e-09 ; train accuracy 0.998822689\n",
      "Step 3063 : train loss 7.45058e-09 ; train accuracy 0.998823047\n",
      "Step 3064 : train loss 3.72529e-09 ; train accuracy 0.998823404\n",
      "Step 3065 : train loss 1.49011603e-08 ; train accuracy 0.998823822\n",
      "Step 3066 : train loss 3.72529e-09 ; train accuracy 0.998824179\n",
      "Step 3067 : train loss 0 ; train accuracy 0.998824596\n",
      "Step 3068 : train loss 0 ; train accuracy 0.998824954\n",
      "Step 3069 : train loss 3.72529e-09 ; train accuracy 0.998825371\n",
      "Step 3070 : train loss 0 ; train accuracy 0.998825729\n",
      "Step 3071 : train loss 3.72529e-09 ; train accuracy 0.998826146\n",
      "Step 3072 : train loss 3.72529e-09 ; train accuracy 0.998826504\n",
      "Step 3073 : train loss 7.45057971e-09 ; train accuracy 0.998826861\n",
      "Step 3074 : train loss 3.72529e-09 ; train accuracy 0.998827279\n",
      "Step 3075 : train loss 2.98023188e-08 ; train accuracy 0.998827636\n",
      "Step 3076 : train loss 7.45058e-09 ; train accuracy 0.998828053\n",
      "Step 3077 : train loss 3.72529e-09 ; train accuracy 0.998828411\n",
      "Step 3078 : train loss 7.45058e-09 ; train accuracy 0.998828828\n",
      "Step 3079 : train loss 7.45058e-09 ; train accuracy 0.998829186\n",
      "Step 3080 : train loss 7.45058e-09 ; train accuracy 0.998829544\n",
      "Step 3081 : train loss 7.45057971e-09 ; train accuracy 0.998829961\n",
      "Step 3082 : train loss 7.45058e-09 ; train accuracy 0.998830318\n",
      "Step 3083 : train loss 3.72529e-09 ; train accuracy 0.998830736\n",
      "Step 3084 : train loss 1.117587e-08 ; train accuracy 0.998831093\n",
      "Step 3085 : train loss 2.60770268e-08 ; train accuracy 0.998831451\n",
      "Step 3086 : train loss 3.72529e-09 ; train accuracy 0.998831868\n",
      "Step 3087 : train loss 3.72529e-09 ; train accuracy 0.998832226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3088 : train loss 1.86264497e-08 ; train accuracy 0.998832583\n",
      "Step 3089 : train loss 2.60770285e-08 ; train accuracy 0.998833\n",
      "Step 3090 : train loss 1.117587e-08 ; train accuracy 0.998833358\n",
      "Step 3091 : train loss 0 ; train accuracy 0.998833716\n",
      "Step 3092 : train loss 3.72529e-09 ; train accuracy 0.998834133\n",
      "Step 3093 : train loss 7.45058e-09 ; train accuracy 0.998834491\n",
      "Step 3094 : train loss 3.72529e-09 ; train accuracy 0.998834848\n",
      "Step 3095 : train loss 1.86264497e-08 ; train accuracy 0.998835266\n",
      "Step 3096 : train loss 1.86264497e-08 ; train accuracy 0.998835623\n",
      "Step 3097 : train loss 1.117587e-08 ; train accuracy 0.998836\n",
      "Step 3098 : train loss 7.45058e-09 ; train accuracy 0.998836398\n",
      "Step 3099 : train loss 7.45058e-09 ; train accuracy 0.998836756\n",
      "Step 3100 : train loss 1.49011603e-08 ; train accuracy 0.998837113\n",
      "Step 3101 : train loss 1.49011576e-08 ; train accuracy 0.998837531\n",
      "Step 3102 : train loss 1.86264497e-08 ; train accuracy 0.998837888\n",
      "Step 3103 : train loss 3.72529e-09 ; train accuracy 0.998838246\n",
      "Step 3104 : train loss 7.45058e-09 ; train accuracy 0.998838663\n",
      "Step 3105 : train loss 4.09781862e-08 ; train accuracy 0.998839\n",
      "Step 3106 : train loss 3.72529e-09 ; train accuracy 0.998839378\n",
      "Step 3107 : train loss 3.72529e-09 ; train accuracy 0.998839796\n",
      "Step 3108 : train loss 3.72529e-09 ; train accuracy 0.998840153\n",
      "Step 3109 : train loss 3.72529e-09 ; train accuracy 0.998840511\n",
      "Step 3110 : train loss 2.235174e-08 ; train accuracy 0.998840868\n",
      "Step 3111 : train loss 3.72529e-09 ; train accuracy 0.998841286\n",
      "Step 3112 : train loss 1.117587e-08 ; train accuracy 0.998841643\n",
      "Step 3113 : train loss 1.86264497e-08 ; train accuracy 0.998842\n",
      "Step 3114 : train loss 0 ; train accuracy 0.99884218\n",
      "val loss 3.97364275e-08 ; val accuracy 1\n",
      "Step 3115 : train loss 3.72529e-09 ; train accuracy 0.998842537\n",
      "Step 3116 : train loss 1.117587e-08 ; train accuracy 0.998842895\n",
      "Step 3117 : train loss 3.72529e-09 ; train accuracy 0.998843312\n",
      "Step 3118 : train loss 7.45058e-09 ; train accuracy 0.99884367\n",
      "Step 3119 : train loss 7.45058e-09 ; train accuracy 0.998844\n",
      "Step 3120 : train loss 3.72529e-09 ; train accuracy 0.998844385\n",
      "Step 3121 : train loss 0 ; train accuracy 0.998844802\n",
      "Step 3122 : train loss 7.45058e-09 ; train accuracy 0.99884516\n",
      "Step 3123 : train loss 3.35276056e-08 ; train accuracy 0.998845518\n",
      "Step 3124 : train loss 3.72529e-09 ; train accuracy 0.998845875\n",
      "Step 3125 : train loss 3.72529e-09 ; train accuracy 0.998846233\n",
      "Step 3126 : train loss 1.86264497e-08 ; train accuracy 0.99884665\n",
      "Step 3127 : train loss 0 ; train accuracy 0.998847\n",
      "Step 3128 : train loss 7.45058e-09 ; train accuracy 0.998847365\n",
      "Step 3129 : train loss 3.72529e-09 ; train accuracy 0.998847723\n",
      "Step 3130 : train loss 0 ; train accuracy 0.99884814\n",
      "Step 3131 : train loss 3.72529e-09 ; train accuracy 0.998848498\n",
      "Step 3132 : train loss 1.86264479e-08 ; train accuracy 0.998848855\n",
      "Step 3133 : train loss 3.72529e-09 ; train accuracy 0.998849213\n",
      "Step 3134 : train loss 7.45058e-09 ; train accuracy 0.998849571\n",
      "Step 3135 : train loss 0 ; train accuracy 0.998849928\n",
      "Step 3136 : train loss 1.117587e-08 ; train accuracy 0.998850346\n",
      "Step 3137 : train loss 7.45058e-09 ; train accuracy 0.998850703\n",
      "Step 3138 : train loss 3.72529e-09 ; train accuracy 0.998851061\n",
      "Step 3139 : train loss 2.235174e-08 ; train accuracy 0.998851418\n",
      "Step 3140 : train loss 1.117587e-08 ; train accuracy 0.998851776\n",
      "Step 3141 : train loss 7.45057971e-09 ; train accuracy 0.998852134\n",
      "Step 3142 : train loss 3.72529e-09 ; train accuracy 0.998852551\n",
      "Step 3143 : train loss 1.117587e-08 ; train accuracy 0.998852909\n",
      "Step 3144 : train loss 0 ; train accuracy 0.998853266\n",
      "Step 3145 : train loss 0 ; train accuracy 0.998853624\n",
      "Step 3146 : train loss 7.45058e-09 ; train accuracy 0.998854\n",
      "Step 3147 : train loss 1.11758691e-08 ; train accuracy 0.998854339\n",
      "Step 3148 : train loss 3.72529e-09 ; train accuracy 0.998854697\n",
      "Step 3149 : train loss 7.45057971e-09 ; train accuracy 0.998855054\n",
      "Step 3150 : train loss 0 ; train accuracy 0.998855472\n",
      "Step 3151 : train loss 3.72529e-09 ; train accuracy 0.998855829\n",
      "Step 3152 : train loss 3.72529e-09 ; train accuracy 0.998856187\n",
      "Step 3153 : train loss 3.72529e-09 ; train accuracy 0.998856544\n",
      "Step 3154 : train loss 0 ; train accuracy 0.998856902\n",
      "Step 3155 : train loss 0 ; train accuracy 0.99885726\n",
      "Step 3156 : train loss 0 ; train accuracy 0.998857617\n",
      "Step 3157 : train loss 3.72529e-09 ; train accuracy 0.998858\n",
      "Step 3158 : train loss 1.49011603e-08 ; train accuracy 0.998858333\n",
      "Step 3159 : train loss 3.72529e-09 ; train accuracy 0.99885869\n",
      "Step 3160 : train loss 3.72529e-09 ; train accuracy 0.998859107\n",
      "Step 3161 : train loss 1.117587e-08 ; train accuracy 0.998859465\n",
      "Step 3162 : train loss 1.117587e-08 ; train accuracy 0.998859823\n",
      "Step 3163 : train loss 0 ; train accuracy 0.99886018\n",
      "Step 3164 : train loss 1.86264479e-08 ; train accuracy 0.998860538\n",
      "Step 3165 : train loss 1.86264497e-08 ; train accuracy 0.998860896\n",
      "Step 3166 : train loss 0 ; train accuracy 0.998861253\n",
      "Step 3167 : train loss 1.117587e-08 ; train accuracy 0.998861611\n",
      "Step 3168 : train loss 3.72529e-09 ; train accuracy 0.998861969\n",
      "Step 3169 : train loss 1.49011603e-08 ; train accuracy 0.998862326\n",
      "Step 3170 : train loss 2.235174e-08 ; train accuracy 0.998862684\n",
      "Step 3171 : train loss 0 ; train accuracy 0.998863041\n",
      "Step 3172 : train loss 3.72529e-09 ; train accuracy 0.998863399\n",
      "Step 3173 : train loss 0 ; train accuracy 0.998863757\n",
      "Step 3174 : train loss 1.49011594e-08 ; train accuracy 0.998864114\n",
      "Step 3175 : train loss 1.49011603e-08 ; train accuracy 0.998864472\n",
      "Step 3176 : train loss 1.49011603e-08 ; train accuracy 0.99886483\n",
      "Step 3177 : train loss 1.86264497e-08 ; train accuracy 0.998865187\n",
      "Step 3178 : train loss 0 ; train accuracy 0.998865545\n",
      "Step 3179 : train loss 1.117587e-08 ; train accuracy 0.998865902\n",
      "Step 3180 : train loss 2.23517382e-08 ; train accuracy 0.99886626\n",
      "Step 3181 : train loss 7.45058e-09 ; train accuracy 0.998866618\n",
      "Step 3182 : train loss 0 ; train accuracy 0.998867\n",
      "Step 3183 : train loss 0 ; train accuracy 0.998867333\n",
      "Step 3184 : train loss 3.72529e-09 ; train accuracy 0.998867691\n",
      "Step 3185 : train loss 3.72529e-09 ; train accuracy 0.998868048\n",
      "Step 3186 : train loss 3.72529e-09 ; train accuracy 0.998868406\n",
      "Step 3187 : train loss 0 ; train accuracy 0.998868763\n",
      "Step 3188 : train loss 7.45058e-09 ; train accuracy 0.998869121\n",
      "Step 3189 : train loss 7.45058e-09 ; train accuracy 0.998869479\n",
      "Step 3190 : train loss 3.72529e-09 ; train accuracy 0.998869836\n",
      "Step 3191 : train loss 1.86264479e-08 ; train accuracy 0.998870194\n",
      "Step 3192 : train loss 3.72529e-09 ; train accuracy 0.998870552\n",
      "Step 3193 : train loss 7.45058e-09 ; train accuracy 0.998870909\n",
      "Step 3194 : train loss 0 ; train accuracy 0.998871267\n",
      "Step 3195 : train loss 0 ; train accuracy 0.998871624\n",
      "Step 3196 : train loss 0 ; train accuracy 0.998872\n",
      "Step 3197 : train loss 3.72529e-09 ; train accuracy 0.99887234\n",
      "Step 3198 : train loss 3.72529e-09 ; train accuracy 0.998872697\n",
      "Step 3199 : train loss 1.117587e-08 ; train accuracy 0.998873055\n",
      "Step 3200 : train loss 3.72529e-09 ; train accuracy 0.998873413\n",
      "Step 3201 : train loss 1.49011603e-08 ; train accuracy 0.99887377\n",
      "Step 3202 : train loss 7.45057971e-09 ; train accuracy 0.998874068\n",
      "Step 3203 : train loss 1.117587e-08 ; train accuracy 0.998874426\n",
      "Step 3204 : train loss 7.45058e-09 ; train accuracy 0.998874784\n",
      "Step 3205 : train loss 1.86264479e-08 ; train accuracy 0.998875141\n",
      "Step 3206 : train loss 0 ; train accuracy 0.998875499\n",
      "Step 3207 : train loss 0 ; train accuracy 0.998875856\n",
      "Step 3208 : train loss 7.45057971e-09 ; train accuracy 0.998876214\n",
      "Step 3209 : train loss 3.72529e-09 ; train accuracy 0.998876572\n",
      "Step 3210 : train loss 7.45058e-09 ; train accuracy 0.998876929\n",
      "Step 3211 : train loss 0 ; train accuracy 0.998877287\n",
      "Step 3212 : train loss 1.117587e-08 ; train accuracy 0.998877585\n",
      "Step 3213 : train loss 0 ; train accuracy 0.998877943\n",
      "Step 3214 : train loss 0 ; train accuracy 0.9988783\n",
      "Step 3215 : train loss 1.117587e-08 ; train accuracy 0.998878658\n",
      "Step 3216 : train loss 0 ; train accuracy 0.998879\n",
      "Step 3217 : train loss 3.72529e-09 ; train accuracy 0.998879373\n",
      "Step 3218 : train loss 0 ; train accuracy 0.998879731\n",
      "Step 3219 : train loss 0 ; train accuracy 0.998880088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3220 : train loss 0 ; train accuracy 0.998880386\n",
      "Step 3221 : train loss 7.45057971e-09 ; train accuracy 0.998880744\n",
      "Step 3222 : train loss 0 ; train accuracy 0.998881102\n",
      "Step 3223 : train loss 3.72529e-09 ; train accuracy 0.998881459\n",
      "Step 3224 : train loss 3.72529e-09 ; train accuracy 0.998881817\n",
      "Step 3225 : train loss 3.72529e-09 ; train accuracy 0.998882174\n",
      "Step 3226 : train loss 0 ; train accuracy 0.998882473\n",
      "Step 3227 : train loss 7.45058e-09 ; train accuracy 0.99888283\n",
      "Step 3228 : train loss 7.45058e-09 ; train accuracy 0.998883188\n",
      "Step 3229 : train loss 3.72529e-09 ; train accuracy 0.998883545\n",
      "Step 3230 : train loss 1.117587e-08 ; train accuracy 0.998883903\n",
      "Step 3231 : train loss 3.72529e-09 ; train accuracy 0.998884261\n",
      "Step 3232 : train loss 1.86264497e-08 ; train accuracy 0.998884559\n",
      "Step 3233 : train loss 7.45058e-09 ; train accuracy 0.998884916\n",
      "Step 3234 : train loss 1.49011576e-08 ; train accuracy 0.998885274\n",
      "Step 3235 : train loss 1.117587e-08 ; train accuracy 0.998885632\n",
      "Step 3236 : train loss 1.117587e-08 ; train accuracy 0.998886\n",
      "Step 3237 : train loss 1.117587e-08 ; train accuracy 0.998886287\n",
      "Step 3238 : train loss 1.86264462e-08 ; train accuracy 0.998886645\n",
      "Step 3239 : train loss 0 ; train accuracy 0.998887\n",
      "Step 3240 : train loss 3.72529e-09 ; train accuracy 0.99888736\n",
      "Step 3241 : train loss 7.45058e-09 ; train accuracy 0.998887658\n",
      "Step 3242 : train loss 3.72529e-09 ; train accuracy 0.998888\n",
      "Step 3243 : train loss 3.72529e-09 ; train accuracy 0.998888373\n",
      "Step 3244 : train loss 0 ; train accuracy 0.998888731\n",
      "Step 3245 : train loss 7.45058e-09 ; train accuracy 0.998889089\n",
      "Step 3246 : train loss 3.72529e-09 ; train accuracy 0.998889387\n",
      "Step 3247 : train loss 7.45058e-09 ; train accuracy 0.998889744\n",
      "Step 3248 : train loss 0 ; train accuracy 0.998890102\n",
      "Step 3249 : train loss 3.72529e-09 ; train accuracy 0.99889046\n",
      "Step 3250 : train loss 3.72529e-09 ; train accuracy 0.998890758\n",
      "Step 3251 : train loss 1.86264479e-08 ; train accuracy 0.998891115\n",
      "Step 3252 : train loss 0 ; train accuracy 0.998891473\n",
      "Step 3253 : train loss 1.117587e-08 ; train accuracy 0.99889183\n",
      "Step 3254 : train loss 0 ; train accuracy 0.998892128\n",
      "Step 3255 : train loss 3.72529e-09 ; train accuracy 0.998892486\n",
      "Step 3256 : train loss 1.117587e-08 ; train accuracy 0.998892844\n",
      "Step 3257 : train loss 1.49011594e-08 ; train accuracy 0.998893142\n",
      "Step 3258 : train loss 3.72529e-09 ; train accuracy 0.998893499\n",
      "Step 3259 : train loss 0 ; train accuracy 0.998893857\n",
      "Step 3260 : train loss 3.72529e-09 ; train accuracy 0.998894215\n",
      "Step 3261 : train loss 3.72529e-09 ; train accuracy 0.998894513\n",
      "Step 3262 : train loss 1.117587e-08 ; train accuracy 0.99889487\n",
      "Step 3263 : train loss 1.117587e-08 ; train accuracy 0.998895228\n",
      "Step 3264 : train loss 3.72529e-09 ; train accuracy 0.998895526\n",
      "Step 3265 : train loss 7.45058e-09 ; train accuracy 0.998895884\n",
      "Step 3266 : train loss 7.45058e-09 ; train accuracy 0.998896241\n",
      "Step 3267 : train loss 1.86264497e-08 ; train accuracy 0.998896539\n",
      "Step 3268 : train loss 7.45058e-09 ; train accuracy 0.998896897\n",
      "Step 3269 : train loss 3.72529e-09 ; train accuracy 0.998897254\n",
      "Step 3270 : train loss 2.6077025e-08 ; train accuracy 0.998897552\n",
      "Step 3271 : train loss 7.45057971e-09 ; train accuracy 0.99889791\n",
      "Step 3272 : train loss 1.117587e-08 ; train accuracy 0.998898268\n",
      "Step 3273 : train loss 2.60770268e-08 ; train accuracy 0.998898566\n",
      "Step 3274 : train loss 1.49011594e-08 ; train accuracy 0.998898923\n",
      "Step 3275 : train loss 1.49011603e-08 ; train accuracy 0.998899281\n",
      "Step 3276 : train loss 2.235174e-08 ; train accuracy 0.998899579\n",
      "Step 3277 : train loss 7.45058e-09 ; train accuracy 0.998899937\n",
      "Step 3278 : train loss 7.45058e-09 ; train accuracy 0.998900294\n",
      "Step 3279 : train loss 7.45058e-09 ; train accuracy 0.998900592\n",
      "Step 3280 : train loss 1.49011594e-08 ; train accuracy 0.99890095\n",
      "Step 3281 : train loss 1.117587e-08 ; train accuracy 0.998901308\n",
      "Step 3282 : train loss 3.72529e-09 ; train accuracy 0.998901606\n",
      "Step 3283 : train loss 7.45058e-09 ; train accuracy 0.998901963\n",
      "Step 3284 : train loss 3.72529e-09 ; train accuracy 0.998902321\n",
      "Step 3285 : train loss 1.117587e-08 ; train accuracy 0.998902619\n",
      "Step 3286 : train loss 1.49011603e-08 ; train accuracy 0.998903\n",
      "Step 3287 : train loss 0 ; train accuracy 0.998903096\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 3288 : train loss 3.72529e-09 ; train accuracy 0.998903453\n",
      "Step 3289 : train loss 3.72529e-09 ; train accuracy 0.998903751\n",
      "Step 3290 : train loss 1.117587e-08 ; train accuracy 0.998904109\n",
      "Step 3291 : train loss 0 ; train accuracy 0.998904467\n",
      "Step 3292 : train loss 1.117587e-08 ; train accuracy 0.998904765\n",
      "Step 3293 : train loss 0 ; train accuracy 0.998905122\n",
      "Step 3294 : train loss 7.45057971e-09 ; train accuracy 0.99890542\n",
      "Step 3295 : train loss 1.117587e-08 ; train accuracy 0.998905778\n",
      "Step 3296 : train loss 3.72529e-09 ; train accuracy 0.998906136\n",
      "Step 3297 : train loss 1.49011576e-08 ; train accuracy 0.998906434\n",
      "Step 3298 : train loss 0 ; train accuracy 0.998906791\n",
      "Step 3299 : train loss 1.49011594e-08 ; train accuracy 0.998907089\n",
      "Step 3300 : train loss 7.45058e-09 ; train accuracy 0.998907447\n",
      "Step 3301 : train loss 1.11758691e-08 ; train accuracy 0.998907804\n",
      "Step 3302 : train loss 2.60770214e-08 ; train accuracy 0.998908103\n",
      "Step 3303 : train loss 7.45058e-09 ; train accuracy 0.99890846\n",
      "Step 3304 : train loss 7.45058e-09 ; train accuracy 0.998908758\n",
      "Step 3305 : train loss 3.72529e-09 ; train accuracy 0.998909116\n",
      "Step 3306 : train loss 1.49011603e-08 ; train accuracy 0.998909414\n",
      "Step 3307 : train loss 0 ; train accuracy 0.998909771\n",
      "Step 3308 : train loss 1.117587e-08 ; train accuracy 0.998910069\n",
      "Step 3309 : train loss 0 ; train accuracy 0.998910427\n",
      "Step 3310 : train loss 7.45058e-09 ; train accuracy 0.998910785\n",
      "Step 3311 : train loss 3.72529e-09 ; train accuracy 0.998911083\n",
      "Step 3312 : train loss 0 ; train accuracy 0.99891144\n",
      "Step 3313 : train loss 1.49011594e-08 ; train accuracy 0.998911738\n",
      "Step 3314 : train loss 0 ; train accuracy 0.998912096\n",
      "Step 3315 : train loss 1.49011603e-08 ; train accuracy 0.998912394\n",
      "Step 3316 : train loss 7.45058e-09 ; train accuracy 0.998912752\n",
      "Step 3317 : train loss 3.72529e-09 ; train accuracy 0.99891305\n",
      "Step 3318 : train loss 1.49011594e-08 ; train accuracy 0.998913407\n",
      "Step 3319 : train loss 1.117587e-08 ; train accuracy 0.998913705\n",
      "Step 3320 : train loss 1.117587e-08 ; train accuracy 0.998914063\n",
      "Step 3321 : train loss 0 ; train accuracy 0.998914361\n",
      "Step 3322 : train loss 0 ; train accuracy 0.998914719\n",
      "Step 3323 : train loss 7.45058e-09 ; train accuracy 0.998915\n",
      "Step 3324 : train loss 1.49011603e-08 ; train accuracy 0.998915374\n",
      "Step 3325 : train loss 7.45058e-09 ; train accuracy 0.998915672\n",
      "Step 3326 : train loss 7.45058e-09 ; train accuracy 0.99891603\n",
      "Step 3327 : train loss 1.117587e-08 ; train accuracy 0.998916328\n",
      "Step 3328 : train loss 1.49011594e-08 ; train accuracy 0.998916686\n",
      "Step 3329 : train loss 0 ; train accuracy 0.998917\n",
      "Step 3330 : train loss 1.117587e-08 ; train accuracy 0.998917341\n",
      "Step 3331 : train loss 0 ; train accuracy 0.998917639\n",
      "Step 3332 : train loss 3.72529e-09 ; train accuracy 0.998918\n",
      "Step 3333 : train loss 7.45058e-09 ; train accuracy 0.998918295\n",
      "Step 3334 : train loss 0 ; train accuracy 0.998918653\n",
      "Step 3335 : train loss 1.11758691e-08 ; train accuracy 0.998918951\n",
      "Step 3336 : train loss 1.117587e-08 ; train accuracy 0.998919249\n",
      "Step 3337 : train loss 3.72529e-09 ; train accuracy 0.998919606\n",
      "Step 3338 : train loss 0 ; train accuracy 0.998919904\n",
      "Step 3339 : train loss 3.72529e-09 ; train accuracy 0.998920262\n",
      "Step 3340 : train loss 7.45057971e-09 ; train accuracy 0.99892056\n",
      "Step 3341 : train loss 1.49011603e-08 ; train accuracy 0.998920918\n",
      "Step 3342 : train loss 1.117587e-08 ; train accuracy 0.998921216\n",
      "Step 3343 : train loss 0 ; train accuracy 0.998921573\n",
      "Step 3344 : train loss 0 ; train accuracy 0.998921871\n",
      "Step 3345 : train loss 0 ; train accuracy 0.998922169\n",
      "Step 3346 : train loss 1.117587e-08 ; train accuracy 0.998922527\n",
      "Step 3347 : train loss 3.72529e-09 ; train accuracy 0.998922825\n",
      "Step 3348 : train loss 1.11758691e-08 ; train accuracy 0.998923182\n",
      "Step 3349 : train loss 7.45057971e-09 ; train accuracy 0.998923481\n",
      "Step 3350 : train loss 3.72529e-09 ; train accuracy 0.998923779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3351 : train loss 1.86264497e-08 ; train accuracy 0.998924136\n",
      "Step 3352 : train loss 3.72529e-09 ; train accuracy 0.998924434\n",
      "Step 3353 : train loss 0 ; train accuracy 0.998924792\n",
      "Step 3354 : train loss 7.45057971e-09 ; train accuracy 0.99892509\n",
      "Step 3355 : train loss 1.49011603e-08 ; train accuracy 0.998925388\n",
      "Step 3356 : train loss 1.86264479e-08 ; train accuracy 0.998925745\n",
      "Step 3357 : train loss 7.45058e-09 ; train accuracy 0.998926044\n",
      "Step 3358 : train loss 7.45058e-09 ; train accuracy 0.998926401\n",
      "Step 3359 : train loss 7.45058e-09 ; train accuracy 0.998926699\n",
      "Step 3360 : train loss 7.45058e-09 ; train accuracy 0.998927\n",
      "Step 3361 : train loss 0 ; train accuracy 0.998927355\n",
      "Step 3362 : train loss 0 ; train accuracy 0.998927653\n",
      "Step 3363 : train loss 3.72529e-09 ; train accuracy 0.998927951\n",
      "Step 3364 : train loss 3.72529e-09 ; train accuracy 0.998928308\n",
      "Step 3365 : train loss 0 ; train accuracy 0.998928607\n",
      "Step 3366 : train loss 2.60770303e-08 ; train accuracy 0.998928964\n",
      "Step 3367 : train loss 0 ; train accuracy 0.998929262\n",
      "Step 3368 : train loss 3.72529e-09 ; train accuracy 0.99892956\n",
      "Step 3369 : train loss 7.45058e-09 ; train accuracy 0.998929918\n",
      "Step 3370 : train loss 2.23517382e-08 ; train accuracy 0.998930216\n",
      "Step 3371 : train loss 0 ; train accuracy 0.998930514\n",
      "Step 3372 : train loss 0 ; train accuracy 0.998930871\n",
      "Step 3373 : train loss 3.72529e-09 ; train accuracy 0.99893117\n",
      "Step 3374 : train loss 1.117587e-08 ; train accuracy 0.998931468\n",
      "Step 3375 : train loss 3.72529e-09 ; train accuracy 0.998931825\n",
      "Step 3376 : train loss 0 ; train accuracy 0.998932123\n",
      "Step 3377 : train loss 1.117587e-08 ; train accuracy 0.998932421\n",
      "Step 3378 : train loss 3.72529e-09 ; train accuracy 0.998932779\n",
      "Step 3379 : train loss 1.117587e-08 ; train accuracy 0.998933077\n",
      "Step 3380 : train loss 0 ; train accuracy 0.998933375\n",
      "Step 3381 : train loss 3.72529e-09 ; train accuracy 0.998933733\n",
      "Step 3382 : train loss 3.72529e-09 ; train accuracy 0.998934031\n",
      "Step 3383 : train loss 7.45058e-09 ; train accuracy 0.998934329\n",
      "Step 3384 : train loss 3.72529e-09 ; train accuracy 0.998934627\n",
      "Step 3385 : train loss 3.72529e-09 ; train accuracy 0.998935\n",
      "Step 3386 : train loss 0 ; train accuracy 0.998935282\n",
      "Step 3387 : train loss 7.45057971e-09 ; train accuracy 0.99893558\n",
      "Step 3388 : train loss 3.72529e-09 ; train accuracy 0.998935938\n",
      "Step 3389 : train loss 3.72529e-09 ; train accuracy 0.998936236\n",
      "Step 3390 : train loss 1.49011594e-08 ; train accuracy 0.998936534\n",
      "Step 3391 : train loss 0 ; train accuracy 0.998936832\n",
      "Step 3392 : train loss 3.72529e-09 ; train accuracy 0.99893719\n",
      "Step 3393 : train loss 2.60770303e-08 ; train accuracy 0.998937488\n",
      "Step 3394 : train loss 0 ; train accuracy 0.998937786\n",
      "Step 3395 : train loss 3.72529e-09 ; train accuracy 0.998938143\n",
      "Step 3396 : train loss 0 ; train accuracy 0.998938441\n",
      "Step 3397 : train loss 0 ; train accuracy 0.998938739\n",
      "Step 3398 : train loss 0 ; train accuracy 0.998939037\n",
      "Step 3399 : train loss 3.72529e-09 ; train accuracy 0.998939395\n",
      "Step 3400 : train loss 3.72529e-09 ; train accuracy 0.998939693\n",
      "Step 3401 : train loss 3.72529e-09 ; train accuracy 0.99894\n",
      "Step 3402 : train loss 7.45058e-09 ; train accuracy 0.998940289\n",
      "Step 3403 : train loss 7.45058e-09 ; train accuracy 0.998940647\n",
      "Step 3404 : train loss 3.72529e-09 ; train accuracy 0.998940945\n",
      "Step 3405 : train loss 0 ; train accuracy 0.998941243\n",
      "Step 3406 : train loss 3.72529e-09 ; train accuracy 0.998941541\n",
      "Step 3407 : train loss 1.117587e-08 ; train accuracy 0.998941839\n",
      "Step 3408 : train loss 3.72529e-09 ; train accuracy 0.998942196\n",
      "Step 3409 : train loss 3.72529e-09 ; train accuracy 0.998942494\n",
      "Step 3410 : train loss 7.45058e-09 ; train accuracy 0.998942792\n",
      "Step 3411 : train loss 7.45058e-09 ; train accuracy 0.99894309\n",
      "Step 3412 : train loss 1.49011576e-08 ; train accuracy 0.998943448\n",
      "Step 3413 : train loss 0 ; train accuracy 0.998943746\n",
      "Step 3414 : train loss 7.45057971e-09 ; train accuracy 0.998944044\n",
      "Step 3415 : train loss 0 ; train accuracy 0.998944342\n",
      "Step 3416 : train loss 7.45058e-09 ; train accuracy 0.99894464\n",
      "Step 3417 : train loss 2.98023188e-08 ; train accuracy 0.998945\n",
      "Step 3418 : train loss 1.117587e-08 ; train accuracy 0.998945296\n",
      "Step 3419 : train loss 3.72529e-09 ; train accuracy 0.998945594\n",
      "Step 3420 : train loss 7.45058e-09 ; train accuracy 0.998945892\n",
      "Step 3421 : train loss 7.45058e-09 ; train accuracy 0.99894619\n",
      "Step 3422 : train loss 0 ; train accuracy 0.998946548\n",
      "Step 3423 : train loss 7.45058e-09 ; train accuracy 0.998946846\n",
      "Step 3424 : train loss 1.117587e-08 ; train accuracy 0.998947144\n",
      "Step 3425 : train loss 1.117587e-08 ; train accuracy 0.998947442\n",
      "Step 3426 : train loss 7.45058e-09 ; train accuracy 0.99894774\n",
      "Step 3427 : train loss 7.45058e-09 ; train accuracy 0.998948038\n",
      "Step 3428 : train loss 3.72529e-09 ; train accuracy 0.998948395\n",
      "Step 3429 : train loss 3.72529e-09 ; train accuracy 0.998948693\n",
      "Step 3430 : train loss 7.45057971e-09 ; train accuracy 0.998949\n",
      "Step 3431 : train loss 7.45058e-09 ; train accuracy 0.998949289\n",
      "Step 3432 : train loss 3.72529e-09 ; train accuracy 0.998949587\n",
      "Step 3433 : train loss 0 ; train accuracy 0.998949885\n",
      "Step 3434 : train loss 1.117587e-08 ; train accuracy 0.998950183\n",
      "Step 3435 : train loss 0 ; train accuracy 0.998950541\n",
      "Step 3436 : train loss 0 ; train accuracy 0.998950839\n",
      "Step 3437 : train loss 1.117587e-08 ; train accuracy 0.998951137\n",
      "Step 3438 : train loss 1.86264497e-08 ; train accuracy 0.998951435\n",
      "Step 3439 : train loss 7.45058e-09 ; train accuracy 0.998951733\n",
      "Step 3440 : train loss 3.72529e-09 ; train accuracy 0.998952031\n",
      "Step 3441 : train loss 7.45058e-09 ; train accuracy 0.998952329\n",
      "Step 3442 : train loss 7.45058e-09 ; train accuracy 0.998952687\n",
      "Step 3443 : train loss 1.49011594e-08 ; train accuracy 0.998953\n",
      "Step 3444 : train loss 3.35276056e-08 ; train accuracy 0.998953283\n",
      "Step 3445 : train loss 1.86264479e-08 ; train accuracy 0.998953581\n",
      "Step 3446 : train loss 3.72529e-09 ; train accuracy 0.998953879\n",
      "Step 3447 : train loss 7.45058e-09 ; train accuracy 0.998954177\n",
      "Step 3448 : train loss 3.72529e-09 ; train accuracy 0.998954475\n",
      "Step 3449 : train loss 1.117587e-08 ; train accuracy 0.998954773\n",
      "Step 3450 : train loss 2.235174e-08 ; train accuracy 0.998955071\n",
      "Step 3451 : train loss 0 ; train accuracy 0.998955429\n",
      "Step 3452 : train loss 7.45058e-09 ; train accuracy 0.998955727\n",
      "Step 3453 : train loss 1.117587e-08 ; train accuracy 0.998956\n",
      "Step 3454 : train loss 7.45057971e-09 ; train accuracy 0.998956323\n",
      "Step 3455 : train loss 7.45057971e-09 ; train accuracy 0.998956621\n",
      "Step 3456 : train loss 3.72529e-09 ; train accuracy 0.998956919\n",
      "Step 3457 : train loss 1.86264497e-08 ; train accuracy 0.998957217\n",
      "Step 3458 : train loss 7.45058e-09 ; train accuracy 0.998957515\n",
      "Step 3459 : train loss 1.49011594e-08 ; train accuracy 0.998957813\n",
      "Step 3460 : train loss 8.51494875e-09 ; train accuracy 0.998957932\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 3461 : train loss 0 ; train accuracy 0.99895823\n",
      "Step 3462 : train loss 3.72529e-09 ; train accuracy 0.998958588\n",
      "Step 3463 : train loss 1.49011594e-08 ; train accuracy 0.998958886\n",
      "Step 3464 : train loss 0 ; train accuracy 0.998959184\n",
      "Step 3465 : train loss 3.72529e-09 ; train accuracy 0.998959482\n",
      "Step 3466 : train loss 3.72529e-09 ; train accuracy 0.99895978\n",
      "Step 3467 : train loss 2.98023171e-08 ; train accuracy 0.998960078\n",
      "Step 3468 : train loss 7.45057971e-09 ; train accuracy 0.998960376\n",
      "Step 3469 : train loss 2.23517382e-08 ; train accuracy 0.998960674\n",
      "Step 3470 : train loss 0 ; train accuracy 0.998961\n",
      "Step 3471 : train loss 3.72529e-09 ; train accuracy 0.99896127\n",
      "Step 3472 : train loss 3.72529e-09 ; train accuracy 0.998961568\n",
      "Step 3473 : train loss 1.117587e-08 ; train accuracy 0.998961866\n",
      "Step 3474 : train loss 1.49011594e-08 ; train accuracy 0.998962164\n",
      "Step 3475 : train loss 3.72529e-09 ; train accuracy 0.998962462\n",
      "Step 3476 : train loss 3.72529e-09 ; train accuracy 0.99896276\n",
      "Step 3477 : train loss 3.72529e-09 ; train accuracy 0.998963058\n",
      "Step 3478 : train loss 0 ; train accuracy 0.998963356\n",
      "Step 3479 : train loss 3.72529e-09 ; train accuracy 0.998963654\n",
      "Step 3480 : train loss 1.117587e-08 ; train accuracy 0.998963952\n",
      "Step 3481 : train loss 7.45058e-09 ; train accuracy 0.99896425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3482 : train loss 3.72529e-09 ; train accuracy 0.998964548\n",
      "Step 3483 : train loss 7.45058e-09 ; train accuracy 0.998964846\n",
      "Step 3484 : train loss 3.72529e-09 ; train accuracy 0.998965144\n",
      "Step 3485 : train loss 0 ; train accuracy 0.998965442\n",
      "Step 3486 : train loss 3.72529e-09 ; train accuracy 0.99896574\n",
      "Step 3487 : train loss 0 ; train accuracy 0.998966038\n",
      "Step 3488 : train loss 0 ; train accuracy 0.998966336\n",
      "Step 3489 : train loss 0 ; train accuracy 0.998966634\n",
      "Step 3490 : train loss 1.49011594e-08 ; train accuracy 0.998966932\n",
      "Step 3491 : train loss 3.72529e-09 ; train accuracy 0.99896723\n",
      "Step 3492 : train loss 3.72529e-09 ; train accuracy 0.998967528\n",
      "Step 3493 : train loss 7.45058e-09 ; train accuracy 0.998967826\n",
      "Step 3494 : train loss 3.72529e-09 ; train accuracy 0.998968124\n",
      "Step 3495 : train loss 0 ; train accuracy 0.998968422\n",
      "Step 3496 : train loss 1.11758691e-08 ; train accuracy 0.99896872\n",
      "Step 3497 : train loss 0 ; train accuracy 0.998969\n",
      "Step 3498 : train loss 7.45058e-09 ; train accuracy 0.998969316\n",
      "Step 3499 : train loss 2.60770303e-08 ; train accuracy 0.998969615\n",
      "Step 3500 : train loss 0 ; train accuracy 0.998969913\n",
      "Step 3501 : train loss 7.45058e-09 ; train accuracy 0.998970211\n",
      "Step 3502 : train loss 3.72529e-09 ; train accuracy 0.998970509\n",
      "Step 3503 : train loss 1.117587e-08 ; train accuracy 0.998970807\n",
      "Step 3504 : train loss 7.45058e-09 ; train accuracy 0.998971105\n",
      "Step 3505 : train loss 0 ; train accuracy 0.998971403\n",
      "Step 3506 : train loss 3.72529e-09 ; train accuracy 0.998971701\n",
      "Step 3507 : train loss 1.117587e-08 ; train accuracy 0.998971939\n",
      "Step 3508 : train loss 3.72529e-09 ; train accuracy 0.998972237\n",
      "Step 3509 : train loss 1.117587e-08 ; train accuracy 0.998972535\n",
      "Step 3510 : train loss 3.72529e-09 ; train accuracy 0.998972833\n",
      "Step 3511 : train loss 1.86264462e-08 ; train accuracy 0.998973131\n",
      "Step 3512 : train loss 3.72529e-09 ; train accuracy 0.998973429\n",
      "Step 3513 : train loss 3.72529e-09 ; train accuracy 0.998973727\n",
      "Step 3514 : train loss 1.86264497e-08 ; train accuracy 0.998974\n",
      "Step 3515 : train loss 7.45058e-09 ; train accuracy 0.998974323\n",
      "Step 3516 : train loss 0 ; train accuracy 0.998974621\n",
      "Step 3517 : train loss 1.117587e-08 ; train accuracy 0.998974919\n",
      "Step 3518 : train loss 3.72529e-09 ; train accuracy 0.998975217\n",
      "Step 3519 : train loss 3.72529e-09 ; train accuracy 0.998975456\n",
      "Step 3520 : train loss 1.117587e-08 ; train accuracy 0.998975754\n",
      "Step 3521 : train loss 7.45058e-09 ; train accuracy 0.998976052\n",
      "Step 3522 : train loss 3.72529e-09 ; train accuracy 0.99897635\n",
      "Step 3523 : train loss 3.72529e-09 ; train accuracy 0.998976648\n",
      "Step 3524 : train loss 3.72529e-09 ; train accuracy 0.998976946\n",
      "Step 3525 : train loss 1.117587e-08 ; train accuracy 0.998977244\n",
      "Step 3526 : train loss 1.86264497e-08 ; train accuracy 0.998977542\n",
      "Step 3527 : train loss 1.11758691e-08 ; train accuracy 0.99897784\n",
      "Step 3528 : train loss 1.86264497e-08 ; train accuracy 0.998978078\n",
      "Step 3529 : train loss 1.117587e-08 ; train accuracy 0.998978376\n",
      "Step 3530 : train loss 3.72529e-09 ; train accuracy 0.998978674\n",
      "Step 3531 : train loss 3.72529e-09 ; train accuracy 0.998979\n",
      "Step 3532 : train loss 3.72529e-09 ; train accuracy 0.99897927\n",
      "Step 3533 : train loss 1.117587e-08 ; train accuracy 0.998979568\n",
      "Step 3534 : train loss 3.72529e-09 ; train accuracy 0.998979867\n",
      "Step 3535 : train loss 1.117587e-08 ; train accuracy 0.998980165\n",
      "Step 3536 : train loss 3.72529e-09 ; train accuracy 0.998980403\n",
      "Step 3537 : train loss 3.72529e-09 ; train accuracy 0.998980701\n",
      "Step 3538 : train loss 0 ; train accuracy 0.998981\n",
      "Step 3539 : train loss 0 ; train accuracy 0.998981297\n",
      "Step 3540 : train loss 3.72529e-09 ; train accuracy 0.998981595\n",
      "Step 3541 : train loss 7.45058e-09 ; train accuracy 0.998981893\n",
      "Step 3542 : train loss 7.45058e-09 ; train accuracy 0.998982131\n",
      "Step 3543 : train loss 3.72529e-09 ; train accuracy 0.99898243\n",
      "Step 3544 : train loss 1.11758691e-08 ; train accuracy 0.998982728\n",
      "Step 3545 : train loss 3.72529e-09 ; train accuracy 0.998983\n",
      "Step 3546 : train loss 3.72529e-09 ; train accuracy 0.998983324\n",
      "Step 3547 : train loss 7.45058e-09 ; train accuracy 0.998983622\n",
      "Step 3548 : train loss 7.45057971e-09 ; train accuracy 0.99898386\n",
      "Step 3549 : train loss 3.72529e-09 ; train accuracy 0.998984158\n",
      "Step 3550 : train loss 7.45058e-09 ; train accuracy 0.998984456\n",
      "Step 3551 : train loss 0 ; train accuracy 0.998984754\n",
      "Step 3552 : train loss 1.117587e-08 ; train accuracy 0.998985052\n",
      "Step 3553 : train loss 1.117587e-08 ; train accuracy 0.998985291\n",
      "Step 3554 : train loss 1.117587e-08 ; train accuracy 0.998985589\n",
      "Step 3555 : train loss 7.45058e-09 ; train accuracy 0.998985887\n",
      "Step 3556 : train loss 0 ; train accuracy 0.998986185\n",
      "Step 3557 : train loss 7.45058e-09 ; train accuracy 0.998986483\n",
      "Step 3558 : train loss 0 ; train accuracy 0.998986721\n",
      "Step 3559 : train loss 3.72529e-09 ; train accuracy 0.998987\n",
      "Step 3560 : train loss 0 ; train accuracy 0.998987317\n",
      "Step 3561 : train loss 7.45057971e-09 ; train accuracy 0.998987615\n",
      "Step 3562 : train loss 0 ; train accuracy 0.998987913\n",
      "Step 3563 : train loss 3.72529e-09 ; train accuracy 0.998988152\n",
      "Step 3564 : train loss 3.72529e-09 ; train accuracy 0.99898845\n",
      "Step 3565 : train loss 3.72529e-09 ; train accuracy 0.998988748\n",
      "Step 3566 : train loss 7.45058e-09 ; train accuracy 0.998989046\n",
      "Step 3567 : train loss 3.72529e-09 ; train accuracy 0.998989284\n",
      "Step 3568 : train loss 0 ; train accuracy 0.998989582\n",
      "Step 3569 : train loss 1.117587e-08 ; train accuracy 0.99898988\n",
      "Step 3570 : train loss 7.45058e-09 ; train accuracy 0.998990178\n",
      "Step 3571 : train loss 0 ; train accuracy 0.998990476\n",
      "Step 3572 : train loss 7.45057971e-09 ; train accuracy 0.998990715\n",
      "Step 3573 : train loss 1.49011594e-08 ; train accuracy 0.998991\n",
      "Step 3574 : train loss 1.117587e-08 ; train accuracy 0.998991311\n",
      "Step 3575 : train loss 7.45058e-09 ; train accuracy 0.998991609\n",
      "Step 3576 : train loss 0 ; train accuracy 0.998991847\n",
      "Step 3577 : train loss 1.117587e-08 ; train accuracy 0.998992145\n",
      "Step 3578 : train loss 3.72529e-09 ; train accuracy 0.998992443\n",
      "Step 3579 : train loss 7.45058e-09 ; train accuracy 0.998992741\n",
      "Step 3580 : train loss 7.45058e-09 ; train accuracy 0.998993\n",
      "Step 3581 : train loss 0 ; train accuracy 0.998993278\n",
      "Step 3582 : train loss 3.72529e-09 ; train accuracy 0.998993576\n",
      "Step 3583 : train loss 3.72529e-09 ; train accuracy 0.998993814\n",
      "Step 3584 : train loss 7.45058e-09 ; train accuracy 0.998994112\n",
      "Step 3585 : train loss 1.117587e-08 ; train accuracy 0.99899441\n",
      "Step 3586 : train loss 7.45057971e-09 ; train accuracy 0.998994708\n",
      "Step 3587 : train loss 1.49011603e-08 ; train accuracy 0.998994946\n",
      "Step 3588 : train loss 0 ; train accuracy 0.998995245\n",
      "Step 3589 : train loss 0 ; train accuracy 0.998995543\n",
      "Step 3590 : train loss 7.45058e-09 ; train accuracy 0.998995781\n",
      "Step 3591 : train loss 0 ; train accuracy 0.998996079\n",
      "Step 3592 : train loss 3.72529e-09 ; train accuracy 0.998996377\n",
      "Step 3593 : train loss 0 ; train accuracy 0.998996675\n",
      "Step 3594 : train loss 3.72529e-09 ; train accuracy 0.998996913\n",
      "Step 3595 : train loss 0 ; train accuracy 0.998997211\n",
      "Step 3596 : train loss 7.45058e-09 ; train accuracy 0.998997509\n",
      "Step 3597 : train loss 3.72529e-09 ; train accuracy 0.998997748\n",
      "Step 3598 : train loss 1.117587e-08 ; train accuracy 0.998998046\n",
      "Step 3599 : train loss 7.45058e-09 ; train accuracy 0.998998344\n",
      "Step 3600 : train loss 3.72529e-09 ; train accuracy 0.998998582\n",
      "Step 3601 : train loss 1.49011603e-08 ; train accuracy 0.99899888\n",
      "Step 3602 : train loss 0 ; train accuracy 0.998999178\n",
      "Step 3603 : train loss 0 ; train accuracy 0.998999417\n",
      "Step 3604 : train loss 3.72529e-09 ; train accuracy 0.998999715\n",
      "Step 3605 : train loss 0 ; train accuracy 0.999\n",
      "Step 3606 : train loss 2.23517382e-08 ; train accuracy 0.999000251\n",
      "Step 3607 : train loss 7.45058e-09 ; train accuracy 0.999000549\n",
      "Step 3608 : train loss 0 ; train accuracy 0.999000847\n",
      "Step 3609 : train loss 1.49011594e-08 ; train accuracy 0.999001086\n",
      "Step 3610 : train loss 3.35276056e-08 ; train accuracy 0.999001384\n",
      "Step 3611 : train loss 1.86264497e-08 ; train accuracy 0.999001682\n",
      "Step 3612 : train loss 7.45058e-09 ; train accuracy 0.99900192\n",
      "Step 3613 : train loss 3.72529e-09 ; train accuracy 0.999002218\n",
      "Step 3614 : train loss 3.72529e-09 ; train accuracy 0.999002516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3615 : train loss 2.60770303e-08 ; train accuracy 0.999002755\n",
      "Step 3616 : train loss 3.72529e-09 ; train accuracy 0.999003053\n",
      "Step 3617 : train loss 1.117587e-08 ; train accuracy 0.999003351\n",
      "Step 3618 : train loss 2.98023188e-08 ; train accuracy 0.999003589\n",
      "Step 3619 : train loss 1.49011603e-08 ; train accuracy 0.999003887\n",
      "Step 3620 : train loss 2.235174e-08 ; train accuracy 0.999004185\n",
      "Step 3621 : train loss 3.72529e-09 ; train accuracy 0.999004424\n",
      "Step 3622 : train loss 3.72529e-09 ; train accuracy 0.999004722\n",
      "Step 3623 : train loss 1.49011603e-08 ; train accuracy 0.99900496\n",
      "Step 3624 : train loss 3.72529e-09 ; train accuracy 0.999005258\n",
      "Step 3625 : train loss 3.72529e-09 ; train accuracy 0.999005556\n",
      "Step 3626 : train loss 7.45058e-09 ; train accuracy 0.999005795\n",
      "Step 3627 : train loss 0 ; train accuracy 0.999006093\n",
      "Step 3628 : train loss 1.117587e-08 ; train accuracy 0.999006331\n",
      "Step 3629 : train loss 3.72529e-09 ; train accuracy 0.999006629\n",
      "Step 3630 : train loss 1.49011603e-08 ; train accuracy 0.999006927\n",
      "Step 3631 : train loss 7.45058e-09 ; train accuracy 0.999007165\n",
      "Step 3632 : train loss 7.45058e-09 ; train accuracy 0.999007463\n",
      "Step 3633 : train loss 1.70298957e-08 ; train accuracy 0.999007583\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 3634 : train loss 1.11758691e-08 ; train accuracy 0.999007881\n",
      "Step 3635 : train loss 7.45058e-09 ; train accuracy 0.999008119\n",
      "Step 3636 : train loss 3.72529e-09 ; train accuracy 0.999008417\n",
      "Step 3637 : train loss 3.72529e-09 ; train accuracy 0.999008656\n",
      "Step 3638 : train loss 7.45058e-09 ; train accuracy 0.999008954\n",
      "Step 3639 : train loss 0 ; train accuracy 0.999009192\n",
      "Step 3640 : train loss 7.45058e-09 ; train accuracy 0.99900949\n",
      "Step 3641 : train loss 3.72529e-09 ; train accuracy 0.999009788\n",
      "Step 3642 : train loss 7.45058e-09 ; train accuracy 0.99901\n",
      "Step 3643 : train loss 1.117587e-08 ; train accuracy 0.999010324\n",
      "Step 3644 : train loss 3.72529e-09 ; train accuracy 0.999010563\n",
      "Step 3645 : train loss 0 ; train accuracy 0.999010861\n",
      "Step 3646 : train loss 1.86264497e-08 ; train accuracy 0.999011099\n",
      "Step 3647 : train loss 3.72529e-09 ; train accuracy 0.999011397\n",
      "Step 3648 : train loss 3.72529e-09 ; train accuracy 0.999011695\n",
      "Step 3649 : train loss 0 ; train accuracy 0.999011934\n",
      "Step 3650 : train loss 3.72529e-09 ; train accuracy 0.999012232\n",
      "Step 3651 : train loss 0 ; train accuracy 0.99901247\n",
      "Step 3652 : train loss 2.6077025e-08 ; train accuracy 0.999012768\n",
      "Step 3653 : train loss 0 ; train accuracy 0.999013\n",
      "Step 3654 : train loss 3.72529e-09 ; train accuracy 0.999013305\n",
      "Step 3655 : train loss 0 ; train accuracy 0.999013543\n",
      "Step 3656 : train loss 3.72529e-09 ; train accuracy 0.999013841\n",
      "Step 3657 : train loss 0 ; train accuracy 0.999014139\n",
      "Step 3658 : train loss 2.60770285e-08 ; train accuracy 0.999014378\n",
      "Step 3659 : train loss 3.72529e-09 ; train accuracy 0.999014676\n",
      "Step 3660 : train loss 3.72529e-09 ; train accuracy 0.999014914\n",
      "Step 3661 : train loss 1.86264462e-08 ; train accuracy 0.999015212\n",
      "Step 3662 : train loss 3.72529e-09 ; train accuracy 0.99901545\n",
      "Step 3663 : train loss 0 ; train accuracy 0.999015749\n",
      "Step 3664 : train loss 0 ; train accuracy 0.999016\n",
      "Step 3665 : train loss 1.49011603e-08 ; train accuracy 0.999016285\n",
      "Step 3666 : train loss 7.45058e-09 ; train accuracy 0.999016523\n",
      "Step 3667 : train loss 3.72529e-09 ; train accuracy 0.999016821\n",
      "Step 3668 : train loss 7.45058e-09 ; train accuracy 0.99901706\n",
      "Step 3669 : train loss 3.72529e-09 ; train accuracy 0.999017358\n",
      "Step 3670 : train loss 0 ; train accuracy 0.999017596\n",
      "Step 3671 : train loss 2.60770303e-08 ; train accuracy 0.999017894\n",
      "Step 3672 : train loss 1.117587e-08 ; train accuracy 0.999018133\n",
      "Step 3673 : train loss 7.45058e-09 ; train accuracy 0.999018431\n",
      "Step 3674 : train loss 7.45057971e-09 ; train accuracy 0.999018669\n",
      "Step 3675 : train loss 1.117587e-08 ; train accuracy 0.999018967\n",
      "Step 3676 : train loss 0 ; train accuracy 0.999019206\n",
      "Step 3677 : train loss 3.72529e-09 ; train accuracy 0.999019504\n",
      "Step 3678 : train loss 1.49011603e-08 ; train accuracy 0.999019742\n",
      "Step 3679 : train loss 1.49011603e-08 ; train accuracy 0.99902004\n",
      "Step 3680 : train loss 3.72529e-09 ; train accuracy 0.999020278\n",
      "Step 3681 : train loss 7.45058e-09 ; train accuracy 0.999020576\n",
      "Step 3682 : train loss 7.45058e-09 ; train accuracy 0.999020815\n",
      "Step 3683 : train loss 0 ; train accuracy 0.999021113\n",
      "Step 3684 : train loss 1.49011594e-08 ; train accuracy 0.999021351\n",
      "Step 3685 : train loss 0 ; train accuracy 0.999021649\n",
      "Step 3686 : train loss 0 ; train accuracy 0.999021888\n",
      "Step 3687 : train loss 7.45058e-09 ; train accuracy 0.999022186\n",
      "Step 3688 : train loss 0 ; train accuracy 0.999022424\n",
      "Step 3689 : train loss 0 ; train accuracy 0.999022663\n",
      "Step 3690 : train loss 2.235174e-08 ; train accuracy 0.999022961\n",
      "Step 3691 : train loss 3.72529e-09 ; train accuracy 0.999023199\n",
      "Step 3692 : train loss 7.45058e-09 ; train accuracy 0.999023497\n",
      "Step 3693 : train loss 3.72529e-09 ; train accuracy 0.999023736\n",
      "Step 3694 : train loss 1.117587e-08 ; train accuracy 0.999024034\n",
      "Step 3695 : train loss 3.72529e-09 ; train accuracy 0.999024272\n",
      "Step 3696 : train loss 1.49011594e-08 ; train accuracy 0.99902457\n",
      "Step 3697 : train loss 1.117587e-08 ; train accuracy 0.999024808\n",
      "Step 3698 : train loss 1.86264497e-08 ; train accuracy 0.999025106\n",
      "Step 3699 : train loss 1.117587e-08 ; train accuracy 0.999025345\n",
      "Step 3700 : train loss 3.72529e-09 ; train accuracy 0.999025583\n",
      "Step 3701 : train loss 1.49011594e-08 ; train accuracy 0.999025881\n",
      "Step 3702 : train loss 0 ; train accuracy 0.99902612\n",
      "Step 3703 : train loss 3.72529e-09 ; train accuracy 0.999026418\n",
      "Step 3704 : train loss 3.72529e-09 ; train accuracy 0.999026656\n",
      "Step 3705 : train loss 7.45058e-09 ; train accuracy 0.999026954\n",
      "Step 3706 : train loss 0 ; train accuracy 0.999027193\n",
      "Step 3707 : train loss 0 ; train accuracy 0.999027431\n",
      "Step 3708 : train loss 3.72529e-09 ; train accuracy 0.999027729\n",
      "Step 3709 : train loss 0 ; train accuracy 0.999027967\n",
      "Step 3710 : train loss 0 ; train accuracy 0.999028265\n",
      "Step 3711 : train loss 1.49011576e-08 ; train accuracy 0.999028504\n",
      "Step 3712 : train loss 1.117587e-08 ; train accuracy 0.999028742\n",
      "Step 3713 : train loss 3.72529e-09 ; train accuracy 0.99902904\n",
      "Step 3714 : train loss 7.45057971e-09 ; train accuracy 0.999029279\n",
      "Step 3715 : train loss 3.72529e-09 ; train accuracy 0.999029577\n",
      "Step 3716 : train loss 0 ; train accuracy 0.999029815\n",
      "Step 3717 : train loss 3.72529e-09 ; train accuracy 0.999030054\n",
      "Step 3718 : train loss 3.72529e-09 ; train accuracy 0.999030352\n",
      "Step 3719 : train loss 7.45058e-09 ; train accuracy 0.99903059\n",
      "Step 3720 : train loss 3.72529e-09 ; train accuracy 0.999030888\n",
      "Step 3721 : train loss 3.72529e-09 ; train accuracy 0.999031126\n",
      "Step 3722 : train loss 7.45058e-09 ; train accuracy 0.999031365\n",
      "Step 3723 : train loss 7.45058e-09 ; train accuracy 0.999031663\n",
      "Step 3724 : train loss 7.45058e-09 ; train accuracy 0.999031901\n",
      "Step 3725 : train loss 3.72529e-09 ; train accuracy 0.99903214\n",
      "Step 3726 : train loss 3.72529e-09 ; train accuracy 0.999032438\n",
      "Step 3727 : train loss 1.117587e-08 ; train accuracy 0.999032676\n",
      "Step 3728 : train loss 7.45058e-09 ; train accuracy 0.999033\n",
      "Step 3729 : train loss 7.45057971e-09 ; train accuracy 0.999033213\n",
      "Step 3730 : train loss 0 ; train accuracy 0.999033451\n",
      "Step 3731 : train loss 3.72529e-09 ; train accuracy 0.999033749\n",
      "Step 3732 : train loss 1.117587e-08 ; train accuracy 0.999034\n",
      "Step 3733 : train loss 0 ; train accuracy 0.999034226\n",
      "Step 3734 : train loss 0 ; train accuracy 0.999034524\n",
      "Step 3735 : train loss 0 ; train accuracy 0.999034762\n",
      "Step 3736 : train loss 7.45058e-09 ; train accuracy 0.999035\n",
      "Step 3737 : train loss 3.72529e-09 ; train accuracy 0.999035299\n",
      "Step 3738 : train loss 0 ; train accuracy 0.999035537\n",
      "Step 3739 : train loss 0 ; train accuracy 0.999035776\n",
      "Step 3740 : train loss 3.72529e-09 ; train accuracy 0.999036074\n",
      "Step 3741 : train loss 3.72529e-09 ; train accuracy 0.999036312\n",
      "Step 3742 : train loss 7.45058e-09 ; train accuracy 0.999036551\n",
      "Step 3743 : train loss 0 ; train accuracy 0.999036849\n",
      "Step 3744 : train loss 0 ; train accuracy 0.999037087\n",
      "Step 3745 : train loss 3.72529e-09 ; train accuracy 0.999037325\n",
      "Step 3746 : train loss 0 ; train accuracy 0.999037623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3747 : train loss 1.117587e-08 ; train accuracy 0.999037862\n",
      "Step 3748 : train loss 7.45058e-09 ; train accuracy 0.9990381\n",
      "Step 3749 : train loss 3.72529e-09 ; train accuracy 0.999038398\n",
      "Step 3750 : train loss 0 ; train accuracy 0.999038637\n",
      "Step 3751 : train loss 1.117587e-08 ; train accuracy 0.999038875\n",
      "Step 3752 : train loss 0 ; train accuracy 0.999039173\n",
      "Step 3753 : train loss 7.45058e-09 ; train accuracy 0.999039412\n",
      "Step 3754 : train loss 7.45058e-09 ; train accuracy 0.99903965\n",
      "Step 3755 : train loss 3.72529e-09 ; train accuracy 0.999039948\n",
      "Step 3756 : train loss 3.72529e-09 ; train accuracy 0.999040186\n",
      "Step 3757 : train loss 1.117587e-08 ; train accuracy 0.999040425\n",
      "Step 3758 : train loss 3.72529e-09 ; train accuracy 0.999040663\n",
      "Step 3759 : train loss 2.235174e-08 ; train accuracy 0.999040961\n",
      "Step 3760 : train loss 0 ; train accuracy 0.9990412\n",
      "Step 3761 : train loss 3.72529e-09 ; train accuracy 0.999041438\n",
      "Step 3762 : train loss 0 ; train accuracy 0.999041736\n",
      "Step 3763 : train loss 7.45058e-09 ; train accuracy 0.999042\n",
      "Step 3764 : train loss 0 ; train accuracy 0.999042213\n",
      "Step 3765 : train loss 0 ; train accuracy 0.999042451\n",
      "Step 3766 : train loss 3.72529e-09 ; train accuracy 0.999042749\n",
      "Step 3767 : train loss 0 ; train accuracy 0.999043\n",
      "Step 3768 : train loss 3.72529e-09 ; train accuracy 0.999043226\n",
      "Step 3769 : train loss 2.23517382e-08 ; train accuracy 0.999043524\n",
      "Step 3770 : train loss 1.86264479e-08 ; train accuracy 0.999043763\n",
      "Step 3771 : train loss 0 ; train accuracy 0.999044\n",
      "Step 3772 : train loss 3.72529e-09 ; train accuracy 0.99904424\n",
      "Step 3773 : train loss 7.45058e-09 ; train accuracy 0.999044538\n",
      "Step 3774 : train loss 7.45058e-09 ; train accuracy 0.999044776\n",
      "Step 3775 : train loss 1.49011576e-08 ; train accuracy 0.999045\n",
      "Step 3776 : train loss 7.45058e-09 ; train accuracy 0.999045253\n",
      "Step 3777 : train loss 7.45057971e-09 ; train accuracy 0.999045551\n",
      "Step 3778 : train loss 0 ; train accuracy 0.999045789\n",
      "Step 3779 : train loss 1.117587e-08 ; train accuracy 0.999046\n",
      "Step 3780 : train loss 7.45057971e-09 ; train accuracy 0.999046266\n",
      "Step 3781 : train loss 3.72529e-09 ; train accuracy 0.999046564\n",
      "Step 3782 : train loss 1.49011603e-08 ; train accuracy 0.999046803\n",
      "Step 3783 : train loss 3.72529e-09 ; train accuracy 0.999047041\n",
      "Step 3784 : train loss 1.86264497e-08 ; train accuracy 0.999047279\n",
      "Step 3785 : train loss 0 ; train accuracy 0.999047577\n",
      "Step 3786 : train loss 7.45058e-09 ; train accuracy 0.999047816\n",
      "Step 3787 : train loss 1.49011603e-08 ; train accuracy 0.999048054\n",
      "Step 3788 : train loss 1.49011603e-08 ; train accuracy 0.999048293\n",
      "Step 3789 : train loss 1.117587e-08 ; train accuracy 0.999048591\n",
      "Step 3790 : train loss 7.45058e-09 ; train accuracy 0.999048829\n",
      "Step 3791 : train loss 1.49011603e-08 ; train accuracy 0.999049067\n",
      "Step 3792 : train loss 3.72529e-09 ; train accuracy 0.999049306\n",
      "Step 3793 : train loss 1.117587e-08 ; train accuracy 0.999049544\n",
      "Step 3794 : train loss 1.117587e-08 ; train accuracy 0.999049842\n",
      "Step 3795 : train loss 7.45058e-09 ; train accuracy 0.999050081\n",
      "Step 3796 : train loss 2.98023171e-08 ; train accuracy 0.999050319\n",
      "Step 3797 : train loss 3.72529e-09 ; train accuracy 0.999050558\n",
      "Step 3798 : train loss 1.117587e-08 ; train accuracy 0.999050856\n",
      "Step 3799 : train loss 1.117587e-08 ; train accuracy 0.999051094\n",
      "Step 3800 : train loss 3.72529e-09 ; train accuracy 0.999051332\n",
      "Step 3801 : train loss 7.45057971e-09 ; train accuracy 0.999051571\n",
      "Step 3802 : train loss 1.49011603e-08 ; train accuracy 0.999051809\n",
      "Step 3803 : train loss 3.72529e-09 ; train accuracy 0.999052107\n",
      "Step 3804 : train loss 3.72529e-09 ; train accuracy 0.999052346\n",
      "Step 3805 : train loss 1.117587e-08 ; train accuracy 0.999052584\n",
      "Step 3806 : train loss 8.51494875e-09 ; train accuracy 0.999052703\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 3807 : train loss 0 ; train accuracy 0.999052942\n",
      "Step 3808 : train loss 0 ; train accuracy 0.99905318\n",
      "Step 3809 : train loss 3.72529e-09 ; train accuracy 0.999053419\n",
      "Step 3810 : train loss 2.235174e-08 ; train accuracy 0.999053657\n",
      "Step 3811 : train loss 3.72529e-09 ; train accuracy 0.999053955\n",
      "Step 3812 : train loss 7.45058e-09 ; train accuracy 0.999054193\n",
      "Step 3813 : train loss 3.72529e-09 ; train accuracy 0.999054432\n",
      "Step 3814 : train loss 2.60770268e-08 ; train accuracy 0.99905467\n",
      "Step 3815 : train loss 7.45058e-09 ; train accuracy 0.999054909\n",
      "Step 3816 : train loss 0 ; train accuracy 0.999055207\n",
      "Step 3817 : train loss 1.11758691e-08 ; train accuracy 0.999055445\n",
      "Step 3818 : train loss 1.117587e-08 ; train accuracy 0.999055684\n",
      "Step 3819 : train loss 3.72529e-09 ; train accuracy 0.999055922\n",
      "Step 3820 : train loss 1.117587e-08 ; train accuracy 0.99905616\n",
      "Step 3821 : train loss 3.72529e-09 ; train accuracy 0.999056399\n",
      "Step 3822 : train loss 1.117587e-08 ; train accuracy 0.999056637\n",
      "Step 3823 : train loss 3.72529e-09 ; train accuracy 0.999056935\n",
      "Step 3824 : train loss 0 ; train accuracy 0.999057174\n",
      "Step 3825 : train loss 7.45057971e-09 ; train accuracy 0.999057412\n",
      "Step 3826 : train loss 3.72529e-09 ; train accuracy 0.999057651\n",
      "Step 3827 : train loss 0 ; train accuracy 0.999057889\n",
      "Step 3828 : train loss 3.72529e-09 ; train accuracy 0.999058127\n",
      "Step 3829 : train loss 1.117587e-08 ; train accuracy 0.999058425\n",
      "Step 3830 : train loss 3.72529e-09 ; train accuracy 0.999058664\n",
      "Step 3831 : train loss 7.45058e-09 ; train accuracy 0.999058902\n",
      "Step 3832 : train loss 7.45057971e-09 ; train accuracy 0.999059141\n",
      "Step 3833 : train loss 3.72529e-09 ; train accuracy 0.999059379\n",
      "Step 3834 : train loss 1.49011603e-08 ; train accuracy 0.999059618\n",
      "Step 3835 : train loss 3.72529e-09 ; train accuracy 0.999059856\n",
      "Step 3836 : train loss 0 ; train accuracy 0.999060094\n",
      "Step 3837 : train loss 3.72529e-09 ; train accuracy 0.999060392\n",
      "Step 3838 : train loss 7.45057971e-09 ; train accuracy 0.999060631\n",
      "Step 3839 : train loss 7.45058e-09 ; train accuracy 0.999060869\n",
      "Step 3840 : train loss 3.72529e-09 ; train accuracy 0.999061108\n",
      "Step 3841 : train loss 3.72529e-09 ; train accuracy 0.999061346\n",
      "Step 3842 : train loss 7.45058e-09 ; train accuracy 0.999061584\n",
      "Step 3843 : train loss 2.23517382e-08 ; train accuracy 0.999061823\n",
      "Step 3844 : train loss 3.72529e-09 ; train accuracy 0.999062061\n",
      "Step 3845 : train loss 1.49011594e-08 ; train accuracy 0.9990623\n",
      "Step 3846 : train loss 1.117587e-08 ; train accuracy 0.999062598\n",
      "Step 3847 : train loss 3.72529e-09 ; train accuracy 0.999062836\n",
      "Step 3848 : train loss 3.72529e-09 ; train accuracy 0.999063075\n",
      "Step 3849 : train loss 3.72529e-09 ; train accuracy 0.999063313\n",
      "Step 3850 : train loss 0 ; train accuracy 0.999063551\n",
      "Step 3851 : train loss 3.72529e-09 ; train accuracy 0.99906379\n",
      "Step 3852 : train loss 7.45058e-09 ; train accuracy 0.999064\n",
      "Step 3853 : train loss 0 ; train accuracy 0.999064267\n",
      "Step 3854 : train loss 3.72529e-09 ; train accuracy 0.999064505\n",
      "Step 3855 : train loss 0 ; train accuracy 0.999064744\n",
      "Step 3856 : train loss 0 ; train accuracy 0.999065\n",
      "Step 3857 : train loss 0 ; train accuracy 0.99906528\n",
      "Step 3858 : train loss 3.72529e-09 ; train accuracy 0.999065518\n",
      "Step 3859 : train loss 2.235174e-08 ; train accuracy 0.999065757\n",
      "Step 3860 : train loss 1.49011594e-08 ; train accuracy 0.999066\n",
      "Step 3861 : train loss 1.86264497e-08 ; train accuracy 0.999066234\n",
      "Step 3862 : train loss 0 ; train accuracy 0.999066472\n",
      "Step 3863 : train loss 2.23517382e-08 ; train accuracy 0.99906671\n",
      "Step 3864 : train loss 7.45058e-09 ; train accuracy 0.999066949\n",
      "Step 3865 : train loss 0 ; train accuracy 0.999067187\n",
      "Step 3866 : train loss 7.45058e-09 ; train accuracy 0.999067426\n",
      "Step 3867 : train loss 1.11758691e-08 ; train accuracy 0.999067664\n",
      "Step 3868 : train loss 3.72529e-09 ; train accuracy 0.999067903\n",
      "Step 3869 : train loss 0 ; train accuracy 0.999068141\n",
      "Step 3870 : train loss 3.72529e-09 ; train accuracy 0.999068379\n",
      "Step 3871 : train loss 0 ; train accuracy 0.999068618\n",
      "Step 3872 : train loss 1.49011603e-08 ; train accuracy 0.999068916\n",
      "Step 3873 : train loss 7.45058e-09 ; train accuracy 0.999069154\n",
      "Step 3874 : train loss 3.72529e-09 ; train accuracy 0.999069393\n",
      "Step 3875 : train loss 0 ; train accuracy 0.999069631\n",
      "Step 3876 : train loss 1.117587e-08 ; train accuracy 0.99906987\n",
      "Step 3877 : train loss 3.72529e-09 ; train accuracy 0.999070108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3878 : train loss 0 ; train accuracy 0.999070346\n",
      "Step 3879 : train loss 1.117587e-08 ; train accuracy 0.999070585\n",
      "Step 3880 : train loss 7.45058e-09 ; train accuracy 0.999070823\n",
      "Step 3881 : train loss 3.72529e-09 ; train accuracy 0.999071062\n",
      "Step 3882 : train loss 1.11758691e-08 ; train accuracy 0.9990713\n",
      "Step 3883 : train loss 7.45058e-09 ; train accuracy 0.999071538\n",
      "Step 3884 : train loss 1.117587e-08 ; train accuracy 0.999071777\n",
      "Step 3885 : train loss 1.49011576e-08 ; train accuracy 0.999072\n",
      "Step 3886 : train loss 3.72529e-09 ; train accuracy 0.999072254\n",
      "Step 3887 : train loss 3.72529e-09 ; train accuracy 0.999072492\n",
      "Step 3888 : train loss 7.45058e-09 ; train accuracy 0.999072731\n",
      "Step 3889 : train loss 3.72529e-09 ; train accuracy 0.999072969\n",
      "Step 3890 : train loss 3.72529e-09 ; train accuracy 0.999073207\n",
      "Step 3891 : train loss 0 ; train accuracy 0.999073446\n",
      "Step 3892 : train loss 0 ; train accuracy 0.999073684\n",
      "Step 3893 : train loss 3.72529e-09 ; train accuracy 0.999073923\n",
      "Step 3894 : train loss 0 ; train accuracy 0.999074161\n",
      "Step 3895 : train loss 1.117587e-08 ; train accuracy 0.999074399\n",
      "Step 3896 : train loss 3.72529e-09 ; train accuracy 0.999074638\n",
      "Step 3897 : train loss 7.45058e-09 ; train accuracy 0.999074876\n",
      "Step 3898 : train loss 1.49011594e-08 ; train accuracy 0.999075115\n",
      "Step 3899 : train loss 0 ; train accuracy 0.999075353\n",
      "Step 3900 : train loss 3.72529e-09 ; train accuracy 0.999075592\n",
      "Step 3901 : train loss 0 ; train accuracy 0.99907583\n",
      "Step 3902 : train loss 3.72529e-09 ; train accuracy 0.999076068\n",
      "Step 3903 : train loss 1.49011603e-08 ; train accuracy 0.999076307\n",
      "Step 3904 : train loss 0 ; train accuracy 0.999076545\n",
      "Step 3905 : train loss 3.72529e-09 ; train accuracy 0.999076784\n",
      "Step 3906 : train loss 7.45057971e-09 ; train accuracy 0.999077\n",
      "Step 3907 : train loss 3.72529e-09 ; train accuracy 0.99907726\n",
      "Step 3908 : train loss 1.49011603e-08 ; train accuracy 0.999077499\n",
      "Step 3909 : train loss 3.72529e-09 ; train accuracy 0.999077737\n",
      "Step 3910 : train loss 0 ; train accuracy 0.999078\n",
      "Step 3911 : train loss 1.86264497e-08 ; train accuracy 0.999078214\n",
      "Step 3912 : train loss 3.72529e-09 ; train accuracy 0.999078453\n",
      "Step 3913 : train loss 7.45058e-09 ; train accuracy 0.999078691\n",
      "Step 3914 : train loss 0 ; train accuracy 0.999078929\n",
      "Step 3915 : train loss 0 ; train accuracy 0.999079168\n",
      "Step 3916 : train loss 3.72529e-09 ; train accuracy 0.999079406\n",
      "Step 3917 : train loss 3.72529e-09 ; train accuracy 0.999079645\n",
      "Step 3918 : train loss 0 ; train accuracy 0.999079823\n",
      "Step 3919 : train loss 7.45058e-09 ; train accuracy 0.999080062\n",
      "Step 3920 : train loss 3.72529e-09 ; train accuracy 0.9990803\n",
      "Step 3921 : train loss 1.11758691e-08 ; train accuracy 0.999080539\n",
      "Step 3922 : train loss 7.45058e-09 ; train accuracy 0.999080777\n",
      "Step 3923 : train loss 3.72529e-09 ; train accuracy 0.999081\n",
      "Step 3924 : train loss 0 ; train accuracy 0.999081254\n",
      "Step 3925 : train loss 7.45058e-09 ; train accuracy 0.999081492\n",
      "Step 3926 : train loss 2.23517382e-08 ; train accuracy 0.999081731\n",
      "Step 3927 : train loss 7.45058e-09 ; train accuracy 0.999081969\n",
      "Step 3928 : train loss 0 ; train accuracy 0.999082208\n",
      "Step 3929 : train loss 7.45058e-09 ; train accuracy 0.999082446\n",
      "Step 3930 : train loss 3.72529e-09 ; train accuracy 0.999082685\n",
      "Step 3931 : train loss 3.72529e-09 ; train accuracy 0.999082923\n",
      "Step 3932 : train loss 7.45057971e-09 ; train accuracy 0.999083161\n",
      "Step 3933 : train loss 3.72529e-09 ; train accuracy 0.9990834\n",
      "Step 3934 : train loss 3.72529e-09 ; train accuracy 0.999083579\n",
      "Step 3935 : train loss 1.117587e-08 ; train accuracy 0.999083817\n",
      "Step 3936 : train loss 0 ; train accuracy 0.999084055\n",
      "Step 3937 : train loss 0 ; train accuracy 0.999084294\n",
      "Step 3938 : train loss 7.45058e-09 ; train accuracy 0.999084532\n",
      "Step 3939 : train loss 0 ; train accuracy 0.999084771\n",
      "Step 3940 : train loss 7.45057971e-09 ; train accuracy 0.999085\n",
      "Step 3941 : train loss 0 ; train accuracy 0.999085248\n",
      "Step 3942 : train loss 0 ; train accuracy 0.999085486\n",
      "Step 3943 : train loss 7.45058e-09 ; train accuracy 0.999085724\n",
      "Step 3944 : train loss 1.49011603e-08 ; train accuracy 0.999085963\n",
      "Step 3945 : train loss 7.45058e-09 ; train accuracy 0.999086142\n",
      "Step 3946 : train loss 7.45058e-09 ; train accuracy 0.99908638\n",
      "Step 3947 : train loss 7.45058e-09 ; train accuracy 0.999086618\n",
      "Step 3948 : train loss 1.86264497e-08 ; train accuracy 0.999086857\n",
      "Step 3949 : train loss 3.72529e-09 ; train accuracy 0.999087095\n",
      "Step 3950 : train loss 7.45058e-09 ; train accuracy 0.999087334\n",
      "Step 3951 : train loss 3.72529e-09 ; train accuracy 0.999087572\n",
      "Step 3952 : train loss 0 ; train accuracy 0.999087811\n",
      "Step 3953 : train loss 1.86264497e-08 ; train accuracy 0.999088049\n",
      "Step 3954 : train loss 7.45057971e-09 ; train accuracy 0.999088228\n",
      "Step 3955 : train loss 1.117587e-08 ; train accuracy 0.999088466\n",
      "Step 3956 : train loss 3.72529e-09 ; train accuracy 0.999088705\n",
      "Step 3957 : train loss 7.45058e-09 ; train accuracy 0.999088943\n",
      "Step 3958 : train loss 7.45058e-09 ; train accuracy 0.999089181\n",
      "Step 3959 : train loss 1.117587e-08 ; train accuracy 0.99908942\n",
      "Step 3960 : train loss 3.72529e-09 ; train accuracy 0.999089658\n",
      "Step 3961 : train loss 1.86264497e-08 ; train accuracy 0.999089897\n",
      "Step 3962 : train loss 0 ; train accuracy 0.999090075\n",
      "Step 3963 : train loss 7.45058e-09 ; train accuracy 0.999090314\n",
      "Step 3964 : train loss 3.72529e-09 ; train accuracy 0.999090552\n",
      "Step 3965 : train loss 7.45058e-09 ; train accuracy 0.999090791\n",
      "Step 3966 : train loss 1.49011603e-08 ; train accuracy 0.999091\n",
      "Step 3967 : train loss 2.60770268e-08 ; train accuracy 0.999091268\n",
      "Step 3968 : train loss 1.49011603e-08 ; train accuracy 0.999091506\n",
      "Step 3969 : train loss 7.45057971e-09 ; train accuracy 0.999091685\n",
      "Step 3970 : train loss 0 ; train accuracy 0.999091923\n",
      "Step 3971 : train loss 7.45058e-09 ; train accuracy 0.999092162\n",
      "Step 3972 : train loss 1.117587e-08 ; train accuracy 0.9990924\n",
      "Step 3973 : train loss 0 ; train accuracy 0.999092638\n",
      "Step 3974 : train loss 1.117587e-08 ; train accuracy 0.999092877\n",
      "Step 3975 : train loss 1.117587e-08 ; train accuracy 0.999093115\n",
      "Step 3976 : train loss 1.86264497e-08 ; train accuracy 0.999093294\n",
      "Step 3977 : train loss 1.86264497e-08 ; train accuracy 0.999093533\n",
      "Step 3978 : train loss 7.45058e-09 ; train accuracy 0.999093771\n",
      "Step 3979 : train loss 8.51494875e-09 ; train accuracy 0.99909389\n",
      "val loss 3.97364275e-08 ; val accuracy 1\n",
      "Step 3980 : train loss 7.45058e-09 ; train accuracy 0.999094129\n",
      "Step 3981 : train loss 7.45057971e-09 ; train accuracy 0.999094307\n",
      "Step 3982 : train loss 2.98023153e-08 ; train accuracy 0.999094546\n",
      "Step 3983 : train loss 7.45058e-09 ; train accuracy 0.999094784\n",
      "Step 3984 : train loss 0 ; train accuracy 0.999095\n",
      "Step 3985 : train loss 0 ; train accuracy 0.999095261\n",
      "Step 3986 : train loss 0 ; train accuracy 0.9990955\n",
      "Step 3987 : train loss 1.86264497e-08 ; train accuracy 0.999095678\n",
      "Step 3988 : train loss 3.72529e-09 ; train accuracy 0.999095917\n",
      "Step 3989 : train loss 1.117587e-08 ; train accuracy 0.999096155\n",
      "Step 3990 : train loss 7.45058e-09 ; train accuracy 0.999096394\n",
      "Step 3991 : train loss 3.72529e-09 ; train accuracy 0.999096632\n",
      "Step 3992 : train loss 1.117587e-08 ; train accuracy 0.999096811\n",
      "Step 3993 : train loss 1.117587e-08 ; train accuracy 0.999097049\n",
      "Step 3994 : train loss 7.45058e-09 ; train accuracy 0.999097288\n",
      "Step 3995 : train loss 3.72529e-09 ; train accuracy 0.999097526\n",
      "Step 3996 : train loss 3.72529e-09 ; train accuracy 0.999097764\n",
      "Step 3997 : train loss 0 ; train accuracy 0.999097943\n",
      "Step 3998 : train loss 3.72529e-09 ; train accuracy 0.999098182\n",
      "Step 3999 : train loss 0 ; train accuracy 0.99909842\n",
      "Step 4000 : train loss 3.72529e-09 ; train accuracy 0.999098659\n",
      "Step 4001 : train loss 1.117587e-08 ; train accuracy 0.999098897\n",
      "Step 4002 : train loss 3.72529e-09 ; train accuracy 0.999099076\n",
      "Step 4003 : train loss 0 ; train accuracy 0.999099314\n",
      "Step 4004 : train loss 1.117587e-08 ; train accuracy 0.999099553\n",
      "Step 4005 : train loss 3.72529e-09 ; train accuracy 0.999099791\n",
      "Step 4006 : train loss 3.72529e-09 ; train accuracy 0.9991\n",
      "Step 4007 : train loss 1.49011594e-08 ; train accuracy 0.999100208\n",
      "Step 4008 : train loss 0 ; train accuracy 0.999100447\n",
      "Step 4009 : train loss 0 ; train accuracy 0.999100685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4010 : train loss 3.72529e-09 ; train accuracy 0.999100924\n",
      "Step 4011 : train loss 0 ; train accuracy 0.999101102\n",
      "Step 4012 : train loss 1.86264497e-08 ; train accuracy 0.999101341\n",
      "Step 4013 : train loss 0 ; train accuracy 0.999101579\n",
      "Step 4014 : train loss 0 ; train accuracy 0.999101818\n",
      "Step 4015 : train loss 3.72529e-09 ; train accuracy 0.999102\n",
      "Step 4016 : train loss 7.45058e-09 ; train accuracy 0.999102235\n",
      "Step 4017 : train loss 3.72529e-09 ; train accuracy 0.999102473\n",
      "Step 4018 : train loss 3.72529e-09 ; train accuracy 0.999102712\n",
      "Step 4019 : train loss 3.72529e-09 ; train accuracy 0.99910295\n",
      "Step 4020 : train loss 3.72529e-09 ; train accuracy 0.999103129\n",
      "Step 4021 : train loss 0 ; train accuracy 0.999103367\n",
      "Step 4022 : train loss 1.117587e-08 ; train accuracy 0.999103606\n",
      "Step 4023 : train loss 1.117587e-08 ; train accuracy 0.999103844\n",
      "Step 4024 : train loss 0 ; train accuracy 0.999104\n",
      "Step 4025 : train loss 1.117587e-08 ; train accuracy 0.999104261\n",
      "Step 4026 : train loss 3.72528959e-08 ; train accuracy 0.9991045\n",
      "Step 4027 : train loss 3.72529e-09 ; train accuracy 0.999104738\n",
      "Step 4028 : train loss 1.49011594e-08 ; train accuracy 0.999104917\n",
      "Step 4029 : train loss 0 ; train accuracy 0.999105155\n",
      "Step 4030 : train loss 7.45058e-09 ; train accuracy 0.999105394\n",
      "Step 4031 : train loss 3.72529e-09 ; train accuracy 0.999105573\n",
      "Step 4032 : train loss 1.117587e-08 ; train accuracy 0.999105811\n",
      "Step 4033 : train loss 3.72529e-09 ; train accuracy 0.99910605\n",
      "Step 4034 : train loss 0 ; train accuracy 0.999106288\n",
      "Step 4035 : train loss 7.45058e-09 ; train accuracy 0.999106467\n",
      "Step 4036 : train loss 7.45058e-09 ; train accuracy 0.999106705\n",
      "Step 4037 : train loss 7.45058e-09 ; train accuracy 0.999106944\n",
      "Step 4038 : train loss 0 ; train accuracy 0.999107182\n",
      "Step 4039 : train loss 3.72529e-09 ; train accuracy 0.999107361\n",
      "Step 4040 : train loss 0 ; train accuracy 0.999107599\n",
      "Step 4041 : train loss 2.98023188e-08 ; train accuracy 0.999107838\n",
      "Step 4042 : train loss 3.72529e-09 ; train accuracy 0.999108\n",
      "Step 4043 : train loss 3.72529e-09 ; train accuracy 0.999108255\n",
      "Step 4044 : train loss 3.72529e-09 ; train accuracy 0.999108493\n",
      "Step 4045 : train loss 7.45058e-09 ; train accuracy 0.999108732\n",
      "Step 4046 : train loss 3.72529e-09 ; train accuracy 0.999108911\n",
      "Step 4047 : train loss 7.45058e-09 ; train accuracy 0.999109149\n",
      "Step 4048 : train loss 3.72529e-09 ; train accuracy 0.999109387\n",
      "Step 4049 : train loss 3.72529e-09 ; train accuracy 0.999109566\n",
      "Step 4050 : train loss 7.45057971e-09 ; train accuracy 0.999109805\n",
      "Step 4051 : train loss 3.72529e-09 ; train accuracy 0.999110043\n",
      "Step 4052 : train loss 1.86264497e-08 ; train accuracy 0.999110222\n",
      "Step 4053 : train loss 2.6077025e-08 ; train accuracy 0.99911046\n",
      "Step 4054 : train loss 0 ; train accuracy 0.999110699\n",
      "Step 4055 : train loss 3.72529e-09 ; train accuracy 0.999110937\n",
      "Step 4056 : train loss 1.49011594e-08 ; train accuracy 0.999111116\n",
      "Step 4057 : train loss 1.117587e-08 ; train accuracy 0.999111354\n",
      "Step 4058 : train loss 3.72529e-09 ; train accuracy 0.999111593\n",
      "Step 4059 : train loss 3.72529e-09 ; train accuracy 0.999111772\n",
      "Step 4060 : train loss 3.72529e-09 ; train accuracy 0.999112\n",
      "Step 4061 : train loss 0 ; train accuracy 0.999112248\n",
      "Step 4062 : train loss 7.45058e-09 ; train accuracy 0.999112427\n",
      "Step 4063 : train loss 1.11758691e-08 ; train accuracy 0.999112666\n",
      "Step 4064 : train loss 3.72529e-09 ; train accuracy 0.999112904\n",
      "Step 4065 : train loss 3.72529e-09 ; train accuracy 0.999113083\n",
      "Step 4066 : train loss 3.72529e-09 ; train accuracy 0.999113321\n",
      "Step 4067 : train loss 1.117587e-08 ; train accuracy 0.99911356\n",
      "Step 4068 : train loss 1.86264497e-08 ; train accuracy 0.999113739\n",
      "Step 4069 : train loss 7.45057971e-09 ; train accuracy 0.999114\n",
      "Step 4070 : train loss 3.72529e-09 ; train accuracy 0.999114215\n",
      "Step 4071 : train loss 7.45058e-09 ; train accuracy 0.999114394\n",
      "Step 4072 : train loss 3.72529e-09 ; train accuracy 0.999114633\n",
      "Step 4073 : train loss 3.72529e-09 ; train accuracy 0.999114871\n",
      "Step 4074 : train loss 0 ; train accuracy 0.99911505\n",
      "Step 4075 : train loss 3.72529e-09 ; train accuracy 0.999115288\n",
      "Step 4076 : train loss 3.72529e-09 ; train accuracy 0.999115527\n",
      "Step 4077 : train loss 0 ; train accuracy 0.999115705\n",
      "Step 4078 : train loss 7.45057971e-09 ; train accuracy 0.999115944\n",
      "Step 4079 : train loss 0 ; train accuracy 0.999116182\n",
      "Step 4080 : train loss 0 ; train accuracy 0.999116361\n",
      "Step 4081 : train loss 7.45057971e-09 ; train accuracy 0.9991166\n",
      "Step 4082 : train loss 3.72529e-09 ; train accuracy 0.999116838\n",
      "Step 4083 : train loss 0 ; train accuracy 0.999117\n",
      "Step 4084 : train loss 7.45058e-09 ; train accuracy 0.999117255\n",
      "Step 4085 : train loss 0 ; train accuracy 0.999117434\n",
      "Step 4086 : train loss 3.72529e-09 ; train accuracy 0.999117672\n",
      "Step 4087 : train loss 3.72529e-09 ; train accuracy 0.999117911\n",
      "Step 4088 : train loss 3.72529e-09 ; train accuracy 0.99911809\n",
      "Step 4089 : train loss 7.45058e-09 ; train accuracy 0.999118328\n",
      "Step 4090 : train loss 7.45058e-09 ; train accuracy 0.999118567\n",
      "Step 4091 : train loss 7.45058e-09 ; train accuracy 0.999118745\n",
      "Step 4092 : train loss 1.117587e-08 ; train accuracy 0.999119\n",
      "Step 4093 : train loss 3.72529e-09 ; train accuracy 0.999119222\n",
      "Step 4094 : train loss 7.45058e-09 ; train accuracy 0.999119401\n",
      "Step 4095 : train loss 3.72529e-09 ; train accuracy 0.999119639\n",
      "Step 4096 : train loss 0 ; train accuracy 0.999119818\n",
      "Step 4097 : train loss 0 ; train accuracy 0.999120057\n",
      "Step 4098 : train loss 7.45057971e-09 ; train accuracy 0.999120295\n",
      "Step 4099 : train loss 0 ; train accuracy 0.999120474\n",
      "Step 4100 : train loss 0 ; train accuracy 0.999120712\n",
      "Step 4101 : train loss 7.45058e-09 ; train accuracy 0.999120891\n",
      "Step 4102 : train loss 3.72529e-09 ; train accuracy 0.99912113\n",
      "Step 4103 : train loss 1.117587e-08 ; train accuracy 0.999121368\n",
      "Step 4104 : train loss 0 ; train accuracy 0.999121547\n",
      "Step 4105 : train loss 3.72529e-09 ; train accuracy 0.999121785\n",
      "Step 4106 : train loss 1.11758691e-08 ; train accuracy 0.999121964\n",
      "Step 4107 : train loss 7.45058e-09 ; train accuracy 0.999122202\n",
      "Step 4108 : train loss 1.117587e-08 ; train accuracy 0.999122441\n",
      "Step 4109 : train loss 3.72529e-09 ; train accuracy 0.99912262\n",
      "Step 4110 : train loss 0 ; train accuracy 0.999122858\n",
      "Step 4111 : train loss 1.49011576e-08 ; train accuracy 0.999123037\n",
      "Step 4112 : train loss 7.45058e-09 ; train accuracy 0.999123275\n",
      "Step 4113 : train loss 3.72529e-09 ; train accuracy 0.999123514\n",
      "Step 4114 : train loss 7.45058e-09 ; train accuracy 0.999123693\n",
      "Step 4115 : train loss 1.86264497e-08 ; train accuracy 0.999123931\n",
      "Step 4116 : train loss 0 ; train accuracy 0.99912411\n",
      "Step 4117 : train loss 1.117587e-08 ; train accuracy 0.999124348\n",
      "Step 4118 : train loss 1.117587e-08 ; train accuracy 0.999124527\n",
      "Step 4119 : train loss 0 ; train accuracy 0.999124765\n",
      "Step 4120 : train loss 1.49011603e-08 ; train accuracy 0.999125\n",
      "Step 4121 : train loss 7.45058e-09 ; train accuracy 0.999125183\n",
      "Step 4122 : train loss 7.45058e-09 ; train accuracy 0.999125421\n",
      "Step 4123 : train loss 3.72529e-09 ; train accuracy 0.9991256\n",
      "Step 4124 : train loss 0 ; train accuracy 0.999125838\n",
      "Step 4125 : train loss 0 ; train accuracy 0.999126\n",
      "Step 4126 : train loss 1.49011594e-08 ; train accuracy 0.999126256\n",
      "Step 4127 : train loss 2.98023171e-08 ; train accuracy 0.999126494\n",
      "Step 4128 : train loss 3.72529e-09 ; train accuracy 0.999126673\n",
      "Step 4129 : train loss 3.72529e-09 ; train accuracy 0.999126911\n",
      "Step 4130 : train loss 1.117587e-08 ; train accuracy 0.99912709\n",
      "Step 4131 : train loss 3.72529e-09 ; train accuracy 0.999127328\n",
      "Step 4132 : train loss 0 ; train accuracy 0.999127507\n",
      "Step 4133 : train loss 1.86264497e-08 ; train accuracy 0.999127746\n",
      "Step 4134 : train loss 1.117587e-08 ; train accuracy 0.999128\n",
      "Step 4135 : train loss 1.117587e-08 ; train accuracy 0.999128163\n",
      "Step 4136 : train loss 0 ; train accuracy 0.999128401\n",
      "Step 4137 : train loss 3.72529e-09 ; train accuracy 0.99912858\n",
      "Step 4138 : train loss 2.60770285e-08 ; train accuracy 0.999128819\n",
      "Step 4139 : train loss 3.72529e-09 ; train accuracy 0.999129\n",
      "Step 4140 : train loss 3.72529e-09 ; train accuracy 0.999129236\n",
      "Step 4141 : train loss 2.235174e-08 ; train accuracy 0.999129415\n",
      "Step 4142 : train loss 1.117587e-08 ; train accuracy 0.999129653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4143 : train loss 7.45057971e-09 ; train accuracy 0.999129832\n",
      "Step 4144 : train loss 1.49011603e-08 ; train accuracy 0.99913007\n",
      "Step 4145 : train loss 1.117587e-08 ; train accuracy 0.999130249\n",
      "Step 4146 : train loss 7.45058e-09 ; train accuracy 0.999130487\n",
      "Step 4147 : train loss 0 ; train accuracy 0.999130726\n",
      "Step 4148 : train loss 7.45058e-09 ; train accuracy 0.999130905\n",
      "Step 4149 : train loss 0 ; train accuracy 0.999131143\n",
      "Step 4150 : train loss 1.49011594e-08 ; train accuracy 0.999131322\n",
      "Step 4151 : train loss 3.72529e-09 ; train accuracy 0.99913156\n",
      "Step 4152 : train loss 0 ; train accuracy 0.99913162\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 4153 : train loss 7.45058e-09 ; train accuracy 0.999131858\n",
      "Step 4154 : train loss 3.72529e-09 ; train accuracy 0.999132037\n",
      "Step 4155 : train loss 3.72529e-09 ; train accuracy 0.999132276\n",
      "Step 4156 : train loss 2.60770268e-08 ; train accuracy 0.999132454\n",
      "Step 4157 : train loss 3.72529e-09 ; train accuracy 0.999132693\n",
      "Step 4158 : train loss 3.72529e-09 ; train accuracy 0.999132872\n",
      "Step 4159 : train loss 0 ; train accuracy 0.99913311\n",
      "Step 4160 : train loss 0 ; train accuracy 0.999133289\n",
      "Step 4161 : train loss 3.72529e-09 ; train accuracy 0.999133527\n",
      "Step 4162 : train loss 0 ; train accuracy 0.999133706\n",
      "Step 4163 : train loss 7.45057971e-09 ; train accuracy 0.999133945\n",
      "Step 4164 : train loss 2.235174e-08 ; train accuracy 0.999134123\n",
      "Step 4165 : train loss 0 ; train accuracy 0.999134362\n",
      "Step 4166 : train loss 0 ; train accuracy 0.999134541\n",
      "Step 4167 : train loss 1.117587e-08 ; train accuracy 0.999134779\n",
      "Step 4168 : train loss 3.72529e-09 ; train accuracy 0.999134958\n",
      "Step 4169 : train loss 0 ; train accuracy 0.999135196\n",
      "Step 4170 : train loss 0 ; train accuracy 0.999135375\n",
      "Step 4171 : train loss 1.86264497e-08 ; train accuracy 0.999135613\n",
      "Step 4172 : train loss 3.72529e-09 ; train accuracy 0.999135792\n",
      "Step 4173 : train loss 3.72529e-09 ; train accuracy 0.999136031\n",
      "Step 4174 : train loss 1.86264497e-08 ; train accuracy 0.999136209\n",
      "Step 4175 : train loss 3.72529e-09 ; train accuracy 0.999136448\n",
      "Step 4176 : train loss 3.72529e-09 ; train accuracy 0.999136627\n",
      "Step 4177 : train loss 0 ; train accuracy 0.999136865\n",
      "Step 4178 : train loss 1.117587e-08 ; train accuracy 0.999137044\n",
      "Step 4179 : train loss 3.72529e-09 ; train accuracy 0.999137282\n",
      "Step 4180 : train loss 0 ; train accuracy 0.999137461\n",
      "Step 4181 : train loss 7.45057971e-09 ; train accuracy 0.9991377\n",
      "Step 4182 : train loss 3.72529e-09 ; train accuracy 0.999137878\n",
      "Step 4183 : train loss 2.23517382e-08 ; train accuracy 0.999138057\n",
      "Step 4184 : train loss 7.45058e-09 ; train accuracy 0.999138296\n",
      "Step 4185 : train loss 7.45058e-09 ; train accuracy 0.999138474\n",
      "Step 4186 : train loss 0 ; train accuracy 0.999138713\n",
      "Step 4187 : train loss 0 ; train accuracy 0.999138892\n",
      "Step 4188 : train loss 0 ; train accuracy 0.99913913\n",
      "Step 4189 : train loss 0 ; train accuracy 0.999139309\n",
      "Step 4190 : train loss 0 ; train accuracy 0.999139547\n",
      "Step 4191 : train loss 3.72529e-09 ; train accuracy 0.999139726\n",
      "Step 4192 : train loss 1.49011594e-08 ; train accuracy 0.999139965\n",
      "Step 4193 : train loss 0 ; train accuracy 0.999140143\n",
      "Step 4194 : train loss 1.86264462e-08 ; train accuracy 0.999140382\n",
      "Step 4195 : train loss 1.117587e-08 ; train accuracy 0.999140561\n",
      "Step 4196 : train loss 3.72529e-09 ; train accuracy 0.999140739\n",
      "Step 4197 : train loss 7.45058e-09 ; train accuracy 0.999141\n",
      "Step 4198 : train loss 3.72529e-09 ; train accuracy 0.999141157\n",
      "Step 4199 : train loss 7.45058e-09 ; train accuracy 0.999141395\n",
      "Step 4200 : train loss 3.72529e-09 ; train accuracy 0.999141574\n",
      "Step 4201 : train loss 1.117587e-08 ; train accuracy 0.999141812\n",
      "Step 4202 : train loss 7.45058e-09 ; train accuracy 0.999142\n",
      "Step 4203 : train loss 3.72529e-09 ; train accuracy 0.99914223\n",
      "Step 4204 : train loss 1.86264497e-08 ; train accuracy 0.999142408\n",
      "Step 4205 : train loss 3.72529e-09 ; train accuracy 0.999142587\n",
      "Step 4206 : train loss 7.45058e-09 ; train accuracy 0.999142826\n",
      "Step 4207 : train loss 0 ; train accuracy 0.999143\n",
      "Step 4208 : train loss 3.72529e-09 ; train accuracy 0.999143243\n",
      "Step 4209 : train loss 7.45058e-09 ; train accuracy 0.999143422\n",
      "Step 4210 : train loss 0 ; train accuracy 0.99914366\n",
      "Step 4211 : train loss 2.23517382e-08 ; train accuracy 0.999143839\n",
      "Step 4212 : train loss 3.72529e-09 ; train accuracy 0.999144\n",
      "Step 4213 : train loss 1.49011594e-08 ; train accuracy 0.999144256\n",
      "Step 4214 : train loss 1.49011603e-08 ; train accuracy 0.999144435\n",
      "Step 4215 : train loss 2.23517382e-08 ; train accuracy 0.999144673\n",
      "Step 4216 : train loss 3.72529e-09 ; train accuracy 0.999144852\n",
      "Step 4217 : train loss 1.117587e-08 ; train accuracy 0.999145031\n",
      "Step 4218 : train loss 0 ; train accuracy 0.999145269\n",
      "Step 4219 : train loss 1.49011594e-08 ; train accuracy 0.999145448\n",
      "Step 4220 : train loss 3.72529e-09 ; train accuracy 0.999145687\n",
      "Step 4221 : train loss 3.72529e-09 ; train accuracy 0.999145865\n",
      "Step 4222 : train loss 0 ; train accuracy 0.999146044\n",
      "Step 4223 : train loss 3.72529e-09 ; train accuracy 0.999146283\n",
      "Step 4224 : train loss 0 ; train accuracy 0.999146461\n",
      "Step 4225 : train loss 0 ; train accuracy 0.9991467\n",
      "Step 4226 : train loss 0 ; train accuracy 0.999146879\n",
      "Step 4227 : train loss 0 ; train accuracy 0.999147058\n",
      "Step 4228 : train loss 1.117587e-08 ; train accuracy 0.999147296\n",
      "Step 4229 : train loss 3.72529e-09 ; train accuracy 0.999147475\n",
      "Step 4230 : train loss 3.72529e-09 ; train accuracy 0.999147713\n",
      "Step 4231 : train loss 1.117587e-08 ; train accuracy 0.999147892\n",
      "Step 4232 : train loss 1.49011603e-08 ; train accuracy 0.999148071\n",
      "Step 4233 : train loss 3.72529e-09 ; train accuracy 0.999148309\n",
      "Step 4234 : train loss 1.117587e-08 ; train accuracy 0.999148488\n",
      "Step 4235 : train loss 1.49011576e-08 ; train accuracy 0.999148726\n",
      "Step 4236 : train loss 3.72529e-09 ; train accuracy 0.999148905\n",
      "Step 4237 : train loss 3.72529e-09 ; train accuracy 0.999149084\n",
      "Step 4238 : train loss 0 ; train accuracy 0.999149323\n",
      "Step 4239 : train loss 0 ; train accuracy 0.999149501\n",
      "Step 4240 : train loss 1.117587e-08 ; train accuracy 0.99914974\n",
      "Step 4241 : train loss 0 ; train accuracy 0.999149919\n",
      "Step 4242 : train loss 1.117587e-08 ; train accuracy 0.999150097\n",
      "Step 4243 : train loss 7.45058e-09 ; train accuracy 0.999150336\n",
      "Step 4244 : train loss 7.45057971e-09 ; train accuracy 0.999150515\n",
      "Step 4245 : train loss 3.72529e-09 ; train accuracy 0.999150693\n",
      "Step 4246 : train loss 7.45058e-09 ; train accuracy 0.999150932\n",
      "Step 4247 : train loss 3.72529e-09 ; train accuracy 0.999151111\n",
      "Step 4248 : train loss 1.117587e-08 ; train accuracy 0.999151289\n",
      "Step 4249 : train loss 3.72529e-09 ; train accuracy 0.999151528\n",
      "Step 4250 : train loss 0 ; train accuracy 0.999151707\n",
      "Step 4251 : train loss 3.72529e-09 ; train accuracy 0.999151945\n",
      "Step 4252 : train loss 7.45057971e-09 ; train accuracy 0.999152124\n",
      "Step 4253 : train loss 7.45058e-09 ; train accuracy 0.999152303\n",
      "Step 4254 : train loss 0 ; train accuracy 0.999152541\n",
      "Step 4255 : train loss 3.72529e-09 ; train accuracy 0.99915272\n",
      "Step 4256 : train loss 0 ; train accuracy 0.999152899\n",
      "Step 4257 : train loss 3.72529e-09 ; train accuracy 0.999153137\n",
      "Step 4258 : train loss 0 ; train accuracy 0.999153316\n",
      "Step 4259 : train loss 0 ; train accuracy 0.999153495\n",
      "Step 4260 : train loss 3.72529e-09 ; train accuracy 0.999153733\n",
      "Step 4261 : train loss 3.72529e-09 ; train accuracy 0.999153912\n",
      "Step 4262 : train loss 0 ; train accuracy 0.999154091\n",
      "Step 4263 : train loss 7.45058e-09 ; train accuracy 0.999154329\n",
      "Step 4264 : train loss 3.72529e-09 ; train accuracy 0.999154508\n",
      "Step 4265 : train loss 3.72529e-09 ; train accuracy 0.999154687\n",
      "Step 4266 : train loss 7.45058e-09 ; train accuracy 0.999154925\n",
      "Step 4267 : train loss 7.45058e-09 ; train accuracy 0.999155104\n",
      "Step 4268 : train loss 0 ; train accuracy 0.999155283\n",
      "Step 4269 : train loss 3.72529e-09 ; train accuracy 0.999155521\n",
      "Step 4270 : train loss 7.45058e-09 ; train accuracy 0.9991557\n",
      "Step 4271 : train loss 1.117587e-08 ; train accuracy 0.999155879\n",
      "Step 4272 : train loss 7.45058e-09 ; train accuracy 0.999156117\n",
      "Step 4273 : train loss 0 ; train accuracy 0.999156296\n",
      "Step 4274 : train loss 3.72529e-09 ; train accuracy 0.999156475\n",
      "Step 4275 : train loss 3.72529e-09 ; train accuracy 0.999156713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4276 : train loss 7.45058e-09 ; train accuracy 0.999156892\n",
      "Step 4277 : train loss 3.72529e-09 ; train accuracy 0.999157071\n",
      "Step 4278 : train loss 0 ; train accuracy 0.99915731\n",
      "Step 4279 : train loss 1.117587e-08 ; train accuracy 0.999157488\n",
      "Step 4280 : train loss 1.49011594e-08 ; train accuracy 0.999157667\n",
      "Step 4281 : train loss 7.45058e-09 ; train accuracy 0.999157906\n",
      "Step 4282 : train loss 0 ; train accuracy 0.999158084\n",
      "Step 4283 : train loss 7.45058e-09 ; train accuracy 0.999158263\n",
      "Step 4284 : train loss 3.72529e-09 ; train accuracy 0.999158442\n",
      "Step 4285 : train loss 7.45057971e-09 ; train accuracy 0.99915868\n",
      "Step 4286 : train loss 3.72529e-09 ; train accuracy 0.999158859\n",
      "Step 4287 : train loss 7.45058e-09 ; train accuracy 0.999159038\n",
      "Step 4288 : train loss 0 ; train accuracy 0.999159276\n",
      "Step 4289 : train loss 7.45058e-09 ; train accuracy 0.999159455\n",
      "Step 4290 : train loss 0 ; train accuracy 0.999159634\n",
      "Step 4291 : train loss 3.72529e-09 ; train accuracy 0.999159873\n",
      "Step 4292 : train loss 7.45058e-09 ; train accuracy 0.999160051\n",
      "Step 4293 : train loss 7.45058e-09 ; train accuracy 0.99916023\n",
      "Step 4294 : train loss 0 ; train accuracy 0.999160409\n",
      "Step 4295 : train loss 1.117587e-08 ; train accuracy 0.999160647\n",
      "Step 4296 : train loss 0 ; train accuracy 0.999160826\n",
      "Step 4297 : train loss 7.45058e-09 ; train accuracy 0.999161\n",
      "Step 4298 : train loss 1.49011594e-08 ; train accuracy 0.999161243\n",
      "Step 4299 : train loss 7.45057971e-09 ; train accuracy 0.999161422\n",
      "Step 4300 : train loss 7.45058e-09 ; train accuracy 0.999161601\n",
      "Step 4301 : train loss 1.117587e-08 ; train accuracy 0.99916178\n",
      "Step 4302 : train loss 0 ; train accuracy 0.999162\n",
      "Step 4303 : train loss 3.35276056e-08 ; train accuracy 0.999162197\n",
      "Step 4304 : train loss 0 ; train accuracy 0.999162376\n",
      "Step 4305 : train loss 3.72529e-09 ; train accuracy 0.999162614\n",
      "Step 4306 : train loss 7.45058e-09 ; train accuracy 0.999162793\n",
      "Step 4307 : train loss 3.72529e-09 ; train accuracy 0.999163\n",
      "Step 4308 : train loss 7.45058e-09 ; train accuracy 0.999163151\n",
      "Step 4309 : train loss 1.117587e-08 ; train accuracy 0.999163389\n",
      "Step 4310 : train loss 1.117587e-08 ; train accuracy 0.999163568\n",
      "Step 4311 : train loss 7.45058e-09 ; train accuracy 0.999163747\n",
      "Step 4312 : train loss 2.98023188e-08 ; train accuracy 0.999163926\n",
      "Step 4313 : train loss 1.49011603e-08 ; train accuracy 0.999164164\n",
      "Step 4314 : train loss 3.72529e-09 ; train accuracy 0.999164343\n",
      "Step 4315 : train loss 0 ; train accuracy 0.999164522\n",
      "Step 4316 : train loss 1.49011603e-08 ; train accuracy 0.999164701\n",
      "Step 4317 : train loss 1.117587e-08 ; train accuracy 0.999164939\n",
      "Step 4318 : train loss 0 ; train accuracy 0.999165118\n",
      "Step 4319 : train loss 1.49011603e-08 ; train accuracy 0.999165297\n",
      "Step 4320 : train loss 7.45058e-09 ; train accuracy 0.999165535\n",
      "Step 4321 : train loss 7.45058e-09 ; train accuracy 0.999165714\n",
      "Step 4322 : train loss 0 ; train accuracy 0.999165893\n",
      "Step 4323 : train loss 1.117587e-08 ; train accuracy 0.999166071\n",
      "Step 4324 : train loss 3.72529e-09 ; train accuracy 0.99916625\n",
      "Step 4325 : train loss 8.51494875e-09 ; train accuracy 0.999166369\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 4326 : train loss 1.117587e-08 ; train accuracy 0.999166548\n",
      "Step 4327 : train loss 7.45058e-09 ; train accuracy 0.999166727\n",
      "Step 4328 : train loss 1.117587e-08 ; train accuracy 0.999166965\n",
      "Step 4329 : train loss 2.23517382e-08 ; train accuracy 0.999167144\n",
      "Step 4330 : train loss 3.72529e-09 ; train accuracy 0.999167323\n",
      "Step 4331 : train loss 1.117587e-08 ; train accuracy 0.999167502\n",
      "Step 4332 : train loss 7.45057971e-09 ; train accuracy 0.99916774\n",
      "Step 4333 : train loss 0 ; train accuracy 0.999167919\n",
      "Step 4334 : train loss 0 ; train accuracy 0.999168098\n",
      "Step 4335 : train loss 0 ; train accuracy 0.999168277\n",
      "Step 4336 : train loss 7.45058e-09 ; train accuracy 0.999168515\n",
      "Step 4337 : train loss 3.72529e-09 ; train accuracy 0.999168694\n",
      "Step 4338 : train loss 0 ; train accuracy 0.999168873\n",
      "Step 4339 : train loss 0 ; train accuracy 0.999169052\n",
      "Step 4340 : train loss 7.45058e-09 ; train accuracy 0.99916923\n",
      "Step 4341 : train loss 7.45058e-09 ; train accuracy 0.999169469\n",
      "Step 4342 : train loss 1.117587e-08 ; train accuracy 0.999169648\n",
      "Step 4343 : train loss 0 ; train accuracy 0.999169827\n",
      "Step 4344 : train loss 3.72529e-09 ; train accuracy 0.99917\n",
      "Step 4345 : train loss 1.117587e-08 ; train accuracy 0.999170244\n",
      "Step 4346 : train loss 7.45058e-09 ; train accuracy 0.999170423\n",
      "Step 4347 : train loss 0 ; train accuracy 0.999170601\n",
      "Step 4348 : train loss 3.72529e-09 ; train accuracy 0.99917078\n",
      "Step 4349 : train loss 0 ; train accuracy 0.999170959\n",
      "Step 4350 : train loss 1.117587e-08 ; train accuracy 0.999171197\n",
      "Step 4351 : train loss 0 ; train accuracy 0.999171376\n",
      "Step 4352 : train loss 1.49011576e-08 ; train accuracy 0.999171555\n",
      "Step 4353 : train loss 3.72529e-09 ; train accuracy 0.999171734\n",
      "Step 4354 : train loss 3.72529e-09 ; train accuracy 0.999171913\n",
      "Step 4355 : train loss 2.6077025e-08 ; train accuracy 0.999172151\n",
      "Step 4356 : train loss 0 ; train accuracy 0.99917233\n",
      "Step 4357 : train loss 0 ; train accuracy 0.999172509\n",
      "Step 4358 : train loss 3.72529e-09 ; train accuracy 0.999172688\n",
      "Step 4359 : train loss 0 ; train accuracy 0.999172866\n",
      "Step 4360 : train loss 7.45058e-09 ; train accuracy 0.999173105\n",
      "Step 4361 : train loss 1.86264497e-08 ; train accuracy 0.999173284\n",
      "Step 4362 : train loss 1.11758691e-08 ; train accuracy 0.999173462\n",
      "Step 4363 : train loss 3.72529e-09 ; train accuracy 0.999173641\n",
      "Step 4364 : train loss 0 ; train accuracy 0.99917382\n",
      "Step 4365 : train loss 7.45058e-09 ; train accuracy 0.999174\n",
      "Step 4366 : train loss 3.72529e-09 ; train accuracy 0.999174237\n",
      "Step 4367 : train loss 3.72529e-09 ; train accuracy 0.999174416\n",
      "Step 4368 : train loss 1.117587e-08 ; train accuracy 0.999174595\n",
      "Step 4369 : train loss 7.45058e-09 ; train accuracy 0.999174774\n",
      "Step 4370 : train loss 7.45058e-09 ; train accuracy 0.999174953\n",
      "Step 4371 : train loss 3.72529e-09 ; train accuracy 0.999175191\n",
      "Step 4372 : train loss 3.72529e-09 ; train accuracy 0.99917537\n",
      "Step 4373 : train loss 1.117587e-08 ; train accuracy 0.999175549\n",
      "Step 4374 : train loss 3.72529e-09 ; train accuracy 0.999175727\n",
      "Step 4375 : train loss 1.86264497e-08 ; train accuracy 0.999175906\n",
      "Step 4376 : train loss 1.49011603e-08 ; train accuracy 0.999176085\n",
      "Step 4377 : train loss 3.72529e-09 ; train accuracy 0.999176323\n",
      "Step 4378 : train loss 0 ; train accuracy 0.999176502\n",
      "Step 4379 : train loss 3.72529e-09 ; train accuracy 0.999176681\n",
      "Step 4380 : train loss 0 ; train accuracy 0.99917686\n",
      "Step 4381 : train loss 0 ; train accuracy 0.999177039\n",
      "Step 4382 : train loss 3.72529e-09 ; train accuracy 0.999177217\n",
      "Step 4383 : train loss 1.86264497e-08 ; train accuracy 0.999177456\n",
      "Step 4384 : train loss 3.72529e-09 ; train accuracy 0.999177635\n",
      "Step 4385 : train loss 3.72529e-09 ; train accuracy 0.999177814\n",
      "Step 4386 : train loss 1.86264497e-08 ; train accuracy 0.999178\n",
      "Step 4387 : train loss 1.86264497e-08 ; train accuracy 0.999178171\n",
      "Step 4388 : train loss 2.60770303e-08 ; train accuracy 0.99917835\n",
      "Step 4389 : train loss 1.117587e-08 ; train accuracy 0.999178588\n",
      "Step 4390 : train loss 0 ; train accuracy 0.999178767\n",
      "Step 4391 : train loss 3.72529e-09 ; train accuracy 0.999178946\n",
      "Step 4392 : train loss 0 ; train accuracy 0.999179125\n",
      "Step 4393 : train loss 0 ; train accuracy 0.999179304\n",
      "Step 4394 : train loss 0 ; train accuracy 0.999179482\n",
      "Step 4395 : train loss 0 ; train accuracy 0.999179661\n",
      "Step 4396 : train loss 0 ; train accuracy 0.9991799\n",
      "Step 4397 : train loss 0 ; train accuracy 0.999180079\n",
      "Step 4398 : train loss 2.235174e-08 ; train accuracy 0.999180257\n",
      "Step 4399 : train loss 0 ; train accuracy 0.999180436\n",
      "Step 4400 : train loss 7.45058e-09 ; train accuracy 0.999180615\n",
      "Step 4401 : train loss 3.72529e-09 ; train accuracy 0.999180794\n",
      "Step 4402 : train loss 1.117587e-08 ; train accuracy 0.999181\n",
      "Step 4403 : train loss 7.45058e-09 ; train accuracy 0.999181151\n",
      "Step 4404 : train loss 3.72529e-09 ; train accuracy 0.99918139\n",
      "Step 4405 : train loss 0 ; train accuracy 0.999181569\n",
      "Step 4406 : train loss 3.72529e-09 ; train accuracy 0.999181747\n",
      "Step 4407 : train loss 0 ; train accuracy 0.999181926\n",
      "Step 4408 : train loss 0 ; train accuracy 0.999182105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4409 : train loss 3.72529e-09 ; train accuracy 0.999182284\n",
      "Step 4410 : train loss 7.45058e-09 ; train accuracy 0.999182463\n",
      "Step 4411 : train loss 7.45058e-09 ; train accuracy 0.999182642\n",
      "Step 4412 : train loss 0 ; train accuracy 0.99918288\n",
      "Step 4413 : train loss 1.117587e-08 ; train accuracy 0.999183059\n",
      "Step 4414 : train loss 7.45057971e-09 ; train accuracy 0.999183238\n",
      "Step 4415 : train loss 3.72529e-09 ; train accuracy 0.999183416\n",
      "Step 4416 : train loss 1.49011594e-08 ; train accuracy 0.999183595\n",
      "Step 4417 : train loss 7.45058e-09 ; train accuracy 0.999183774\n",
      "Step 4418 : train loss 7.45058e-09 ; train accuracy 0.999183953\n",
      "Step 4419 : train loss 1.117587e-08 ; train accuracy 0.999184132\n",
      "Step 4420 : train loss 0 ; train accuracy 0.99918431\n",
      "Step 4421 : train loss 7.45057971e-09 ; train accuracy 0.999184549\n",
      "Step 4422 : train loss 0 ; train accuracy 0.999184728\n",
      "Step 4423 : train loss 0 ; train accuracy 0.999184906\n",
      "Step 4424 : train loss 3.72529e-09 ; train accuracy 0.999185085\n",
      "Step 4425 : train loss 1.117587e-08 ; train accuracy 0.999185264\n",
      "Step 4426 : train loss 3.72529e-09 ; train accuracy 0.999185443\n",
      "Step 4427 : train loss 0 ; train accuracy 0.999185622\n",
      "Step 4428 : train loss 1.117587e-08 ; train accuracy 0.999185801\n",
      "Step 4429 : train loss 0 ; train accuracy 0.999186\n",
      "Step 4430 : train loss 3.72529e-09 ; train accuracy 0.999186158\n",
      "Step 4431 : train loss 3.72529e-09 ; train accuracy 0.999186397\n",
      "Step 4432 : train loss 3.72529e-09 ; train accuracy 0.999186575\n",
      "Step 4433 : train loss 3.72529e-09 ; train accuracy 0.999186754\n",
      "Step 4434 : train loss 0 ; train accuracy 0.999186933\n",
      "Step 4435 : train loss 1.49011603e-08 ; train accuracy 0.999187112\n",
      "Step 4436 : train loss 3.72529e-09 ; train accuracy 0.999187291\n",
      "Step 4437 : train loss 0 ; train accuracy 0.999187469\n",
      "Step 4438 : train loss 0 ; train accuracy 0.999187648\n",
      "Step 4439 : train loss 7.45058e-09 ; train accuracy 0.999187827\n",
      "Step 4440 : train loss 3.72529e-09 ; train accuracy 0.999188\n",
      "Step 4441 : train loss 7.45058e-09 ; train accuracy 0.999188185\n",
      "Step 4442 : train loss 1.86264497e-08 ; train accuracy 0.999188364\n",
      "Step 4443 : train loss 0 ; train accuracy 0.999188602\n",
      "Step 4444 : train loss 3.72529e-09 ; train accuracy 0.999188781\n",
      "Step 4445 : train loss 2.235174e-08 ; train accuracy 0.99918896\n",
      "Step 4446 : train loss 7.45058e-09 ; train accuracy 0.999189138\n",
      "Step 4447 : train loss 0 ; train accuracy 0.999189317\n",
      "Step 4448 : train loss 0 ; train accuracy 0.999189496\n",
      "Step 4449 : train loss 3.72529e-09 ; train accuracy 0.999189675\n",
      "Step 4450 : train loss 0 ; train accuracy 0.999189854\n",
      "Step 4451 : train loss 3.72529e-09 ; train accuracy 0.999190032\n",
      "Step 4452 : train loss 0 ; train accuracy 0.999190211\n",
      "Step 4453 : train loss 3.72529e-09 ; train accuracy 0.99919039\n",
      "Step 4454 : train loss 3.72529e-09 ; train accuracy 0.999190569\n",
      "Step 4455 : train loss 0 ; train accuracy 0.999190748\n",
      "Step 4456 : train loss 7.45058e-09 ; train accuracy 0.999190927\n",
      "Step 4457 : train loss 3.72529e-09 ; train accuracy 0.999191105\n",
      "Step 4458 : train loss 3.72529e-09 ; train accuracy 0.999191344\n",
      "Step 4459 : train loss 0 ; train accuracy 0.999191523\n",
      "Step 4460 : train loss 0 ; train accuracy 0.999191701\n",
      "Step 4461 : train loss 3.72529e-09 ; train accuracy 0.99919188\n",
      "Step 4462 : train loss 3.72529e-09 ; train accuracy 0.999192059\n",
      "Step 4463 : train loss 3.72529e-09 ; train accuracy 0.999192238\n",
      "Step 4464 : train loss 3.72529e-09 ; train accuracy 0.999192417\n",
      "Step 4465 : train loss 3.72529e-09 ; train accuracy 0.999192595\n",
      "Step 4466 : train loss 1.117587e-08 ; train accuracy 0.999192774\n",
      "Step 4467 : train loss 3.72529e-09 ; train accuracy 0.999192953\n",
      "Step 4468 : train loss 7.45057971e-09 ; train accuracy 0.999193132\n",
      "Step 4469 : train loss 1.117587e-08 ; train accuracy 0.999193311\n",
      "Step 4470 : train loss 0 ; train accuracy 0.99919349\n",
      "Step 4471 : train loss 1.117587e-08 ; train accuracy 0.999193668\n",
      "Step 4472 : train loss 0 ; train accuracy 0.999193847\n",
      "Step 4473 : train loss 0 ; train accuracy 0.999194\n",
      "Step 4474 : train loss 7.45058e-09 ; train accuracy 0.999194205\n",
      "Step 4475 : train loss 3.72529e-09 ; train accuracy 0.999194384\n",
      "Step 4476 : train loss 7.45058e-09 ; train accuracy 0.999194562\n",
      "Step 4477 : train loss 1.117587e-08 ; train accuracy 0.999194741\n",
      "Step 4478 : train loss 1.49011603e-08 ; train accuracy 0.99919492\n",
      "Step 4479 : train loss 7.45058e-09 ; train accuracy 0.999195099\n",
      "Step 4480 : train loss 1.49011603e-08 ; train accuracy 0.999195278\n",
      "Step 4481 : train loss 7.45058e-09 ; train accuracy 0.999195457\n",
      "Step 4482 : train loss 7.45058e-09 ; train accuracy 0.999195635\n",
      "Step 4483 : train loss 7.45057971e-09 ; train accuracy 0.999195814\n",
      "Step 4484 : train loss 7.45058e-09 ; train accuracy 0.999196\n",
      "Step 4485 : train loss 3.72529e-09 ; train accuracy 0.999196172\n",
      "Step 4486 : train loss 0 ; train accuracy 0.999196351\n",
      "Step 4487 : train loss 7.45058e-09 ; train accuracy 0.999196529\n",
      "Step 4488 : train loss 1.117587e-08 ; train accuracy 0.999196708\n",
      "Step 4489 : train loss 1.49011594e-08 ; train accuracy 0.999196887\n",
      "Step 4490 : train loss 1.49011603e-08 ; train accuracy 0.999197066\n",
      "Step 4491 : train loss 1.49011576e-08 ; train accuracy 0.999197304\n",
      "Step 4492 : train loss 3.72529e-09 ; train accuracy 0.999197483\n",
      "Step 4493 : train loss 3.72529e-09 ; train accuracy 0.999197662\n",
      "Step 4494 : train loss 3.72529e-09 ; train accuracy 0.999197841\n",
      "Step 4495 : train loss 7.45058e-09 ; train accuracy 0.999198\n",
      "Step 4496 : train loss 3.72529e-09 ; train accuracy 0.999198198\n",
      "Step 4497 : train loss 2.98023188e-08 ; train accuracy 0.999198377\n",
      "Step 4498 : train loss 8.51494875e-09 ; train accuracy 0.999198437\n",
      "val loss 1.19209282e-07 ; val accuracy 1\n",
      "Step 4499 : train loss 0 ; train accuracy 0.999198616\n",
      "Step 4500 : train loss 3.72529e-09 ; train accuracy 0.999198794\n",
      "Step 4501 : train loss 7.45058e-09 ; train accuracy 0.999199\n",
      "Step 4502 : train loss 1.86264497e-08 ; train accuracy 0.999199152\n",
      "Step 4503 : train loss 1.11758691e-08 ; train accuracy 0.999199331\n",
      "Step 4504 : train loss 3.72529e-09 ; train accuracy 0.99919951\n",
      "Step 4505 : train loss 7.45058e-09 ; train accuracy 0.999199688\n",
      "Step 4506 : train loss 0 ; train accuracy 0.999199867\n",
      "Step 4507 : train loss 0 ; train accuracy 0.999200046\n",
      "Step 4508 : train loss 0 ; train accuracy 0.999200225\n",
      "Step 4509 : train loss 7.45058e-09 ; train accuracy 0.999200404\n",
      "Step 4510 : train loss 7.45058e-09 ; train accuracy 0.999200583\n",
      "Step 4511 : train loss 0 ; train accuracy 0.999200761\n",
      "Step 4512 : train loss 3.72529e-09 ; train accuracy 0.99920094\n",
      "Step 4513 : train loss 7.45057971e-09 ; train accuracy 0.999201119\n",
      "Step 4514 : train loss 3.72529e-09 ; train accuracy 0.999201298\n",
      "Step 4515 : train loss 7.45058e-09 ; train accuracy 0.999201477\n",
      "Step 4516 : train loss 3.72529e-09 ; train accuracy 0.999201655\n",
      "Step 4517 : train loss 1.49011603e-08 ; train accuracy 0.999201834\n",
      "Step 4518 : train loss 7.45057971e-09 ; train accuracy 0.999202\n",
      "Step 4519 : train loss 3.72528959e-08 ; train accuracy 0.999202192\n",
      "Step 4520 : train loss 0 ; train accuracy 0.999202371\n",
      "Step 4521 : train loss 0 ; train accuracy 0.99920249\n",
      "Step 4522 : train loss 1.49011594e-08 ; train accuracy 0.999202669\n",
      "Step 4523 : train loss 0 ; train accuracy 0.999202847\n",
      "Step 4524 : train loss 0 ; train accuracy 0.999203\n",
      "Step 4525 : train loss 0 ; train accuracy 0.999203205\n",
      "Step 4526 : train loss 1.117587e-08 ; train accuracy 0.999203384\n",
      "Step 4527 : train loss 0 ; train accuracy 0.999203563\n",
      "Step 4528 : train loss 0 ; train accuracy 0.999203742\n",
      "Step 4529 : train loss 7.45058e-09 ; train accuracy 0.99920392\n",
      "Step 4530 : train loss 3.72529e-09 ; train accuracy 0.999204099\n",
      "Step 4531 : train loss 0 ; train accuracy 0.999204278\n",
      "Step 4532 : train loss 3.72529e-09 ; train accuracy 0.999204457\n",
      "Step 4533 : train loss 7.45057971e-09 ; train accuracy 0.999204636\n",
      "Step 4534 : train loss 7.45058e-09 ; train accuracy 0.999204814\n",
      "Step 4535 : train loss 0 ; train accuracy 0.999205\n",
      "Step 4536 : train loss 0 ; train accuracy 0.999205172\n",
      "Step 4537 : train loss 7.45058e-09 ; train accuracy 0.999205351\n",
      "Step 4538 : train loss 0 ; train accuracy 0.99920553\n",
      "Step 4539 : train loss 0 ; train accuracy 0.999205709\n",
      "Step 4540 : train loss 3.72529e-09 ; train accuracy 0.999205887\n",
      "Step 4541 : train loss 1.117587e-08 ; train accuracy 0.999206066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4542 : train loss 0 ; train accuracy 0.999206245\n",
      "Step 4543 : train loss 3.72529e-09 ; train accuracy 0.999206364\n",
      "Step 4544 : train loss 3.72529e-09 ; train accuracy 0.999206543\n",
      "Step 4545 : train loss 0 ; train accuracy 0.999206722\n",
      "Step 4546 : train loss 1.49011603e-08 ; train accuracy 0.999206901\n",
      "Step 4547 : train loss 1.117587e-08 ; train accuracy 0.999207079\n",
      "Step 4548 : train loss 3.72529e-09 ; train accuracy 0.999207258\n",
      "Step 4549 : train loss 1.49011603e-08 ; train accuracy 0.999207437\n",
      "Step 4550 : train loss 7.45058e-09 ; train accuracy 0.999207616\n",
      "Step 4551 : train loss 3.72529e-09 ; train accuracy 0.999207795\n",
      "Step 4552 : train loss 7.45057971e-09 ; train accuracy 0.999208\n",
      "Step 4553 : train loss 7.45057971e-09 ; train accuracy 0.999208152\n",
      "Step 4554 : train loss 0 ; train accuracy 0.999208331\n",
      "Step 4555 : train loss 1.49011603e-08 ; train accuracy 0.99920851\n",
      "Step 4556 : train loss 7.45057971e-09 ; train accuracy 0.999208689\n",
      "Step 4557 : train loss 1.86264497e-08 ; train accuracy 0.999208868\n",
      "Step 4558 : train loss 1.86264497e-08 ; train accuracy 0.999209\n",
      "Step 4559 : train loss 7.45057971e-09 ; train accuracy 0.999209166\n",
      "Step 4560 : train loss 7.45057971e-09 ; train accuracy 0.999209344\n",
      "Step 4561 : train loss 3.72529e-09 ; train accuracy 0.999209523\n",
      "Step 4562 : train loss 1.11758691e-08 ; train accuracy 0.999209702\n",
      "Step 4563 : train loss 1.117587e-08 ; train accuracy 0.999209881\n",
      "Step 4564 : train loss 0 ; train accuracy 0.99921006\n",
      "Step 4565 : train loss 0 ; train accuracy 0.999210238\n",
      "Step 4566 : train loss 0 ; train accuracy 0.999210417\n",
      "Step 4567 : train loss 3.72529e-09 ; train accuracy 0.999210596\n",
      "Step 4568 : train loss 7.45057971e-09 ; train accuracy 0.999210775\n",
      "Step 4569 : train loss 3.72529e-09 ; train accuracy 0.999210894\n",
      "Step 4570 : train loss 3.72529e-09 ; train accuracy 0.999211073\n",
      "Step 4571 : train loss 7.45058e-09 ; train accuracy 0.999211252\n",
      "Step 4572 : train loss 7.45058e-09 ; train accuracy 0.999211431\n",
      "Step 4573 : train loss 1.49011603e-08 ; train accuracy 0.999211609\n",
      "Step 4574 : train loss 3.72529e-09 ; train accuracy 0.999211788\n",
      "Step 4575 : train loss 0 ; train accuracy 0.999211967\n",
      "Step 4576 : train loss 0 ; train accuracy 0.999212146\n",
      "Step 4577 : train loss 0 ; train accuracy 0.999212325\n",
      "Step 4578 : train loss 3.72529e-09 ; train accuracy 0.999212503\n",
      "Step 4579 : train loss 1.49011603e-08 ; train accuracy 0.999212623\n",
      "Step 4580 : train loss 1.49011594e-08 ; train accuracy 0.999212801\n",
      "Step 4581 : train loss 3.72529e-09 ; train accuracy 0.999213\n",
      "Step 4582 : train loss 3.72529e-09 ; train accuracy 0.999213159\n",
      "Step 4583 : train loss 0 ; train accuracy 0.999213338\n",
      "Step 4584 : train loss 3.72529e-09 ; train accuracy 0.999213517\n",
      "Step 4585 : train loss 7.45057971e-09 ; train accuracy 0.999213696\n",
      "Step 4586 : train loss 7.45058e-09 ; train accuracy 0.999213874\n",
      "Step 4587 : train loss 1.49011594e-08 ; train accuracy 0.999214053\n",
      "Step 4588 : train loss 1.86264497e-08 ; train accuracy 0.999214172\n",
      "Step 4589 : train loss 0 ; train accuracy 0.999214351\n",
      "Step 4590 : train loss 1.11758691e-08 ; train accuracy 0.99921453\n",
      "Step 4591 : train loss 1.117587e-08 ; train accuracy 0.999214709\n",
      "Step 4592 : train loss 0 ; train accuracy 0.999214888\n",
      "Step 4593 : train loss 1.117587e-08 ; train accuracy 0.999215066\n",
      "Step 4594 : train loss 3.72529e-09 ; train accuracy 0.999215245\n",
      "Step 4595 : train loss 0 ; train accuracy 0.999215424\n",
      "Step 4596 : train loss 3.72529e-09 ; train accuracy 0.999215603\n",
      "Step 4597 : train loss 3.72529e-09 ; train accuracy 0.999215722\n",
      "Step 4598 : train loss 1.117587e-08 ; train accuracy 0.999215901\n",
      "Step 4599 : train loss 0 ; train accuracy 0.99921608\n",
      "Step 4600 : train loss 0 ; train accuracy 0.999216259\n",
      "Step 4601 : train loss 3.72529e-09 ; train accuracy 0.999216437\n",
      "Step 4602 : train loss 3.72529e-09 ; train accuracy 0.999216616\n",
      "Step 4603 : train loss 3.72529e-09 ; train accuracy 0.999216795\n",
      "Step 4604 : train loss 3.72529e-09 ; train accuracy 0.999216914\n",
      "Step 4605 : train loss 3.72529e-09 ; train accuracy 0.999217093\n",
      "Step 4606 : train loss 7.45058e-09 ; train accuracy 0.999217272\n",
      "Step 4607 : train loss 0 ; train accuracy 0.999217451\n",
      "Step 4608 : train loss 3.72529e-09 ; train accuracy 0.999217629\n",
      "Step 4609 : train loss 0 ; train accuracy 0.999217808\n",
      "Step 4610 : train loss 3.72529e-09 ; train accuracy 0.999218\n",
      "Step 4611 : train loss 3.72529e-09 ; train accuracy 0.999218106\n",
      "Step 4612 : train loss 0 ; train accuracy 0.999218285\n",
      "Step 4613 : train loss 7.45058e-09 ; train accuracy 0.999218464\n",
      "Step 4614 : train loss 1.117587e-08 ; train accuracy 0.999218643\n",
      "Step 4615 : train loss 7.45058e-09 ; train accuracy 0.999218822\n",
      "Step 4616 : train loss 1.49011576e-08 ; train accuracy 0.999219\n",
      "Step 4617 : train loss 0 ; train accuracy 0.999219179\n",
      "Step 4618 : train loss 7.45058e-09 ; train accuracy 0.999219298\n",
      "Step 4619 : train loss 0 ; train accuracy 0.999219477\n",
      "Step 4620 : train loss 3.72529e-09 ; train accuracy 0.999219656\n",
      "Step 4621 : train loss 0 ; train accuracy 0.999219835\n",
      "Step 4622 : train loss 2.60770285e-08 ; train accuracy 0.99922\n",
      "Step 4623 : train loss 3.72529e-09 ; train accuracy 0.999220192\n",
      "Step 4624 : train loss 3.72529e-09 ; train accuracy 0.999220312\n",
      "Step 4625 : train loss 3.72529e-09 ; train accuracy 0.99922049\n",
      "Step 4626 : train loss 0 ; train accuracy 0.999220669\n",
      "Step 4627 : train loss 0 ; train accuracy 0.999220848\n",
      "Step 4628 : train loss 0 ; train accuracy 0.999221\n",
      "Step 4629 : train loss 7.45057971e-09 ; train accuracy 0.999221206\n",
      "Step 4630 : train loss 3.72529e-09 ; train accuracy 0.999221325\n",
      "Step 4631 : train loss 7.45058e-09 ; train accuracy 0.999221504\n",
      "Step 4632 : train loss 1.117587e-08 ; train accuracy 0.999221683\n",
      "Step 4633 : train loss 3.72529e-09 ; train accuracy 0.999221861\n",
      "Step 4634 : train loss 7.45058e-09 ; train accuracy 0.99922204\n",
      "Step 4635 : train loss 3.72529e-09 ; train accuracy 0.999222219\n",
      "Step 4636 : train loss 3.72529e-09 ; train accuracy 0.999222338\n",
      "Step 4637 : train loss 3.72529e-09 ; train accuracy 0.999222517\n",
      "Step 4638 : train loss 7.45058e-09 ; train accuracy 0.999222696\n",
      "Step 4639 : train loss 0 ; train accuracy 0.999222875\n",
      "Step 4640 : train loss 7.45058e-09 ; train accuracy 0.999223053\n",
      "Step 4641 : train loss 7.45058e-09 ; train accuracy 0.999223232\n",
      "Step 4642 : train loss 3.72529e-09 ; train accuracy 0.999223351\n",
      "Step 4643 : train loss 1.49011603e-08 ; train accuracy 0.99922353\n",
      "Step 4644 : train loss 7.45057971e-09 ; train accuracy 0.999223709\n",
      "Step 4645 : train loss 0 ; train accuracy 0.999223888\n",
      "Step 4646 : train loss 7.45058e-09 ; train accuracy 0.999224067\n",
      "Step 4647 : train loss 3.72529e-09 ; train accuracy 0.999224186\n",
      "Step 4648 : train loss 0 ; train accuracy 0.999224365\n",
      "Step 4649 : train loss 1.117587e-08 ; train accuracy 0.999224544\n",
      "Step 4650 : train loss 3.72529e-09 ; train accuracy 0.999224722\n",
      "Step 4651 : train loss 7.45058e-09 ; train accuracy 0.999224901\n",
      "Step 4652 : train loss 3.72529e-09 ; train accuracy 0.999225\n",
      "Step 4653 : train loss 1.49011603e-08 ; train accuracy 0.999225199\n",
      "Step 4654 : train loss 1.86264497e-08 ; train accuracy 0.999225378\n",
      "Step 4655 : train loss 3.72529e-09 ; train accuracy 0.999225557\n",
      "Step 4656 : train loss 3.72529e-09 ; train accuracy 0.999225736\n",
      "Step 4657 : train loss 0 ; train accuracy 0.999225855\n",
      "Step 4658 : train loss 1.117587e-08 ; train accuracy 0.999226034\n",
      "Step 4659 : train loss 1.49011594e-08 ; train accuracy 0.999226213\n",
      "Step 4660 : train loss 0 ; train accuracy 0.999226391\n",
      "Step 4661 : train loss 7.45058e-09 ; train accuracy 0.99922657\n",
      "Step 4662 : train loss 3.72529e-09 ; train accuracy 0.999226689\n",
      "Step 4663 : train loss 7.45058e-09 ; train accuracy 0.999226868\n",
      "Step 4664 : train loss 3.72529e-09 ; train accuracy 0.999227047\n",
      "Step 4665 : train loss 0 ; train accuracy 0.999227226\n",
      "Step 4666 : train loss 7.45058e-09 ; train accuracy 0.999227405\n",
      "Step 4667 : train loss 1.117587e-08 ; train accuracy 0.999227524\n",
      "Step 4668 : train loss 3.72529e-09 ; train accuracy 0.999227703\n",
      "Step 4669 : train loss 4.47034765e-08 ; train accuracy 0.999227881\n",
      "Step 4670 : train loss 7.45058e-09 ; train accuracy 0.99922806\n",
      "Step 4671 : train loss 8.51494875e-09 ; train accuracy 0.99922812\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 4672 : train loss 7.45058e-09 ; train accuracy 0.999228299\n",
      "Step 4673 : train loss 3.72529e-09 ; train accuracy 0.999228418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4674 : train loss 7.45057971e-09 ; train accuracy 0.999228597\n",
      "Step 4675 : train loss 0 ; train accuracy 0.999228776\n",
      "Step 4676 : train loss 1.117587e-08 ; train accuracy 0.999228954\n",
      "Step 4677 : train loss 1.117587e-08 ; train accuracy 0.999229133\n",
      "Step 4678 : train loss 7.45058e-09 ; train accuracy 0.999229252\n",
      "Step 4679 : train loss 0 ; train accuracy 0.999229431\n",
      "Step 4680 : train loss 7.45057971e-09 ; train accuracy 0.99922961\n",
      "Step 4681 : train loss 0 ; train accuracy 0.999229789\n",
      "Step 4682 : train loss 1.49011576e-08 ; train accuracy 0.999229908\n",
      "Step 4683 : train loss 1.49011603e-08 ; train accuracy 0.999230087\n",
      "Step 4684 : train loss 7.45058e-09 ; train accuracy 0.999230266\n",
      "Step 4685 : train loss 3.72529e-09 ; train accuracy 0.999230444\n",
      "Step 4686 : train loss 1.117587e-08 ; train accuracy 0.999230623\n",
      "Step 4687 : train loss 3.72529e-09 ; train accuracy 0.999230742\n",
      "Step 4688 : train loss 0 ; train accuracy 0.999230921\n",
      "Step 4689 : train loss 1.86264497e-08 ; train accuracy 0.9992311\n",
      "Step 4690 : train loss 7.45057971e-09 ; train accuracy 0.999231279\n",
      "Step 4691 : train loss 0 ; train accuracy 0.999231398\n",
      "Step 4692 : train loss 0 ; train accuracy 0.999231577\n",
      "Step 4693 : train loss 3.72529e-09 ; train accuracy 0.999231756\n",
      "Step 4694 : train loss 3.72529e-09 ; train accuracy 0.999231935\n",
      "Step 4695 : train loss 3.72529e-09 ; train accuracy 0.999232054\n",
      "Step 4696 : train loss 0 ; train accuracy 0.999232233\n",
      "Step 4697 : train loss 7.45058e-09 ; train accuracy 0.999232411\n",
      "Step 4698 : train loss 0 ; train accuracy 0.99923259\n",
      "Step 4699 : train loss 7.45058e-09 ; train accuracy 0.999232709\n",
      "Step 4700 : train loss 1.117587e-08 ; train accuracy 0.999232888\n",
      "Step 4701 : train loss 1.117587e-08 ; train accuracy 0.999233067\n",
      "Step 4702 : train loss 3.72529e-09 ; train accuracy 0.999233246\n",
      "Step 4703 : train loss 7.45058e-09 ; train accuracy 0.999233365\n",
      "Step 4704 : train loss 1.117587e-08 ; train accuracy 0.999233544\n",
      "Step 4705 : train loss 7.45057971e-09 ; train accuracy 0.999233723\n",
      "Step 4706 : train loss 3.72529e-09 ; train accuracy 0.999233902\n",
      "Step 4707 : train loss 3.72529e-09 ; train accuracy 0.999234\n",
      "Step 4708 : train loss 0 ; train accuracy 0.9992342\n",
      "Step 4709 : train loss 3.72529e-09 ; train accuracy 0.999234378\n",
      "Step 4710 : train loss 3.72529e-09 ; train accuracy 0.999234557\n",
      "Step 4711 : train loss 1.117587e-08 ; train accuracy 0.999234676\n",
      "Step 4712 : train loss 7.45058e-09 ; train accuracy 0.999234855\n",
      "Step 4713 : train loss 1.117587e-08 ; train accuracy 0.999235034\n",
      "Step 4714 : train loss 0 ; train accuracy 0.999235153\n",
      "Step 4715 : train loss 1.11758691e-08 ; train accuracy 0.999235332\n",
      "Step 4716 : train loss 7.45058e-09 ; train accuracy 0.999235511\n",
      "Step 4717 : train loss 3.72529e-09 ; train accuracy 0.99923569\n",
      "Step 4718 : train loss 7.45058e-09 ; train accuracy 0.999235809\n",
      "Step 4719 : train loss 7.45058e-09 ; train accuracy 0.999236\n",
      "Step 4720 : train loss 3.72529e-09 ; train accuracy 0.999236166\n",
      "Step 4721 : train loss 7.45057971e-09 ; train accuracy 0.999236345\n",
      "Step 4722 : train loss 1.49011594e-08 ; train accuracy 0.999236465\n",
      "Step 4723 : train loss 7.45057971e-09 ; train accuracy 0.999236643\n",
      "Step 4724 : train loss 0 ; train accuracy 0.999236822\n",
      "Step 4725 : train loss 0 ; train accuracy 0.999236941\n",
      "Step 4726 : train loss 0 ; train accuracy 0.99923712\n",
      "Step 4727 : train loss 7.45058e-09 ; train accuracy 0.999237299\n",
      "Step 4728 : train loss 7.45057971e-09 ; train accuracy 0.999237478\n",
      "Step 4729 : train loss 3.72529e-09 ; train accuracy 0.999237597\n",
      "Step 4730 : train loss 0 ; train accuracy 0.999237776\n",
      "Step 4731 : train loss 0 ; train accuracy 0.999237955\n",
      "Step 4732 : train loss 0 ; train accuracy 0.999238074\n",
      "Step 4733 : train loss 1.117587e-08 ; train accuracy 0.999238253\n",
      "Step 4734 : train loss 1.86264497e-08 ; train accuracy 0.999238431\n",
      "Step 4735 : train loss 1.86264479e-08 ; train accuracy 0.99923861\n",
      "Step 4736 : train loss 7.45057971e-09 ; train accuracy 0.999238729\n",
      "Step 4737 : train loss 1.49011603e-08 ; train accuracy 0.999238908\n",
      "Step 4738 : train loss 7.45058e-09 ; train accuracy 0.999239087\n",
      "Step 4739 : train loss 7.45058e-09 ; train accuracy 0.999239206\n",
      "Step 4740 : train loss 7.45058e-09 ; train accuracy 0.999239385\n",
      "Step 4741 : train loss 0 ; train accuracy 0.999239564\n",
      "Step 4742 : train loss 1.117587e-08 ; train accuracy 0.999239683\n",
      "Step 4743 : train loss 7.45058e-09 ; train accuracy 0.999239862\n",
      "Step 4744 : train loss 3.72529e-09 ; train accuracy 0.999240041\n",
      "Step 4745 : train loss 3.72529e-09 ; train accuracy 0.99924022\n",
      "Step 4746 : train loss 3.72529e-09 ; train accuracy 0.999240339\n",
      "Step 4747 : train loss 1.49011603e-08 ; train accuracy 0.999240518\n",
      "Step 4748 : train loss 0 ; train accuracy 0.999240696\n",
      "Step 4749 : train loss 3.72529e-09 ; train accuracy 0.999240816\n",
      "Step 4750 : train loss 3.72529e-09 ; train accuracy 0.999241\n",
      "Step 4751 : train loss 0 ; train accuracy 0.999241173\n",
      "Step 4752 : train loss 0 ; train accuracy 0.999241292\n",
      "Step 4753 : train loss 1.86264479e-08 ; train accuracy 0.999241471\n",
      "Step 4754 : train loss 3.72529e-09 ; train accuracy 0.99924165\n",
      "Step 4755 : train loss 3.72529e-09 ; train accuracy 0.999241769\n",
      "Step 4756 : train loss 0 ; train accuracy 0.999241948\n",
      "Step 4757 : train loss 3.72529e-09 ; train accuracy 0.999242127\n",
      "Step 4758 : train loss 3.72529e-09 ; train accuracy 0.999242246\n",
      "Step 4759 : train loss 7.45058e-09 ; train accuracy 0.999242425\n",
      "Step 4760 : train loss 1.49011594e-08 ; train accuracy 0.999242604\n",
      "Step 4761 : train loss 0 ; train accuracy 0.999242783\n",
      "Step 4762 : train loss 0 ; train accuracy 0.999242902\n",
      "Step 4763 : train loss 1.117587e-08 ; train accuracy 0.999243081\n",
      "Step 4764 : train loss 1.117587e-08 ; train accuracy 0.999243259\n",
      "Step 4765 : train loss 3.72529e-09 ; train accuracy 0.999243379\n",
      "Step 4766 : train loss 7.45058e-09 ; train accuracy 0.999243557\n",
      "Step 4767 : train loss 3.72529e-09 ; train accuracy 0.999243736\n",
      "Step 4768 : train loss 0 ; train accuracy 0.999243855\n",
      "Step 4769 : train loss 7.45058e-09 ; train accuracy 0.999244034\n",
      "Step 4770 : train loss 3.72529e-09 ; train accuracy 0.999244213\n",
      "Step 4771 : train loss 0 ; train accuracy 0.999244332\n",
      "Step 4772 : train loss 0 ; train accuracy 0.999244511\n",
      "Step 4773 : train loss 3.72529e-09 ; train accuracy 0.99924469\n",
      "Step 4774 : train loss 3.72529e-09 ; train accuracy 0.999244809\n",
      "Step 4775 : train loss 0 ; train accuracy 0.999245\n",
      "Step 4776 : train loss 3.72529e-09 ; train accuracy 0.999245167\n",
      "Step 4777 : train loss 3.72529e-09 ; train accuracy 0.999245286\n",
      "Step 4778 : train loss 0 ; train accuracy 0.999245465\n",
      "Step 4779 : train loss 0 ; train accuracy 0.999245644\n",
      "Step 4780 : train loss 0 ; train accuracy 0.999245763\n",
      "Step 4781 : train loss 3.72529e-09 ; train accuracy 0.999245942\n",
      "Step 4782 : train loss 0 ; train accuracy 0.999246061\n",
      "Step 4783 : train loss 0 ; train accuracy 0.99924624\n",
      "Step 4784 : train loss 1.117587e-08 ; train accuracy 0.999246418\n",
      "Step 4785 : train loss 3.72529e-09 ; train accuracy 0.999246538\n",
      "Step 4786 : train loss 0 ; train accuracy 0.999246716\n",
      "Step 4787 : train loss 7.45058e-09 ; train accuracy 0.999246895\n",
      "Step 4788 : train loss 1.49011594e-08 ; train accuracy 0.999247\n",
      "Step 4789 : train loss 7.45058e-09 ; train accuracy 0.999247193\n",
      "Step 4790 : train loss 0 ; train accuracy 0.999247372\n",
      "Step 4791 : train loss 3.72529e-09 ; train accuracy 0.999247491\n",
      "Step 4792 : train loss 3.72529e-09 ; train accuracy 0.99924767\n",
      "Step 4793 : train loss 1.49011603e-08 ; train accuracy 0.999247849\n",
      "Step 4794 : train loss 3.72529e-09 ; train accuracy 0.999247968\n",
      "Step 4795 : train loss 3.72529e-09 ; train accuracy 0.999248147\n",
      "Step 4796 : train loss 0 ; train accuracy 0.999248326\n",
      "Step 4797 : train loss 7.45058e-09 ; train accuracy 0.999248445\n",
      "Step 4798 : train loss 3.72529e-09 ; train accuracy 0.999248624\n",
      "Step 4799 : train loss 3.72529e-09 ; train accuracy 0.999248743\n",
      "Step 4800 : train loss 0 ; train accuracy 0.999248922\n",
      "Step 4801 : train loss 3.72529e-09 ; train accuracy 0.999249101\n",
      "Step 4802 : train loss 3.72529e-09 ; train accuracy 0.99924922\n",
      "Step 4803 : train loss 1.49011576e-08 ; train accuracy 0.999249399\n",
      "Step 4804 : train loss 0 ; train accuracy 0.999249578\n",
      "Step 4805 : train loss 3.72529e-09 ; train accuracy 0.999249697\n",
      "Step 4806 : train loss 7.45058e-09 ; train accuracy 0.999249876\n",
      "Step 4807 : train loss 3.72529e-09 ; train accuracy 0.99925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4808 : train loss 3.72529e-09 ; train accuracy 0.999250174\n",
      "Step 4809 : train loss 1.49011603e-08 ; train accuracy 0.999250352\n",
      "Step 4810 : train loss 0 ; train accuracy 0.999250472\n",
      "Step 4811 : train loss 3.72529e-09 ; train accuracy 0.99925065\n",
      "Step 4812 : train loss 3.72529e-09 ; train accuracy 0.999250829\n",
      "Step 4813 : train loss 1.117587e-08 ; train accuracy 0.999250948\n",
      "Step 4814 : train loss 0 ; train accuracy 0.999251127\n",
      "Step 4815 : train loss 1.117587e-08 ; train accuracy 0.999251246\n",
      "Step 4816 : train loss 0 ; train accuracy 0.999251425\n",
      "Step 4817 : train loss 7.45058e-09 ; train accuracy 0.999251604\n",
      "Step 4818 : train loss 0 ; train accuracy 0.999251723\n",
      "Step 4819 : train loss 0 ; train accuracy 0.999251902\n",
      "Step 4820 : train loss 1.49011603e-08 ; train accuracy 0.999252081\n",
      "Step 4821 : train loss 2.23517365e-08 ; train accuracy 0.9992522\n",
      "Step 4822 : train loss 1.49011603e-08 ; train accuracy 0.999252379\n",
      "Step 4823 : train loss 1.117587e-08 ; train accuracy 0.999252498\n",
      "Step 4824 : train loss 7.45058e-09 ; train accuracy 0.999252677\n",
      "Step 4825 : train loss 7.45058e-09 ; train accuracy 0.999252856\n",
      "Step 4826 : train loss 1.49011594e-08 ; train accuracy 0.999253\n",
      "Step 4827 : train loss 7.45058e-09 ; train accuracy 0.999253154\n",
      "Step 4828 : train loss 0 ; train accuracy 0.999253273\n",
      "Step 4829 : train loss 1.117587e-08 ; train accuracy 0.999253452\n",
      "Step 4830 : train loss 7.45058e-09 ; train accuracy 0.999253631\n",
      "Step 4831 : train loss 3.72529e-09 ; train accuracy 0.99925375\n",
      "Step 4832 : train loss 7.45058e-09 ; train accuracy 0.999253929\n",
      "Step 4833 : train loss 7.45058e-09 ; train accuracy 0.999254048\n",
      "Step 4834 : train loss 0 ; train accuracy 0.999254227\n",
      "Step 4835 : train loss 3.72529e-09 ; train accuracy 0.999254405\n",
      "Step 4836 : train loss 1.117587e-08 ; train accuracy 0.999254525\n",
      "Step 4837 : train loss 7.45058e-09 ; train accuracy 0.999254704\n",
      "Step 4838 : train loss 1.49011603e-08 ; train accuracy 0.999254823\n",
      "Step 4839 : train loss 0 ; train accuracy 0.999255\n",
      "Step 4840 : train loss 1.117587e-08 ; train accuracy 0.99925518\n",
      "Step 4841 : train loss 1.117587e-08 ; train accuracy 0.9992553\n",
      "Step 4842 : train loss 1.86264497e-08 ; train accuracy 0.999255478\n",
      "Step 4843 : train loss 3.72529e-09 ; train accuracy 0.999255598\n",
      "Step 4844 : train loss 0 ; train accuracy 0.999255657\n",
      "val loss 0 ; val accuracy 1\n",
      "Step 4845 : train loss 1.117587e-08 ; train accuracy 0.999255836\n",
      "Step 4846 : train loss 0 ; train accuracy 0.999256\n",
      "Step 4847 : train loss 0 ; train accuracy 0.999256134\n",
      "Step 4848 : train loss 3.72529e-09 ; train accuracy 0.999256313\n",
      "Step 4849 : train loss 1.49011594e-08 ; train accuracy 0.999256432\n",
      "Step 4850 : train loss 1.49011594e-08 ; train accuracy 0.999256611\n",
      "Step 4851 : train loss 7.45058e-09 ; train accuracy 0.99925679\n",
      "Step 4852 : train loss 1.117587e-08 ; train accuracy 0.999256909\n",
      "Step 4853 : train loss 3.72529e-09 ; train accuracy 0.999257088\n",
      "Step 4854 : train loss 1.86264497e-08 ; train accuracy 0.999257207\n",
      "Step 4855 : train loss 3.72529e-09 ; train accuracy 0.999257386\n",
      "Step 4856 : train loss 0 ; train accuracy 0.999257505\n",
      "Step 4857 : train loss 0 ; train accuracy 0.999257684\n",
      "Step 4858 : train loss 2.23517382e-08 ; train accuracy 0.999257863\n",
      "Step 4859 : train loss 7.45057971e-09 ; train accuracy 0.999258\n",
      "Step 4860 : train loss 0 ; train accuracy 0.999258161\n",
      "Step 4861 : train loss 7.45058e-09 ; train accuracy 0.99925828\n",
      "Step 4862 : train loss 7.45058e-09 ; train accuracy 0.999258459\n",
      "Step 4863 : train loss 3.72529e-09 ; train accuracy 0.999258578\n",
      "Step 4864 : train loss 7.45058e-09 ; train accuracy 0.999258757\n",
      "Step 4865 : train loss 0 ; train accuracy 0.999258935\n",
      "Step 4866 : train loss 0 ; train accuracy 0.999259055\n",
      "Step 4867 : train loss 1.49011603e-08 ; train accuracy 0.999259233\n",
      "Step 4868 : train loss 0 ; train accuracy 0.999259353\n",
      "Step 4869 : train loss 3.72529e-09 ; train accuracy 0.999259531\n",
      "Step 4870 : train loss 7.45058e-09 ; train accuracy 0.999259651\n",
      "Step 4871 : train loss 0 ; train accuracy 0.99925983\n",
      "Step 4872 : train loss 0 ; train accuracy 0.999259949\n",
      "Step 4873 : train loss 3.72529e-09 ; train accuracy 0.999260128\n",
      "Step 4874 : train loss 0 ; train accuracy 0.999260306\n",
      "Step 4875 : train loss 3.72529e-09 ; train accuracy 0.999260426\n",
      "Step 4876 : train loss 3.72529e-09 ; train accuracy 0.999260604\n",
      "Step 4877 : train loss 3.72529e-09 ; train accuracy 0.999260724\n",
      "Step 4878 : train loss 7.45058e-09 ; train accuracy 0.999260902\n",
      "Step 4879 : train loss 0 ; train accuracy 0.999261\n",
      "Step 4880 : train loss 0 ; train accuracy 0.9992612\n",
      "Step 4881 : train loss 3.72529e-09 ; train accuracy 0.99926132\n",
      "Step 4882 : train loss 0 ; train accuracy 0.999261498\n",
      "Step 4883 : train loss 7.45058e-09 ; train accuracy 0.999261618\n",
      "Step 4884 : train loss 7.45058e-09 ; train accuracy 0.999261796\n",
      "Step 4885 : train loss 3.72529e-09 ; train accuracy 0.999262\n",
      "Step 4886 : train loss 0 ; train accuracy 0.999262094\n",
      "Step 4887 : train loss 7.45057971e-09 ; train accuracy 0.999262273\n",
      "Step 4888 : train loss 0 ; train accuracy 0.999262393\n",
      "Step 4889 : train loss 7.45058e-09 ; train accuracy 0.999262571\n",
      "Step 4890 : train loss 7.45058e-09 ; train accuracy 0.999262691\n",
      "Step 4891 : train loss 0 ; train accuracy 0.999262869\n",
      "Step 4892 : train loss 3.72529e-09 ; train accuracy 0.999263\n",
      "Step 4893 : train loss 0 ; train accuracy 0.999263167\n",
      "Step 4894 : train loss 3.72529e-09 ; train accuracy 0.999263287\n",
      "Step 4895 : train loss 1.117587e-08 ; train accuracy 0.999263465\n",
      "Step 4896 : train loss 1.49011594e-08 ; train accuracy 0.999263585\n",
      "Step 4897 : train loss 3.72529e-09 ; train accuracy 0.999263763\n",
      "Step 4898 : train loss 7.45058e-09 ; train accuracy 0.999263942\n",
      "Step 4899 : train loss 1.117587e-08 ; train accuracy 0.999264061\n",
      "Step 4900 : train loss 3.72529e-09 ; train accuracy 0.99926424\n",
      "Step 4901 : train loss 3.72529e-09 ; train accuracy 0.999264359\n",
      "Step 4902 : train loss 1.86264497e-08 ; train accuracy 0.999264538\n",
      "Step 4903 : train loss 0 ; train accuracy 0.999264657\n",
      "Step 4904 : train loss 1.49011576e-08 ; train accuracy 0.999264836\n",
      "Step 4905 : train loss 7.45057971e-09 ; train accuracy 0.999264956\n",
      "Step 4906 : train loss 0 ; train accuracy 0.999265134\n",
      "Step 4907 : train loss 1.86264497e-08 ; train accuracy 0.999265254\n",
      "Step 4908 : train loss 3.72529e-09 ; train accuracy 0.999265432\n",
      "Step 4909 : train loss 1.117587e-08 ; train accuracy 0.999265552\n",
      "Step 4910 : train loss 7.45058e-09 ; train accuracy 0.99926573\n",
      "Step 4911 : train loss 3.72529e-09 ; train accuracy 0.99926585\n",
      "Step 4912 : train loss 0 ; train accuracy 0.999266\n",
      "Step 4913 : train loss 3.72529e-09 ; train accuracy 0.999266148\n",
      "Step 4914 : train loss 3.72529e-09 ; train accuracy 0.999266326\n",
      "Step 4915 : train loss 0 ; train accuracy 0.999266446\n",
      "Step 4916 : train loss 3.72529e-09 ; train accuracy 0.999266624\n",
      "Step 4917 : train loss 0 ; train accuracy 0.999266744\n",
      "Step 4918 : train loss 0 ; train accuracy 0.999266922\n",
      "Step 4919 : train loss 3.72529e-09 ; train accuracy 0.999267042\n",
      "Step 4920 : train loss 3.72529e-09 ; train accuracy 0.99926722\n",
      "Step 4921 : train loss 0 ; train accuracy 0.99926734\n",
      "Step 4922 : train loss 1.117587e-08 ; train accuracy 0.999267519\n",
      "Step 4923 : train loss 3.72529e-09 ; train accuracy 0.999267638\n",
      "Step 4924 : train loss 3.72529e-09 ; train accuracy 0.999267817\n",
      "Step 4925 : train loss 1.117587e-08 ; train accuracy 0.999267936\n",
      "Step 4926 : train loss 3.72529e-09 ; train accuracy 0.999268115\n",
      "Step 4927 : train loss 0 ; train accuracy 0.999268234\n",
      "Step 4928 : train loss 3.72529e-09 ; train accuracy 0.999268413\n",
      "Step 4929 : train loss 0 ; train accuracy 0.999268532\n",
      "Step 4930 : train loss 0 ; train accuracy 0.999268711\n",
      "Step 4931 : train loss 3.72529e-09 ; train accuracy 0.99926883\n",
      "Step 4932 : train loss 7.45058e-09 ; train accuracy 0.999269\n",
      "Step 4933 : train loss 3.72529e-09 ; train accuracy 0.999269128\n",
      "Step 4934 : train loss 2.23517382e-08 ; train accuracy 0.999269307\n",
      "Step 4935 : train loss 3.72529e-09 ; train accuracy 0.999269426\n",
      "Step 4936 : train loss 7.45058e-09 ; train accuracy 0.999269605\n",
      "Step 4937 : train loss 0 ; train accuracy 0.999269724\n",
      "Step 4938 : train loss 7.45057971e-09 ; train accuracy 0.999269903\n",
      "Step 4939 : train loss 3.72529e-09 ; train accuracy 0.99927\n",
      "Step 4940 : train loss 7.45058e-09 ; train accuracy 0.999270201\n",
      "Step 4941 : train loss 7.45058e-09 ; train accuracy 0.99927032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4942 : train loss 0 ; train accuracy 0.999270499\n",
      "Step 4943 : train loss 0 ; train accuracy 0.999270618\n",
      "Step 4944 : train loss 0 ; train accuracy 0.999270797\n",
      "Step 4945 : train loss 1.117587e-08 ; train accuracy 0.999270916\n",
      "Step 4946 : train loss 0 ; train accuracy 0.999271095\n",
      "Step 4947 : train loss 3.72529e-09 ; train accuracy 0.999271214\n",
      "Step 4948 : train loss 0 ; train accuracy 0.999271393\n",
      "Step 4949 : train loss 7.45058e-09 ; train accuracy 0.999271512\n",
      "Step 4950 : train loss 7.45057971e-09 ; train accuracy 0.999271691\n",
      "Step 4951 : train loss 0 ; train accuracy 0.99927181\n",
      "Step 4952 : train loss 7.45058e-09 ; train accuracy 0.999272\n",
      "Step 4953 : train loss 0 ; train accuracy 0.999272108\n",
      "Step 4954 : train loss 3.72529e-09 ; train accuracy 0.999272287\n",
      "Step 4955 : train loss 3.72529e-09 ; train accuracy 0.999272406\n",
      "Step 4956 : train loss 3.72529e-09 ; train accuracy 0.999272585\n",
      "Step 4957 : train loss 3.72529e-09 ; train accuracy 0.999272704\n",
      "Step 4958 : train loss 0 ; train accuracy 0.999272823\n",
      "Step 4959 : train loss 7.45057971e-09 ; train accuracy 0.999273\n",
      "Step 4960 : train loss 3.72529e-09 ; train accuracy 0.999273121\n",
      "Step 4961 : train loss 0 ; train accuracy 0.9992733\n",
      "Step 4962 : train loss 2.23517382e-08 ; train accuracy 0.999273419\n",
      "Step 4963 : train loss 1.117587e-08 ; train accuracy 0.999273598\n",
      "Step 4964 : train loss 7.45058e-09 ; train accuracy 0.999273717\n",
      "Step 4965 : train loss 1.49011594e-08 ; train accuracy 0.999273896\n",
      "Step 4966 : train loss 1.49011594e-08 ; train accuracy 0.999274\n",
      "Step 4967 : train loss 0 ; train accuracy 0.999274194\n",
      "Step 4968 : train loss 3.72529e-09 ; train accuracy 0.999274313\n",
      "Step 4969 : train loss 0 ; train accuracy 0.999274492\n",
      "Step 4970 : train loss 3.72529e-09 ; train accuracy 0.999274611\n",
      "Step 4971 : train loss 3.72529e-09 ; train accuracy 0.999274731\n",
      "Step 4972 : train loss 3.72529e-09 ; train accuracy 0.999274909\n",
      "Step 4973 : train loss 0 ; train accuracy 0.999275\n",
      "Step 4974 : train loss 0 ; train accuracy 0.999275208\n",
      "Step 4975 : train loss 7.45058e-09 ; train accuracy 0.999275327\n",
      "Step 4976 : train loss 3.72529e-09 ; train accuracy 0.999275506\n",
      "Step 4977 : train loss 3.72529e-09 ; train accuracy 0.999275625\n",
      "Step 4978 : train loss 3.72529e-09 ; train accuracy 0.999275804\n",
      "Step 4979 : train loss 3.72529e-09 ; train accuracy 0.999275923\n",
      "Step 4980 : train loss 3.72529e-09 ; train accuracy 0.999276102\n",
      "Step 4981 : train loss 3.72529e-09 ; train accuracy 0.999276221\n",
      "Step 4982 : train loss 7.45057971e-09 ; train accuracy 0.99927634\n",
      "Step 4983 : train loss 3.72529e-09 ; train accuracy 0.999276519\n",
      "Step 4984 : train loss 7.45058e-09 ; train accuracy 0.999276638\n",
      "Step 4985 : train loss 7.45058e-09 ; train accuracy 0.999276817\n",
      "Step 4986 : train loss 7.45058e-09 ; train accuracy 0.999276936\n",
      "Step 4987 : train loss 3.72529e-09 ; train accuracy 0.999277115\n",
      "Step 4988 : train loss 3.72529e-09 ; train accuracy 0.999277234\n",
      "Step 4989 : train loss 0 ; train accuracy 0.999277413\n",
      "Step 4990 : train loss 1.117587e-08 ; train accuracy 0.999277532\n",
      "Step 4991 : train loss 7.45058e-09 ; train accuracy 0.999277651\n",
      "Step 4992 : train loss 3.72529e-09 ; train accuracy 0.99927783\n",
      "Step 4993 : train loss 3.72529e-09 ; train accuracy 0.999277949\n",
      "Step 4994 : train loss 1.86264497e-08 ; train accuracy 0.999278128\n",
      "Step 4995 : train loss 1.49011603e-08 ; train accuracy 0.999278247\n",
      "Step 4996 : train loss 1.11758691e-08 ; train accuracy 0.999278426\n",
      "Step 4997 : train loss 7.45058e-09 ; train accuracy 0.999278545\n",
      "Step 4998 : train loss 3.72529e-09 ; train accuracy 0.999278665\n",
      "Step 4999 : train loss 1.117587e-08 ; train accuracy 0.999278843\n",
      "Step 5000 : train loss 7.45058e-09 ; train accuracy 0.999278963\n",
      "Step 5001 : train loss 7.45058e-09 ; train accuracy 0.999279141\n",
      "Step 5002 : train loss 7.45058e-09 ; train accuracy 0.999279261\n",
      "Step 5003 : train loss 7.45057971e-09 ; train accuracy 0.999279439\n",
      "Step 5004 : train loss 0 ; train accuracy 0.999279559\n",
      "Step 5005 : train loss 3.72529e-09 ; train accuracy 0.999279678\n",
      "Step 5006 : train loss 1.86264497e-08 ; train accuracy 0.999279857\n",
      "Step 5007 : train loss 3.72529e-09 ; train accuracy 0.99928\n",
      "Step 5008 : train loss 1.117587e-08 ; train accuracy 0.999280155\n",
      "Step 5009 : train loss 7.45058e-09 ; train accuracy 0.999280274\n",
      "Step 5010 : train loss 1.86264497e-08 ; train accuracy 0.999280393\n",
      "Step 5011 : train loss 3.72529e-09 ; train accuracy 0.999280572\n",
      "Step 5012 : train loss 3.72529e-09 ; train accuracy 0.999280691\n",
      "Step 5013 : train loss 1.117587e-08 ; train accuracy 0.99928087\n",
      "Step 5014 : train loss 3.72529e-09 ; train accuracy 0.999281\n",
      "Step 5015 : train loss 3.72529e-09 ; train accuracy 0.999281168\n",
      "Step 5016 : train loss 0 ; train accuracy 0.999281287\n",
      "Step 5017 : train loss 1.70298957e-08 ; train accuracy 0.999281347\n",
      "val loss 1.19209268e-07 ; val accuracy 1\n",
      "Step 5018 : train loss 7.45058e-09 ; train accuracy 0.999281466\n",
      "Step 5019 : train loss 3.72529e-09 ; train accuracy 0.999281645\n",
      "Step 5020 : train loss 7.45058e-09 ; train accuracy 0.999281764\n",
      "Step 5021 : train loss 0 ; train accuracy 0.999281943\n",
      "Step 5022 : train loss 1.117587e-08 ; train accuracy 0.999282062\n",
      "Step 5023 : train loss 1.117587e-08 ; train accuracy 0.999282181\n",
      "Step 5024 : train loss 0 ; train accuracy 0.99928236\n",
      "Step 5025 : train loss 3.72529e-09 ; train accuracy 0.999282479\n",
      "Step 5026 : train loss 3.72529e-09 ; train accuracy 0.999282658\n",
      "Step 5027 : train loss 1.11758691e-08 ; train accuracy 0.999282777\n",
      "Step 5028 : train loss 1.117587e-08 ; train accuracy 0.999282897\n",
      "Step 5029 : train loss 0 ; train accuracy 0.999283075\n",
      "Step 5030 : train loss 3.72529e-09 ; train accuracy 0.999283195\n",
      "Step 5031 : train loss 2.23517365e-08 ; train accuracy 0.999283373\n",
      "Step 5032 : train loss 3.72529e-09 ; train accuracy 0.999283493\n",
      "Step 5033 : train loss 2.60770285e-08 ; train accuracy 0.999283612\n",
      "Step 5034 : train loss 0 ; train accuracy 0.999283791\n",
      "Step 5035 : train loss 0 ; train accuracy 0.99928391\n",
      "Step 5036 : train loss 7.45058e-09 ; train accuracy 0.999284089\n",
      "Step 5037 : train loss 7.45058e-09 ; train accuracy 0.999284208\n",
      "Step 5038 : train loss 7.45058e-09 ; train accuracy 0.999284327\n",
      "Step 5039 : train loss 1.117587e-08 ; train accuracy 0.999284506\n",
      "Step 5040 : train loss 1.117587e-08 ; train accuracy 0.999284625\n",
      "Step 5041 : train loss 0 ; train accuracy 0.999284804\n",
      "Step 5042 : train loss 3.72529e-09 ; train accuracy 0.999284923\n",
      "Step 5043 : train loss 0 ; train accuracy 0.999285042\n",
      "Step 5044 : train loss 0 ; train accuracy 0.999285221\n",
      "Step 5045 : train loss 7.45057971e-09 ; train accuracy 0.99928534\n",
      "Step 5046 : train loss 0 ; train accuracy 0.999285519\n",
      "Step 5047 : train loss 3.72529e-09 ; train accuracy 0.999285638\n",
      "Step 5048 : train loss 7.45058e-09 ; train accuracy 0.999285758\n",
      "Step 5049 : train loss 1.117587e-08 ; train accuracy 0.999285936\n",
      "Step 5050 : train loss 7.45058e-09 ; train accuracy 0.999286056\n",
      "Step 5051 : train loss 3.72529e-09 ; train accuracy 0.999286175\n",
      "Step 5052 : train loss 1.117587e-08 ; train accuracy 0.999286354\n",
      "Step 5053 : train loss 0 ; train accuracy 0.999286473\n",
      "Step 5054 : train loss 0 ; train accuracy 0.999286652\n",
      "Step 5055 : train loss 7.45057971e-09 ; train accuracy 0.999286771\n",
      "Step 5056 : train loss 7.45058e-09 ; train accuracy 0.99928689\n",
      "Step 5057 : train loss 1.117587e-08 ; train accuracy 0.999287069\n",
      "Step 5058 : train loss 3.72529e-09 ; train accuracy 0.999287188\n",
      "Step 5059 : train loss 0 ; train accuracy 0.999287307\n",
      "Step 5060 : train loss 7.45058e-09 ; train accuracy 0.999287486\n",
      "Step 5061 : train loss 0 ; train accuracy 0.999287605\n",
      "Step 5062 : train loss 1.117587e-08 ; train accuracy 0.999287784\n",
      "Step 5063 : train loss 3.72529e-09 ; train accuracy 0.999287903\n",
      "Step 5064 : train loss 0 ; train accuracy 0.999288\n",
      "Step 5065 : train loss 7.45058e-09 ; train accuracy 0.999288201\n",
      "Step 5066 : train loss 7.45058e-09 ; train accuracy 0.999288321\n",
      "Step 5067 : train loss 7.45058e-09 ; train accuracy 0.99928844\n",
      "Step 5068 : train loss 7.45057971e-09 ; train accuracy 0.999288619\n",
      "Step 5069 : train loss 3.72529e-09 ; train accuracy 0.999288738\n",
      "Step 5070 : train loss 1.117587e-08 ; train accuracy 0.999288857\n",
      "Step 5071 : train loss 7.45057971e-09 ; train accuracy 0.999289036\n",
      "Step 5072 : train loss 0 ; train accuracy 0.999289155\n",
      "Step 5073 : train loss 0 ; train accuracy 0.999289334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5074 : train loss 7.45058e-09 ; train accuracy 0.999289453\n",
      "Step 5075 : train loss 1.11758691e-08 ; train accuracy 0.999289572\n",
      "Step 5076 : train loss 0 ; train accuracy 0.999289751\n",
      "Step 5077 : train loss 1.86264497e-08 ; train accuracy 0.99928987\n",
      "Step 5078 : train loss 0 ; train accuracy 0.99929\n",
      "Step 5079 : train loss 0 ; train accuracy 0.999290168\n",
      "Step 5080 : train loss 1.117587e-08 ; train accuracy 0.999290287\n",
      "Step 5081 : train loss 3.72529e-09 ; train accuracy 0.999290407\n",
      "Step 5082 : train loss 7.45058e-09 ; train accuracy 0.999290586\n",
      "Step 5083 : train loss 0 ; train accuracy 0.999290705\n",
      "Step 5084 : train loss 0 ; train accuracy 0.999290824\n",
      "Step 5085 : train loss 3.72529e-09 ; train accuracy 0.999291\n",
      "Step 5086 : train loss 1.117587e-08 ; train accuracy 0.999291122\n",
      "Step 5087 : train loss 3.72529e-09 ; train accuracy 0.999291241\n",
      "Step 5088 : train loss 3.72529e-09 ; train accuracy 0.99929142\n",
      "Step 5089 : train loss 3.72529e-09 ; train accuracy 0.999291539\n",
      "Step 5090 : train loss 0 ; train accuracy 0.999291718\n",
      "Step 5091 : train loss 0 ; train accuracy 0.999291837\n",
      "Step 5092 : train loss 1.49011576e-08 ; train accuracy 0.999291956\n",
      "Step 5093 : train loss 2.23517382e-08 ; train accuracy 0.999292135\n",
      "Step 5094 : train loss 0 ; train accuracy 0.999292254\n",
      "Step 5095 : train loss 7.45058e-09 ; train accuracy 0.999292374\n",
      "Step 5096 : train loss 7.45058e-09 ; train accuracy 0.999292552\n",
      "Step 5097 : train loss 1.86264497e-08 ; train accuracy 0.999292672\n",
      "Step 5098 : train loss 0 ; train accuracy 0.999292791\n",
      "Step 5099 : train loss 3.72529e-09 ; train accuracy 0.99929297\n",
      "Step 5100 : train loss 0 ; train accuracy 0.999293089\n",
      "Step 5101 : train loss 0 ; train accuracy 0.999293208\n",
      "Step 5102 : train loss 1.117587e-08 ; train accuracy 0.999293387\n",
      "Step 5103 : train loss 3.72529e-09 ; train accuracy 0.999293506\n",
      "Step 5104 : train loss 0 ; train accuracy 0.999293625\n",
      "Step 5105 : train loss 1.117587e-08 ; train accuracy 0.999293804\n",
      "Step 5106 : train loss 0 ; train accuracy 0.999293923\n",
      "Step 5107 : train loss 0 ; train accuracy 0.999294043\n",
      "Step 5108 : train loss 7.45058e-09 ; train accuracy 0.999294221\n",
      "Step 5109 : train loss 3.72529e-09 ; train accuracy 0.999294341\n",
      "Step 5110 : train loss 3.72529e-09 ; train accuracy 0.99929446\n",
      "Step 5111 : train loss 3.72529e-09 ; train accuracy 0.999294579\n",
      "Step 5112 : train loss 3.72529e-09 ; train accuracy 0.999294758\n",
      "Step 5113 : train loss 7.45058e-09 ; train accuracy 0.999294877\n",
      "Step 5114 : train loss 3.72529e-09 ; train accuracy 0.999295\n",
      "Step 5115 : train loss 7.45058e-09 ; train accuracy 0.999295175\n",
      "Step 5116 : train loss 3.72529e-09 ; train accuracy 0.999295294\n",
      "Step 5117 : train loss 0 ; train accuracy 0.999295413\n",
      "Step 5118 : train loss 3.72529e-09 ; train accuracy 0.999295592\n",
      "Step 5119 : train loss 1.49011603e-08 ; train accuracy 0.999295712\n",
      "Step 5120 : train loss 0 ; train accuracy 0.999295831\n",
      "Step 5121 : train loss 0 ; train accuracy 0.999296\n",
      "Step 5122 : train loss 0 ; train accuracy 0.999296129\n",
      "Step 5123 : train loss 7.45058e-09 ; train accuracy 0.999296248\n",
      "Step 5124 : train loss 3.72529e-09 ; train accuracy 0.999296427\n",
      "Step 5125 : train loss 0 ; train accuracy 0.999296546\n",
      "Step 5126 : train loss 0 ; train accuracy 0.999296665\n",
      "Step 5127 : train loss 7.45058e-09 ; train accuracy 0.999296844\n",
      "Step 5128 : train loss 0 ; train accuracy 0.999296963\n",
      "Step 5129 : train loss 0 ; train accuracy 0.999297082\n",
      "Step 5130 : train loss 3.72529e-09 ; train accuracy 0.999297202\n",
      "Step 5131 : train loss 1.117587e-08 ; train accuracy 0.99929738\n",
      "Step 5132 : train loss 0 ; train accuracy 0.9992975\n",
      "Step 5133 : train loss 1.117587e-08 ; train accuracy 0.999297619\n",
      "Step 5134 : train loss 0 ; train accuracy 0.999297798\n",
      "Step 5135 : train loss 0 ; train accuracy 0.999297917\n",
      "Step 5136 : train loss 0 ; train accuracy 0.999298036\n",
      "Step 5137 : train loss 3.72529e-09 ; train accuracy 0.999298215\n",
      "Step 5138 : train loss 0 ; train accuracy 0.999298334\n",
      "Step 5139 : train loss 0 ; train accuracy 0.999298453\n",
      "Step 5140 : train loss 7.45057971e-09 ; train accuracy 0.999298573\n",
      "Step 5141 : train loss 7.45058e-09 ; train accuracy 0.999298751\n",
      "Step 5142 : train loss 7.45058e-09 ; train accuracy 0.999298871\n",
      "Step 5143 : train loss 0 ; train accuracy 0.999299\n",
      "Step 5144 : train loss 3.72529e-09 ; train accuracy 0.999299169\n",
      "Step 5145 : train loss 3.72529e-09 ; train accuracy 0.999299288\n",
      "Step 5146 : train loss 7.45058e-09 ; train accuracy 0.999299407\n",
      "Step 5147 : train loss 3.72529e-09 ; train accuracy 0.999299586\n",
      "Step 5148 : train loss 0 ; train accuracy 0.999299705\n",
      "Step 5149 : train loss 7.45058e-09 ; train accuracy 0.999299824\n",
      "Step 5150 : train loss 7.45058e-09 ; train accuracy 0.999299943\n",
      "Step 5151 : train loss 3.72529e-09 ; train accuracy 0.999300122\n",
      "Step 5152 : train loss 1.117587e-08 ; train accuracy 0.999300241\n",
      "Step 5153 : train loss 1.49011603e-08 ; train accuracy 0.999300361\n",
      "Step 5154 : train loss 0 ; train accuracy 0.999300539\n",
      "Step 5155 : train loss 3.72529e-09 ; train accuracy 0.999300659\n",
      "Step 5156 : train loss 3.72529e-09 ; train accuracy 0.999300778\n",
      "Step 5157 : train loss 3.72529e-09 ; train accuracy 0.999300897\n",
      "Step 5158 : train loss 1.117587e-08 ; train accuracy 0.999301076\n",
      "Step 5159 : train loss 0 ; train accuracy 0.999301195\n",
      "Step 5160 : train loss 1.117587e-08 ; train accuracy 0.999301314\n",
      "Step 5161 : train loss 3.72529e-09 ; train accuracy 0.999301493\n",
      "Step 5162 : train loss 0 ; train accuracy 0.999301612\n",
      "Step 5163 : train loss 3.72529e-09 ; train accuracy 0.999301732\n",
      "Step 5164 : train loss 3.72529e-09 ; train accuracy 0.999301851\n",
      "Step 5165 : train loss 1.49011603e-08 ; train accuracy 0.999302\n",
      "Step 5166 : train loss 7.45058e-09 ; train accuracy 0.999302149\n",
      "Step 5167 : train loss 1.117587e-08 ; train accuracy 0.999302268\n",
      "Step 5168 : train loss 3.72529e-09 ; train accuracy 0.999302387\n",
      "Step 5169 : train loss 3.72529e-09 ; train accuracy 0.999302566\n",
      "Step 5170 : train loss 7.45058e-09 ; train accuracy 0.999302685\n",
      "Step 5171 : train loss 0 ; train accuracy 0.999302804\n",
      "Step 5172 : train loss 1.117587e-08 ; train accuracy 0.999303\n",
      "Step 5173 : train loss 3.72529e-09 ; train accuracy 0.999303102\n",
      "Step 5174 : train loss 1.49011603e-08 ; train accuracy 0.999303222\n",
      "Step 5175 : train loss 1.49011603e-08 ; train accuracy 0.999303341\n",
      "Step 5176 : train loss 3.72529e-09 ; train accuracy 0.99930352\n",
      "Step 5177 : train loss 1.86264479e-08 ; train accuracy 0.999303639\n",
      "Step 5178 : train loss 1.49011603e-08 ; train accuracy 0.999303758\n",
      "Step 5179 : train loss 7.45058e-09 ; train accuracy 0.999303877\n",
      "Step 5180 : train loss 3.72529e-09 ; train accuracy 0.999304056\n",
      "Step 5181 : train loss 1.86264497e-08 ; train accuracy 0.999304175\n",
      "Step 5182 : train loss 3.72529e-09 ; train accuracy 0.999304295\n",
      "Step 5183 : train loss 1.86264497e-08 ; train accuracy 0.999304414\n",
      "Step 5184 : train loss 3.72529e-09 ; train accuracy 0.999304593\n",
      "Step 5185 : train loss 3.72529e-09 ; train accuracy 0.999304712\n",
      "Step 5186 : train loss 3.72529e-09 ; train accuracy 0.999304831\n",
      "Step 5187 : train loss 1.117587e-08 ; train accuracy 0.99930495\n",
      "Step 5188 : train loss 7.45058e-09 ; train accuracy 0.999305129\n",
      "Step 5189 : train loss 3.72529e-09 ; train accuracy 0.999305248\n",
      "Step 5190 : train loss 8.51494875e-09 ; train accuracy 0.999305308\n",
      "val loss 0 ; val accuracy 1\n",
      "finishing time:  1617083151.0911484\n",
      "\n",
      "total time taken:  543.774621963501\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(pre_trained_model.input, x)\n",
    "\n",
    "# selecting GPU as the training device\n",
    "device = '/gpu:0' if tf.config.list_physical_devices('GPU') else '/cpu:0'\n",
    "\n",
    "# Custom training step\n",
    "def train_one_step(model, optimizer, x, y, train_loss, train_accuracy):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x)\n",
    "        loss = train_loss(y, predictions)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)   \n",
    "    # Zip the gradients and model variables, and then apply the result on the optimizer\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables)) \n",
    "    # Call the train accuracy object on ground truth and predictions\n",
    "    train_accuracy(y, predictions)\n",
    "    return loss\n",
    "\n",
    "# Decorate this function with tf.function to enable autograph on the training loop\n",
    "@tf.function\n",
    "def train(model, optimizer, epochs, device, train_ds, train_loss, train_accuracy, valid_ds, val_loss, val_accuracy):\n",
    "    step = 0\n",
    "    loss = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in train_ds:\n",
    "            # training step number increments at each iteration\n",
    "            step += 1\n",
    "            with tf.device(device_name=device):\n",
    "                # Run one training step by passing appropriate model parameters\n",
    "                # required by the function and finally get the loss to report the results\n",
    "                loss = train_one_step(model, optimizer, x, y, train_loss, train_accuracy)\n",
    "            # Use tf.print to report your results.\n",
    "            # Print the training step number, loss and accuracy\n",
    "            tf.print('Step', step, \n",
    "                   ': train loss', loss, \n",
    "                   '; train accuracy', train_accuracy.result())\n",
    "\n",
    "        with tf.device(device_name=device):\n",
    "            for x, y in valid_ds:\n",
    "                # Call the model on the batches of inputs x and get the predictions\n",
    "                y_pred = model(x)\n",
    "                loss = val_loss(y, y_pred)\n",
    "                val_accuracy(y, y_pred)\n",
    "        \n",
    "        # Print the validation loss and accuracy\n",
    "        tf.print('val loss', loss, '; val accuracy', val_accuracy.result())\n",
    "    \n",
    "t0 = time.time()\n",
    "print('starting time: ', t0)\n",
    "    \n",
    "train(model, optimizer, EPOCHS, device, train_ds, train_loss, train_accuracy, val_ds, val_loss, val_accuracy)\n",
    "\n",
    "tn = time.time()\n",
    "print('finishing time: ', tn)\n",
    "t_m3 = tn - t0\n",
    "print('\\ntotal time taken: ', t_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "revolutionary-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ignored-crash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by ImageDataGenerator method\t:\t331.32935905456543 seconds\n",
      "Time taken by tf.Data method\t:\t321.99148511886597 seconds\n",
      "Time taken by Autograph method\t:\t543.774621963501 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time taken by ImageDataGenerator method\\t:\\t{t_m1} seconds\")\n",
    "print(f\"Time taken by tf.Data method\\t:\\t{t_m2} seconds\")\n",
    "print(f\"Time taken by Autograph method\\t:\\t{t_m3} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-exploration",
   "metadata": {},
   "source": [
    "# Results:\n",
    "| Method | Time taken(s) |\n",
    "|---|---|\n",
    "| ImageDataGenerator | 331 |\n",
    "| tf.Data | 321 |\n",
    "| Autograph Model | 543 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
